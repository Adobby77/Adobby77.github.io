<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://adobby77.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://adobby77.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-02-16T12:58:38+00:00</updated><id>https://adobby77.github.io/feed.xml</id><title type="html">Woojin Shin</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Control Barrier Functions</title><link href="https://adobby77.github.io/study/2026/CBF/" rel="alternate" type="text/html" title="Control Barrier Functions"/><published>2026-02-04T03:00:00+00:00</published><updated>2026-02-04T03:00:00+00:00</updated><id>https://adobby77.github.io/study/2026/CBF</id><content type="html" xml:base="https://adobby77.github.io/study/2026/CBF/"><![CDATA[<p>Control Barrier Function is one of the most popular methods of ‘Safety Control’.</p> <p>This documents mainly refers to ‘Control Barrier Functions: Theory and Applications (2019)’ and includes additional explanations from other references.</p> <h2 id="1-introduction">1. Introduction</h2> <div style="height: 0.1em;"></div> <h3 id="11-motivation">1.1. Motivation</h3> <ul> <li><strong>Intuition of Liveness &amp; Safety</strong> <ul> <li><strong>Liveness:</strong> “Good” things eventually happen. (ex: Asymptotic Stability)</li> <li><strong>Safety:</strong> “Bad” things do not happen. (ex: Invariance)</li> </ul> </li> <li><strong>Motivation (Why CBF?)</strong> <ol> <li> <p><strong>Societal need for safety control</strong></p> <p>Much of the recent interest lies broadly on autonomous systems, that are expected to operate in ==unknown and unstructured environments.== However, while the modern control theory dominantly focuses on methods analyzing and implementing liveness such as Lyapunov functions, the research about ==ensuring safety was not extensively studied.==</p> </li> <li> <p><strong>Usefulness</strong></p> <p>Lots of ==methods based on Lyapunov theory can be suitably transposed== to address the safety considerations,</p> </li> </ol> </li> </ul> <div style="height: 0.1em;"></div> <h3 id="12-a-brief-history-of-barrier-functions">1.2. A Brief History of Barrier Functions</h3> <p>As we mentioned above, our major concern in safety control is <strong>invariance</strong>- ensuring that the system states remain within a predefined safe set.</p> <p>First, introduce a definition of safe set.</p> <h5 id="def-11-safe-set">Def 1.1) Safe set</h5> <blockquote> <p>Given a smooth function $h:\R^n\to\R$, a safe set $\mathcal{C}$ is a superlevel set</p> <div class="kdmath">$$ \mathcal{C}=\{x\in\R^n:h(x)\geq 0\} $$</div> <p>satisfying $\del h(x)=\frac{\pp h}{\pp x}(x)\neq0$ for all $x\in\pp \mathcal{C}={x\in\R^n:h(x)=0}$.</p> </blockquote> <p>Here, he boundary condition is required to guarantee that the boundary $\pp\mathcal{C}$ be smooth $(n-1)$-dimensional manifold.</p> <h4 id="121-bony-brezis-theorem-nagumos-theorem">1.2.1. Bony-Brezis theorem (Nagumo’s theorem)</h4> <p>One of the most monumental theorem is a <strong>Bony-Brezis theorem (also called Nagumo’s theorem)</strong>, that gives necessary and sufficient conditions for set invariance.</p> <p>While Nagumo’s theorem is the first, these conditions have been independently re-discovered on multiple occasions; in particular, around the 1970s by Bony and Brezis.</p> <h5 id="thm-12-bony-brezis-theorem">Thm 1.2) Bony-Brezis theorem</h5> <blockquote> <p>Let $F$ be closed subset of a $C^2$ manifold $M$ and let $X$ be a vector field on $M$ which is Lipschitz continuous. Then, TFAE:</p> <ol> <li>Every integral curve of $X$ starting in $F$ remains in $F$.</li> <li>$(X(m),v)\leq 0$ for every exterior normal vector $v$ at a point $m\in F$.</li> </ol> </blockquote> <div style="height: 0.1em;"></div> <p>In the context of control theory, we can translate such a theorem in more familiar form below.</p> <blockquote> <p>Given a dynamical system $\dot x=f(x)$ with $x\in \R^n$, let the safe set $\mathcal{C}$ corresponding to a smooth function $h:\R^n\to\R$.</p> <p>Then, TFAE:</p> <ol> <li>$\mathcal{C}$ is invariant.</li> <li>$\dot h(x)\geq 0,\q\forall x\in\partial C={x:h(x)=0}$.</li> </ol> </blockquote> <p>Here, $\dot h(x)=\frac{dh}{dt}=\frac{\pp h}{\pp x}\frac{dx}{dt}=\frac{\pp h}{\pp x} f(x)$.</p> <div style="height: 0.1em;"></div> <blockquote> <p>[!note] Comparison of the Two forms</p> <table> <thead> <tr> <th style="text-align: left">Component</th> <th style="text-align: center">Geometric Form</th> <th style="text-align: center">Functional Form</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><strong>Motion</strong></td> <td style="text-align: center">Vector field $X(m)$</td> <td style="text-align: center">System dynamics $f(x)$</td> </tr> <tr> <td style="text-align: left"><strong>Safe Region</strong></td> <td style="text-align: center">Closed set $F$</td> <td style="text-align: center">Superlevel set ${x : h(x) \ge 0}$</td> </tr> <tr> <td style="text-align: left"><strong>Boundary Vector</strong></td> <td style="text-align: center">Exterior normal $\nu$ (points <strong>out</strong>)</td> <td style="text-align: center">Gradient $\nabla h$ (points <strong>in</strong>)</td> </tr> <tr> <td style="text-align: left"><strong>The Requirement</strong></td> <td style="text-align: center">Velocity must not point <strong>out</strong> ($\le 0$)</td> <td style="text-align: center">$h$ must not <strong>decrease</strong> ($\ge 0$)</td> </tr> </tbody> </table> </blockquote> <div style="height: 0.1em;"></div> <h4 id="122-barrier-certificates">1.2.2. Barrier Certificates</h4> <p>Barrier Certificates was introduced to formally prove safety of nonlinear and hybrid systems.</p> <h5 id="def-13-barrier-certificates">Def 1.3) Barrier Certificates</h5> <blockquote> <p>Let $\mathcal{C_0}$ be the set of initial conditions and $\mathcal{C}_u$ be an unsafe set. Then, a function $B:\R^n\to \R$ is called a <strong>barrier certificate</strong> if</p> <ol> <li>$B(x)\leq 0$ for all $x\in \mathcal{C}_0$</li> <li>$B(x)&gt; 0$ for all $x\in \mathcal{C}_u$</li> <li>$\dot B(x)\leq 0\;\Longrightarrow\;\mathcal{C}$ is invariant (where $\mathcal{C}=\mathcal{C}_u^c$).</li> </ol> </blockquote> <p>Here, by letting $h=-B$, the $h$ in the Bony-Brezis theorem corresponds to the restriction of the barrier certificate to $\partial C$.</p> <div style="height: 0.1em;"></div> <h4 id="123-barrier-lyapunov-functions">1.2.3. Barrier Lyapunov Functions</h4> <p>To extend the safety guarantees beyond the boundary of the set, a various “Lyapunov-like” approaches were introduced.</p> <h5 id="def-14-barrier-lyapunov-functions">Def 1.4) Barrier Lyapunov functions</h5> <blockquote> <p>Let $\mathcal{C_0}$ be the set of initial conditions and $\mathcal{C}_u$ be an unsafe set. Then, a function $B:\R^n\to \R$ is called a <strong>barrier Lyapunov function</strong> if</p> <ol> <li>$B(x)\leq 0$ for all $x\in \mathcal{C}_0$</li> <li>$B(x)&gt; 0$ for all $x\in \mathcal{C}_u$</li> <li>$\dot B(x)\leq 0\;\Longrightarrow\;\mathcal{C}$ is invariant (where $\mathcal{C}=\mathcal{C}_u^c$).</li> <li>$B$ is positive definite.</li> </ol> </blockquote> <p>This is just adding “positive definiteness” to the definition of Barrier certificate $B$.</p> <p>Then, $\dot B(x)\leq 0$ be satisfied for all $x\in \mathcal{C}$.</p> <ul> <li><strong>Advantage:</strong> It ensures <strong>invariance and hence safety</strong>.</li> <li><strong>Limitation:</strong> They enforce every level set invariant and hence they be <strong>overly conservative.</strong></li> </ul> <blockquote> <p>[! note] Limitation of BLF</p> <p>Let $\Omega_c={x(t):B(x(t))\leq c}\subset \mathcal{C}$ is a sublevel set of $B$.</p> <p>Then, by the definition of sublevel set,</p> <ol> <li>$\Omega_{c_1}\subseteq\Omega_{c_2}$ iff $c_1\leq c_2$.</li> <li>$\exists c_{\text{max}}$ s.t. $\Omega_c\subset\Omega_{c_\max}=\mathcal{C}$ for all $c\leq c_\max$ and $\Omega_c\not\subset\mathcal{C}$ for all $c&gt;c_\max$.</li> </ol> <p>Here, let $B(x(0))=c_0$ and hence $x(0)\in\Omega_{c_0}$.</p> <p>If $B$ is a barrier Lyapunov function, then $\dot B(x(t))\leq 0$ for all $t$ and hence $x(t)\in \Omega_{c_0}$ for all $t$, i.e. $B(x(t))\leq c_0$ for all $t$. So, while this system is obviously safe, but overly conservative.</p> <ul> <li><strong>The Trap</strong>: If the system starts in a “very safe” state where $c_0​\ll c_\max$​, it is mathematically forbidden from moving toward the boundary of $\mathcal{C}$.</li> <li><strong>The Lost Space</strong>: The region $\mathcal{C}\setminus \Omega_{c_0}$​​ becomes “dead space.” Even though these states are safe, the BLF controller will treat them as “forbidden” because reaching them would require $B(x)$ to increase ($\dot B&gt;0$), which is prohibited.</li> </ul> </blockquote> <div style="height: 0.1em;"></div> <h4 id="124-open-dynamical-systems">1.2.4. Open Dynamical Systems</h4> <p>Early work, such as Bony-Brezis theorem or Barrier Certificates, focused on <strong>closed systems</strong> $(\dot x=f(x))$, which was more about <strong>analysis and verification(not control)</strong> of existing dynamics.</p> <p>The discussion then shifted to <strong>open systems</strong> $(\dot x=f(x)+g(x)u)$, moving from passive observation to <strong>active control synthesis</strong>.</p> <p>In this paradigm, the barrier certificate was extended to the first definition of a control barrier function.</p> <p>First, introduce the definition.</p> <h5 id="def-15-forward-invariant-set-safe-system">Def 1.5) Forward invariant set, Safe system</h5> <blockquote> <p>The set $\mathcal{C}$ is called <strong>forward invariant</strong> if for every $x_0\in\mathcal{C}$, $x(t)\in\mathcal{C}$ for $x(0)=x_0$ and all $t\in \left[0,\tau_\max\right)$. The system is called <strong>safe</strong> w.r.t. $\mathcal{C}$ if the safe set $\mathcal{C}={x\in D:h(x)\geq 0}$ of the system is forward invariant.</p> </blockquote> <h5 id="def-16-first-version-of-control-barrier-function">Def 1.6) First version of Control Barrier Function</h5> <blockquote> <p>Consider a control system $\dot x(t)=f(x)+g(x)u$ and a safe set $\mathcal{C}\subset D\subset\R^n$ defined as the superlevel set of a continuously differentiable function $h:D\to \R$, i.e.</p> <div class="kdmath">$$ \mathcal{C}=\{x\in D:h(x)\geq 0\} $$</div> <p>Then, the function $h$ is a <strong>control barrier function</strong> if for all $x\in\mathcal{C}$, there exists a control input $u\in U$ such that</p> <div class="kdmath">$$ \dot h(x,u)\geq 0\;\Longrightarrow\;\mathcal{C}\;\text{ is forward invariant} $$</div> </blockquote> <p>This definition essentially demanded that the safety measure $h(x)$ never decrease, enforcing the system to <strong>“stay away” or “move away” from the boundary at all times.</strong></p> <div style="height: 0.1em;"></div> <h4 id="125-unification-of-barrier-function-with-lyapunov">1.2.5. Unification of Barrier function with Lyapunov</h4> <p>Following this, researchers sought to explicitly combine barrier functions with <strong>Control Lyapunov Functions (CLF)</strong> to achieve safety and stability simultaneously. These early frameworks (e.g., “Control Lyapunov Barrier Functions”) successfully unified the concepts but relied on the strict condition of the first definition ($\dot h \geq 0$).</p> <ul> <li><strong>The Problem:</strong> This condition was <strong>stronger than necessary</strong>.</li> <li><strong>Interpretation:</strong> It implied that even when the system is far from danger (i.e., $h(x)$ is very large), the controller is not allowed to let $h(x)$ decrease. This essentially treats safe states as “frozen,” severely restricting the controller’s flexibility and performance.</li> </ul> <div style="height: 0.1em;"></div> <p>These limitations motivated the <strong>“most recent formulation”</strong> of safety certificates, simply termed <strong>Control Barrier Functions (CBF)</strong>.</p> <hr/> <h2 id="2-foundations-of-control-barrier-functions">2. Foundations of Control Barrier Functions</h2> <div style="height: 0.1em;"></div> <p>We will suppose that we have a nonlinear affine control system:</p> <div class="kdmath">$$ \dot x=f(x)+g(x)u\q\cdots\q(*) $$</div> <p>where both $f$ and $g$ are locally Lipschitz, $x\in D\in\R^n$ and $u\in U\subset \R^m$.</p> <p>Before starting our argument, introduce a simple lemma first.</p> <h5 id="lem-21-comparison-lemma">Lem 2.1) Comparison lemma</h5> <blockquote> <p>Consider the scalar function $f$ defined as:</p> <div class="kdmath">$$ f : [t_0,\infty) \times D \to \mathbb{R} $$</div> <p>where $t_0\in\R$ and $D \subset \mathbb{R}$ is a connected open set.</p> <p>Suppose that $f(t, x)$ is continuous in $t$ and locally Lipschitz in $x$.</p> <p>Let $u(t): [t_0,\infty) \to D$ be the solution to the <strong>differential equation</strong>:</p> <div class="kdmath">$$ \dot{u}(t) = f(t, u(t)), \quad u(t_0) = u_0 $$</div> <p>Let $v(t): [t_0,\infty) \to D$ be a differentiable function satisfying the <strong>differential inequality</strong>:</p> <div class="kdmath">$$ \dot{v}(t) \leq f(t, v(t)), \quad \forall t \in [t_0,\infty) $$</div> <p><strong>Statement:</strong></p> <p>If the initial conditions satisfy $v(t_0) \leq u(t_0)$, then:</p> <div class="kdmath">$$ v(t) \leq u(t), \quad \forall t \in [t_0,\infty) $$</div> </blockquote> <p>In short, this lemma says that <strong>“Given two systems with initial condition $u_0, v_0$ s.t. $u_0\leq v_0$, if $\dot u\leq \dot v$, then $u(t)\leq v(t)$ for all $t$.”</strong></p> <div style="height: 0.1em;"></div> <h3 id="21-motivation-control-lyapunov-functions">2.1. Motivation: Control Lyapunov Functions</h3> <p>Recall that the objective(goal) of Control Lyapunov function is “Stabilizing” a given system.</p> <p>Suppose we have the control objective of stabilizing a system $(*)$ to a point $x^*=0$, i.e. driving $x(t)\to 0$.</p> <p>In a nonlinear context, this can be achieved equivalently ==finding a feedback control law that drives a positive definite function $V:D\to\R_{\ge 0}$ to zero.==</p> <p>This can be formally stated as:</p> <blockquote> <p>[!note] Asymptotically stabilizable system</p> <p>If</p> <div class="kdmath">$$ \exists u=k(x)\q\text{s.t.}\q \dot V(x, k(x))\leq -\gamma(V(x))\q\cdots\q(\dagger) $$</div> <p>where</p> <div class="kdmath">$$ \dot V(x,k(x))=L_fV(x)+L_gV(x)k(x) $$</div> <p>and $\gamma:\R_{\ge0}\to\R_{\ge 0}$ is a class $\mathcal{K}$ function,</p> <p>then the system $(*)$ is <strong>asymptotically stabilizable</strong> to $V(x^*)=0$, i.e. $x^*=0$.</p> </blockquote> <p><strong>Reduction of complexity:</strong> By the statement that we stated above, we only need to treat the one-dimensional (scalar) value $V(x)$ from $(\dagger)$ instead of treating the $n$-dimensional state vector $x(t)$ of $(*)$.</p> <p>Specifically, by invoking the <strong>comparison lemma</strong>, the differential inequality $(\dagger)$ ensures that the trajectory of $V(x(t))$ is upper-bounded by the solution of the scalar equation $\dot{y} = -\gamma(y)$.</p> <p>Since the origin of this scalar system is asymptotically stable (by the definition of the class $\mathcal{K}$ function $\gamma$), $y(t) \to 0$ as $t \to \infty$. Consequently, $V(x(t))$ is forced to zero.</p> <p>Finally, due to the <strong>positive definite</strong> property of $V$, ==driving $V(x) \to 0$ necessarily implies driving the state $x(t) \to 0$.==</p> <div style="height: 0.1em;"></div> <p>Based on the argument above, we <strong>do not need to explicitly construct</strong> the feedback controller $u=k(x)$ first. Instead, we only need to ensure that a stabilizing controller <strong>exists.</strong></p> <h5 id="def-22-control-lyapunov-function-set-of-all-stabilizing-controllers">Def 2.2) Control Lyapunov Function, Set of all stabilizing controllers</h5> <blockquote> <p>A positive definite function $V:D\to \R_{\geq 0}$ is a <strong>Control Lyapunov Function</strong> if it satisfies the following condition</p> <div class="kdmath">$$ \inf_{u\in U}[L_fV(x)+L_gV(x)u]\leq \gamma(V(x)) $$</div> <p>where $\gamma:\R_{\ge0}\to\R_{\ge 0}$ is a class $\mathcal{K}$ function.</p> <p>This definition allows us to define the <strong>set of all valid control inputs</strong> that stabilize the system for every point $x\in D$:</p> <div class="kdmath">$$ K_{\text{clf}}(x):=\{u\in U: L_fV(x)+L_gV(x)u\leq -\gamma(V(x))\}\q\cdots\q(**) $$</div> </blockquote> <blockquote> <p>[!note] Key insight: Affine constraint</p> <p>The inequality in (**) is <strong>affine in $u$</strong>.</p> <ul> <li>This is crucial because it allows us to <strong>formulate the controller synthesis problem as an Optimization Problem</strong> (e.g., Quadratic Program).</li> </ul> </blockquote> <div style="height: 0.1em;"></div> <p><strong>Proposition 2.3) Verification of CLF</strong></p> <blockquote> <p>Suppose that $V$ is a CLF and $U=\R^m$. If $L_gV(x)=0$, i.e. uncontrollable, then $K_\text{clf}(x)\neq \varnothing$.</p> </blockquote> <p><strong>Proof)</strong> Since $V$ is a CLF, this satisfies that</p> <div class="kdmath">$$ \inf_{u\in U}[L_fV(x)+L_gV(x)u]\leq -\gamma(V(x)) $$</div> <p>Here, if $L_gV(x)=0$, then the argument of infimum, $L_fV(x)$, is no longer $u$-dependent and hence</p> <div class="kdmath">$$ \inf_{u\in U}[L_fV(x)]=L_fV(x)\leq -\gamma(V(x)) $$</div> <p>Recall that $K_\text{clf}={u\in U: L_fV(x)+0\cdot u\leq-\gamma(V(x)) }$. Since this inequality is independent of $u$, <strong>any $u$ in the admissible set $U$</strong> satisfies the condition.</p> <p><strong>Here, because we assumed $U = \mathbb{R}^m$ (unconstrained input),</strong> the set $U$ is not empty. Therefore, there exists at least one $u$ (in fact, infinitely many) that satisfies the condition.<span style="float: right;">$\square$</span></p> <p>These arguments can be generalized by the following theorem.</p> <h5 id="thm-23-stabilization-theorem">Thm 2.3) Stabilization Theorem</h5> <blockquote> <p>For the nonlinear control system</p> <div class="kdmath">$$ \dot x=f(x)+g(x)u $$</div> <p>, if there exists a control Lyapunov function $V:D\to\R_{\geq 0}$, then any Lipschitz continuous feedback controller $u(x)\in K_{\text{clf}}(x)$ asymptotically stabilizes the system to $x^*=0$.</p> </blockquote> <div style="height: 0.1em;"></div> <h3 id="22-control-barrier-functions">2.2. Control Barrier Functions</h3> <p>Using control Lyapunov functions as motivation, we wish to generalize to the concept of safety.</p> <p><strong>Q. Can we use Control Lyapunov functions directly for safety?</strong> $\to$ NO.</p> <p>The <strong>“overly restrictive”</strong> issue for BLF again occurs in CLF.</p> <blockquote> <p>[! note] Limitation of CLF</p> <p><strong>- The following argument is almost same to that of BLF.</strong></p> <p>Let $\Omega_c={x(t):V(x(t))\leq c}\subset \mathcal{C}$ is a sublevel set of $V$.</p> <p>Then, by the definition of sublevel set,</p> <ol> <li>$\Omega_{c_1}\subseteq\Omega_{c_2}$ iff $c_1\leq c_2$.</li> <li>$\exists c_{\text{max}}$ s.t. $\Omega_c\subset\Omega_{c_\max}=\mathcal{C}$ for all $c\leq c_\max$ and $\Omega_c\not\subset\mathcal{C}$ for all $c&gt;c_\max$.</li> </ol> <p>Here, let $V(x(0))=c_0$ and hence $x(0)\in\Omega_{c_0}$.</p> <p>If $V$ is a control Lyapunov function, then $\dot V(x(t))\leq -\gamma\left(V(x(t))\right)$ for all $t$ and hence $x(t)\in \Omega_{c_0}$ for all $t$, i.e. $V(x(t))\leq c_0$ for all $t$. So, while this system is obviously safe, but overly conservative.</p> <ul> <li><strong>The Trap</strong>: If the system starts in a “very safe” state where $c_0​\ll c_\max$​, it is mathematically forbidden from moving toward the boundary of $\mathcal{C}$.</li> <li><strong>The Lost Space</strong>: The region $\mathcal{C}\setminus \Omega_{c_0}$​​ becomes “dead space.” Even though these states are safe, the CLF controller will treat them as “forbidden” because reaching them would require $V(x)$ to increase ($\dot V&gt;0$), which is prohibited.</li> </ul> </blockquote> <p>This motivates the formulation of Control Barrier Functions. Let’s begin with a historical remark that motivates the modern definition of CBF.</p> <h5 id="historical-remark-viability-theory">Historical remark: Viability Theory</h5> <ul> <li>The condition for set invariance, $\dot{h}(x) \ge -h(x)$, was proposed in <strong>Viability Theory</strong>.</li> <li>The modern definition of CBF generalizes this by allowing <strong>any extended class $\mathcal{K}_\infty$ function</strong> $\alpha$, offering greater flexibility in designing the convergence rate to the boundary.</li> </ul> <h5 id="def-24-modern-definition-of-control-barrier-functions-set-of-all-safe-controllers">Def 2.4) Modern definition of Control Barrier Functions, Set of all safe controllers</h5> <blockquote> <p>Let $\mathcal{C}\subset D\subset\R^n$ be the superlevel set of a continuously differentiable function $h:D\to \R$, i.e.</p> <div class="kdmath">$$ \mathcal{C}=\{x\in D:h(x)\geq 0\} $$</div> <p>Then, $h$ is called a <strong>control barrier function</strong> if there exists an extended class $\mathcal{K}_\infty$ function $\al$ such that, for the control system $(*)$,</p> <div class="kdmath">$$ \sup_{u\in U}\left[L_fh(x)+L_gh(x)u\right]\geq-\al(h(x)) $$</div> <p>for all $x\in D$.</p> <p>This definition allows us to define the <strong>set of all safe controllers</strong> that render $\mathcal{C}$ safe:</p> <div class="kdmath">$$ K_\text{cbf}(x)=\{u\in U:L_fh(x)+L_gh(x)u+\al h(x)\geq 0\} $$</div> </blockquote> <p>Here,</p> <div class="kdmath">$$ \dot h(x,u)=\frac{\pp h}{\pp x}\frac{dx}{dt}=\frac{\pp h}{\pp x}\left(f(x)+g(x)u\right)=\underbrace{\frac{\pp h}{\pp x}f(x)}_{L_f h(x)}+\underbrace{\frac{\pp h}{\pp x}g(x)}_{L_g h(x)}u=L_fh(x)+L_gh(x)u $$</div> <p>and hence CBF can be rewritten as $\sup_{u\in U}\dot h(x,u)\geq -\al((h(x)))$.</p> <blockquote> <p>[!note] Why $\al$ is extended $\mathcal{K}_\infty$ function?</p> <ol> <li>$\al(0)=0$: Ensures safety at the boundary <ul> <li>Since we have $\dot h(x)\geq-\al(h(x))$ and we need to keep $h(x)\ge0$, we need to force $f$ not to decrease anymore if $h(x)=0$.</li> </ul> </li> <li>$\al$ is strictly increasing: Modulate the allowable decay rate in proportion to the safe margin. <ul> <li>$h(x)\gg 0$(very safe): A large decay is permitted, allowing aggressive maneuvers.</li> <li>$h(x) \to 0$ (approaching danger): The lower bound $-\alpha(h(x))$ approaches zero, forcing the system to “brake” and slow its approach to the boundary.</li> </ul> </li> <li>$\al(r)\to\infty$ as $r\to \infty$: Guarantees global behavior and robustness <ul> <li>Unboundedness: Ensures that for any arbitrarily large safety margin, the control law remains valid and allows for proportionally fast dynamics.</li> </ul> </li> <li>$\al:\R\to\R$: Escaping unsafety (Asymptotic stability) <ul> <li>Since $\alpha$ is defined not only on $\R_{\geq 0}$ but also on $\R_{\leq 0}$ (odd-function-like), if the system is perturbed outside the safe set ($h(x)&lt;0$), then $-\alpha(h(x))$ becomes <strong>positive</strong>. This forces $\dot h(x) &gt; 0$, driving the system <strong>back into the safe set</strong> and hence $\mathcal{C}$ is not only invariant but also asymptotically stable.</li> </ul> </li> </ol> </blockquote> <div style="height: 0.1em;"></div> <blockquote> <p>[! note] First Vs modern definitions of CBF</p> <p><strong>1. First definition: $\dot h(x,u)\geq 0$</strong></p> <p>$\to$ <strong>Requires $h$ to be non-decreasing</strong>, and hence invariance of every level set is forced (overly restrictive).</p> <p><strong>2. Modern definition: $\dot h(x,u)\geq -\al(h(x))$</strong></p> <p>$\to$ <strong>Allows $h$ to decrease</strong> within a bound. This only forces invariance of the zero superlevel set, i.e. safe set $\mathcal{C}$ and hence allows moving freely within the interior (minimally restrictive).</p> </blockquote> <p>As we can see, this definition is quite analogous to that of CLF and set of all stabilizing controllers. So, similar results follows as well.</p> <h5 id="thm-25-safety-guarantee-via-cbfs-sufficiency-for-safety">Thm 2.5) Safety guarantee via CBFs (sufficiency for safety)</h5> <blockquote> <p>Let $\mathcal{C}\subset\R^n$ be a set defined as the superlevel set of a continuously differentiable function $h:D\to\R$. If $h$ is a control barrier function on $D$ and $\frac{\pp h}{\pp x}(x)\neq 0$ for all $x\in\pp C$, then any Lipschitz continuous controller $u(x)\in K_\text{cbf}$ for the system $(*)$ renders the set $\mathcal{C}$ safe. Additionally, the set $\mathcal{C}$ is asymptotically stable in $D$.</p> </blockquote> <h5 id="thm-26-necessity-for-safety">Thm 2.6) Necessity for safety</h5> <blockquote> <p>Let $\mathcal{C}$ be a compact set that is the superlevel set of a continuously differentiable function $h:D\to\R$ where $\frac{\pp h}{\pp x}(x)\neq0$ for all $x\in\pp \mathcal{C}$. If there exists a control law $u=k(x)$ that renders $\mathcal{C}$ safe, i.e. $\mathcal{C}$ is forward invariant with respect to $\dot x=f(x)+g(x)k(x)$, then $h|_\mathcal{C}:\mathcal{C}\to\R$ is a control barrier function on $\mathcal{C}$.</p> </blockquote> <div style="height: 0.1em;"></div> <p>In short,</p> <div class="kdmath">$$ \begin{aligned} \text{Theorem 2.4)}& \q h\; \text{ is CBF } \Longrightarrow u\in K_\text{cbf}\; \text{ makes }\; \mathcal{C}\; \text{safe}. \q\q(\text{Sufficiency})\\ \text{Theorem 2.5)}& \q \exists u\; \text{ makes }\; \mathcal{C}\; \text{ safe } \Longrightarrow h|_\mathcal{C}\; \text{ is CBF} \q\q\q\q(\text{Necessity}). \end{aligned} $$</div> <p>the theorem 2.4 states the sufficient condition for $\mathcal{C}$ to be safe and the theorem 2.5 states the necessary condition for $\mathcal{C}$ to be safe.</p> <div style="height: 0.1em;"></div> <h3 id="23-optimization-based-control">2.3. Optimization Based Control</h3> <p>In the previous section, we’ve observed that CBF provides necessary and sufficient conditions for safety.</p> <p>Then, a natural question arises:</p> <p><strong>Q. How can we incorporate these safety conditions into an existing controller with minimal modification?</strong> $\to$ Optimization based controller</p> <h4 id="231-safety-critical-control">2.3.1. Safety-Critical Control</h4> <p>Suppose that we have a nominal feedback controller $u=k(x)$.</p> <ul> <li><strong>Problem:</strong> While this controller has good performance, <strong>it may not guarantee safety</strong> (i.e. $k(x)\notin K_\text{cbf}$).</li> <li><strong>Objective:</strong> Construct a safe controller $u^*(x)\in K_\text{cbf}$ with performance similar to $k(x)$.</li> </ul> <p>To acheive such a goal, we can construct a QP problem.</p> <blockquote> <p>[!note] Safe-Critical QP (CBF-QP)</p> <div class="kdmath">$$ \begin{aligned} u^*(x) &=\underset{u\in\R^m}{\arg\min} \frac{1}{2}\lnm u-k(x) \rnm^2\\[1.4ex] &\text{s.t.}\q L_fh(x)+L_gh(x)u\geq -\al(h(x)) \end{aligned} $$</div> </blockquote> <p>There are two advantages of this method:</p> <ol> <li><strong>Minimally Invasive:</strong> Since an objective function measures the deivation between nominal controller and new controller that satisfies the safety condition, <ul> <li><strong>Case 1)</strong> If $k(x)\in K_\text{cbf}$, then $u^*(x)=k(x)$ and hence the objective function is zero.</li> <li><strong>Case 2)</strong> If $k(x)\notin K_\text{cbf}$, then $u^*(x)$ is a safe controller that is the closest to $k(x)$.</li> </ul> </li> <li><strong>Closed-form Solution:</strong> Since the constraint is affine in $u$, such QP has a closed form solution and hence applicable to the real-time control.</li> </ol> <h4 id="232-unifying-with-lyapunov">2.3.2. Unifying with Lyapunov</h4> <p>Analogous to the safety-critical control, we can incorporate a control Lyapunov constraint into the QP to guarantee stability.</p> <p><strong>Q. Is the following construction (just add Lyapunov control directly) valid?</strong></p> <div class="kdmath">$$ \begin{aligned} u^*(x) &=\underset{u\in\R^m}{\arg\min} \frac{1}{2}\lnm u-k(x) \rnm^2\\[1.4ex] &\text{s.t.}\q L_fh(x)+L_gh(x)u\geq -\al(h(x))\\ &\text{s.t.}\q L_fV(x)+L_gV(x)u\geq -\gm(V(x)) \end{aligned} $$</div> <p><strong>A. NO. A conflict may arise between safety(CBF) and stability(CLF) constraints</strong>, i.e. such a QP may be infeasible.</p> <p>To resolve this, we need to introduce a relaxation variable $\delta$.</p> <blockquote> <p>[!note] Safety-Stability QP (CBF-CLF QP)</p> <div class="kdmath">$$ \begin{aligned} u^*&(x) =\underset{u\in\R^m}{\arg\min}\left[\frac{1}{2}u^\T H(x) u + p\delta^2\right]\\[1.5ex] &\text{s.t.}\q L_fh(x)+L_gh(x)u\geq -\al(h(x))\\ &\text{s.t.}\q L_fV(x)+L_gV(x)u\geq -\gm(V(x))+\delta \end{aligned} $$</div> <p>where $H(x)$ is any positive definite matrix, $\delta$ is a relaxation variable and $p$ is a penalty coefficient for relaxation.</p> </blockquote> <p>Observe the difference between Safety-critical QP.</p> <ol> <li><strong>Constraint</strong> <ul> <li>As we mentioned above, two constraints may conflict and result in infeasibility.</li> <li>So, by introducing the relaxation variable $\delta$, we can treat the CLF constraint as a <strong>soft</strong> constraint (allow violation).</li> </ul> </li> <li><strong>Objective function</strong> <ul> <li>Unlike the Safety-Critical QP (CBF-QP), the <strong>CLF-CBF QP</strong> explicitly enforces stability through the CLF constraint.</li> <li>Since this constraint directly restricts the feasible set to stabilizing control inputs, <strong>tracking a nominal controller is not required to achieve stability.</strong></li> <li>Therefore, the objective function does not need to include a deviation term $|u - k(x)|^2$ and can instead <strong>focus on minimizing control effort</strong> ($\frac{1}{2}u^T H u$).</li> <li>Also, by introducing the penalizing term $p\delta^2$, we can penalize the over-relaxation and hence <strong>prevents the stability constraint from being excessively violated.</strong></li> </ul> </li> </ol> <div style="height: 0.1em;"></div> <hr/> <h2 id="3-cbf-for-systems-with-actuation-constraints">3. CBF for systems with Actuation Constraints</h2> <h3 id="31-motivation">3.1. Motivation</h3> <p>In the previous section, we’ve established the conditions for the existence of CBFs. However, <strong>is the theoretical CBF always be applicable to the real world?</strong></p> <p>Specifically, most of the actuators have their own <strong>physical limitations</strong> we need to consider when we apply the control inputs to the system.</p> <h5 id="def-31-performance-function-allowable-set">Def 3.1) Performance function, Allowable set</h5> <blockquote> <p>A function $\rho:D\to\R$ is called a <strong>performance function</strong> if it is a continuously differentiable function that defines the <strong>allowable set of states $A$</strong> as its superlevel set, i.e. $A={x\in D:\rho(x)\geq 0}$.</p> </blockquote> <p>Recall the definition of <u>safe set</u>:</p> <div class="kdmath">$$ \mathcal{C}=\{x\in D:h(x)\geq 0\} $$</div> <p>In some ideal cases, it may possible to take $h(x)=\rho(x)$, i.e.</p> <div class="kdmath">$$ \forall x\in A,\;\exists u\in U\q\text{s.t.}\q\dot\rho(x,u)\geq -\al(\rho(x)) $$</div> <p>Then, $\mathcal{C}=A$ and hence $A$ is forward invariant itself as well.</p> <p>However, forward invariance of $A$ cannot be achieved in general because:</p> <blockquote> <p>[!example] Example) Invariance violation of $A$</p> <ul> <li><strong>Case 1) Insufficient actuation limit</strong> <ul> <li> <p>In many cases, $U$ is defined by <span class="kdmath">$U=\{u\in\R^m:\lnm u\rnm\leq u_\max\}$</span></p> </li> <li> <p>$\rho=h$ implies that $\rho$ is CBF and hence $A$ is forward invariant. So, by the definition of the set of all safe controllers, the set of control inputs that render $A$ invariant is</p> </li> </ul> <div class="kdmath">$$ K_{\rho}(x)=\{u\in \R^m: L_f\rho(x)+L_g\rho(x)u\geq-\al(\rho(x))\} $$</div> <ul> <li>However, $K_\rho(x)\cap U=\varnothing$ for some $x\in A$. <ul> <li> <p>Specifically, for $x$ near the boundary of $A$ (i.e. $x$ s.t. $\rho(x)\to 0^+$), for $u$ to make $A$ invariant, $u$ must satisfy</p> <div class="kdmath">$$ L_f\rho(x)+L_g\rho(x)u \geq \underbrace{-\al(\rho(x))\approx0}_{\al \in\\ \text{ extended class}\ \mathcal{K}_\infty} $$</div> </li> <li> <p>In this case, if $L_f\rho(x)\ll 0$, then, there may not exist $u\in U$ s.t. $L_f\rho(x)&lt;L_g\rho(x)u$.</p> </li> </ul> </li> </ul> </li> <li><strong>Case 2) Dynamics with higher relative degree</strong> <ul> <li> <p>Let $\rho(x)$ has a relative degree $r$. If $r\geq 2$, then by the definition of relative degree,</p> <div class="kdmath">$$ \dot\rho(x)=\frac{\pp \rho}{\pp x}(f(x)+g(x)u)=L_f\rho(x)+\underbrace{L_g\rho(x)}_{=\;0}u=L_f\rho(x) $$</div> </li> <li> <p>So, the invariance conditions become state-dependent that is independent of $u$, i.e.</p> <div class="kdmath">$$ L_f\rho(x)\geq -\al(\rho(x)) $$</div> </li> <li> <p>In this case, we cannot choose proper $u\in U$. If the system enters a state $x_0\in A$ where $L_f\rho(x_0)&lt;-\al(\rho(x_0))$, then the condition is violated regardless of the control input.</p> </li> </ul> </li> <li><strong>Case 3) Dynamics with disturbances</strong> <ul> <li> <p>Consider the perturbed system dynamics:</p> <div class="kdmath">$$ \dot x=f(x)+g(x)u+d(t) $$</div> </li> </ul> <p>where $d(t)\in\R^n$ is an unknown disturbance.</p> <ul> <li> <p>Then,</p> <div class="kdmath">$$ \dot \rho(x,u,d)=L_f\rho(x)+L_g\rho(x)u+\frac{\pp\rho}{\pp x}d(t) $$</div> </li> <li> <p>So, even if we choose $u$ satisfying $L_f\rho(x)+L_g\rho(x)u\geq-\al(\rho(x))$, a large negative disturbance can cause the violation, i.e.</p> <div class="kdmath">$$ L_f\rho(x)+L_g\rho(x)u+\frac{\pp\rho}{\pp x}d(t)<-\al(\rho(x)) $$</div> <p>and this forces $A$ is not invariant.</p> </li> </ul> </li> </ul> </blockquote> <p>So, our objective is to construct a CBF $h:D\to\R$ s.t. $\mathcal{C}\subseteq A$.</p> <div style="height: 0.1em;"></div> <h3 id="32-constructing-cbf-considering-actuation-limits">3.2. Constructing CBF considering Actuation limits</h3> <p>First, introduce a definition.</p> <h5 id="def-31-nominal-controller-nominal-trajectory">Def 3.1) Nominal Controller, Nominal Trajectory</h5> <blockquote> <p>Let $D\subset\R^n$ be the set of states and $U\in\R^m$ be the set of admissible control inputs.</p> <p>Here, a <strong>nominal controller</strong> $\be:D\to U$ is a locally Lipschitz function that encapsulates a control strategy intended to keep the system within the allowable set $A$, even if it provides no a priori guarantees of safety.</p> <p>For any $t\geq 0$ and $x\in D$, the <strong>nominal trajectory</strong> $\phi_\be(t,x):\R_{\ge0}\times D\to D$ is defined by the state of the control system $(*)$ at time $t$ when the nominal controller $\be$ is used as input and the system is initialized to $x$.</p> <p>So, $\phi_\be(t,x)$ satisfies</p> <div class="kdmath">$$ \dot\phi_\be(t,x)=f(\phi_\be(t,x))+g(\phi_\be(t,x))\be(\phi_\be(t,x)) $$</div> <p>with initial condition $\phi_\be(0,x)=x$.</p> </blockquote> <blockquote> <p>[!warning] Warning</p> <p><strong>These are NOT general definitions in control theory</strong>. They are just adopted to construct CBF in this context.</p> </blockquote> <div style="height: 0.1em;"></div> <p>Now, the following theorem provides the way to construct a CBF satisfying $\mathcal{C}\subseteq A$.</p> <h5 id="thm-33-cbf-using-nominal-controller">Thm 3.3) CBF using nominal controller</h5> <blockquote> <p>Let $\rho(x)$ be a continuously differentiable performance function with and $A$ is an allowable set corresponds to $\rho$. Also, let $\be(x)$ be a nominal controller s.t. $f(x)+g(x)\be(x)$ is continuously differentiable.</p> <p>Define $h:D\to\R$ as</p> <div class="kdmath">$$ h(x):=\inf_{\tau\in[0,\infty)}\rho(\phi_\be(\tau,x)) $$</div> <p>and define $\mathcal{C}:={x\in D:h(x)\geq 0}$.</p> <p>Suppose that for each $x$ there exists a unique $x^*$ s.t. $h(x)=\rho(x^*)$ and $\phi_\be(\tau,x)=x^*$ for some $\tau\geq 0$. Then,</p> <ol> <li>$h$ is a CBF.</li> <li>$\mathcal{C}\subseteq A$.</li> <li>$\be(x)\in K_\text{cbf}(x)$ for all $x\in\mathcal{C}$.</li> </ol> </blockquote> <div style="height: 0.1em;"></div> <h3 id="33-numerical-implementation">3.3. Numerical Implementation</h3> <p>Note that we’re discussing about the <strong>‘real-world’ application</strong> and hence we need to consider the way to <strong>compute in practice</strong>.</p> <blockquote> <p>[!abstract] Q. How to compute $h$ in theorem 3.3 in practice?</p> <ul> <li>In some cases, it is possible to compute $h$ in <strong>closed form</strong>.</li> <li>If it is not possible, we need to approximate $h$ by <strong>simulating the system trajectory for a finite horizon and compute the infimum numerically.</strong> <ul> <li>However, as we observed in CBF-QP, we need to compute the gradient of $h$ to utilize $h$ in QP problem that requires <strong>huge computational burden as the dimension of the system grows.</strong></li> </ul> </li> </ul> </blockquote> <p>To overcome this issue, another approach is introduced.</p> <h5 id="def-34-sos-polynomial">Def 3.4) SOS polynomial</h5> <blockquote> <p>A polynomial $s(x)$ is called a sums of squares (SOS) polynomial if there exists a family of polynomials ${g_i(x)}_{i\in [r]}$ s.t.</p> <div class="kdmath">$$ s(x)\sum_{i= 1}^r(g_i(x))^2 $$</div> <p>Also, $\Sigma[x]$ denotes the set of all SOS polynomials.</p> </blockquote> <p>Using this definition, we can compute $h$ by parametrizing $h$ as fixed degree polynomial and use SOS programming to enforce the required conditions on $h$.</p> <h5 id="prop-35-polynomial-cbf-synthesis-via-sos">Prop 3.5) Polynomial CBF Synthesis via SOS</h5> <blockquote> <p>Given the control system $(*)$, assume both $f(x)$ and $g(x)$ are polynomials. Let $\rho(x)$ be a polynomial performance function and let $\be(x)$ be a polynomial nominal controller.</p> <p>A polynomial $h(x)$ is a CBF if there exists positive constants $a&gt;0$, $\varepsilon&gt;0$ and SOS polynomials $s_1(x),s_2(x)$ s.t.</p> <div class="kdmath">$$ \begin{aligned} -h(x)-\varepsilon+s_1(x)\rho(x)\in\Sigma[x]\q&\cdots\q (1)\\[1.3ex] L_fh(x)+L_gh(x)\be(x)+ah(x)-s_2(x)h(x)\in\Sigma[x]\q&\cdots\q (2) \end{aligned} $$</div> <p>Moreover, $\mathcal{C}\subseteq A$ and $\be(x)\in K_\text{cbf}$ for all $x\in\mathcal{C}$.</p> </blockquote> <blockquote> <p>[!note] Q. What are the equations $(1)$ and $(2)$ mean?</p> <p><strong>Claim 1:</strong> If $(1)$, then $\mathcal{C}\subset A$.</p> <p><strong>Proof)</strong> Suppose that $-h(x)-\varepsilon+s_1(x)\rho(x)\in\Sigma[x]$. Then, $\exists\sigma(x)\in\Sigma[x]$ s.t.</p> <div class="kdmath">$$ -h(x)-\varepsilon+s_1(x)\rho(x)=\sigma(x) $$</div> <p>Since $\sigma(x)$ is SOS, $\sigma(x)\geq 0$ for all $x\in D$ and hence we have</p> <div class="kdmath">$$ -h(x)-\varepsilon+s_1(x)\rho(x)=\sigma(x)\geq 0\\[1.2ex] $$</div> <p>By arranging terms properly,</p> <div class="kdmath">$$ h(x)\leq s_1(x)\rho(x)-\varepsilon-\sigma(x) $$</div> <p>and since $s_1(x)$ is SOS, $s_1(x)\geq 0$ for all $x\in D$ and hence $h(x)&lt;0$ if $\rho(x)&lt;0$.</p> <p>Here, $\rho(x)&lt;0$ and $h(x)&lt;0$ implies that $x\notin A$ and $x\notin \mathcal{C}$, respectively and hence we can conclude that if $(1)$ is true, then $D\setminus A\subseteq D\setminus\mathcal{C}$.</p> <p>By taking complement, $\mathcal{C}\subseteq A$.<span style="float: right;">$\square$</span></p> <hr/> <p><strong>Claim 2:</strong> If $(2)$, then $\be(x)\in K_\text{cbf}(x)$.</p> <p><strong>Proof)</strong> Suppose that $L_fh(x)+L_gh(x)\be(x)+ah(x)-s_2(x)h(x)\in\Sigma[x]$, i.e. $\exists\sigma(x)\in\Sigma[x]$ s.t.</p> <div class="kdmath">$$ \underbrace{L_fh(x)+L_gh(x)\be(x)}_{\dot h(x,\be(x))}+\underbrace{ah(x)}_{\al(h(x))}-\underbrace{s_2(x)h(x)}_{\text{relaxation}}=\sigma(x)\geq 0 $$</div> <p>Here, as we can see above,</p> <ul> <li>The first two terms $L_fh(x)+L_gh(x)\be(x)$ is the time derivative of $h$ when the nominal controller $\be(x)$ is applied, i.e. $\dot h(x,\be(x))$.</li> <li>The third term $ah(x)$ is $\al(h(x))$ where $\al(\cdot)\in\mathcal{K}_\infty$ is linear, i.e. $\al(s)=as$.</li> <li>Since $s_2(x)$ is SOS, $s_2(x)\geq 0$ for all $x\in D$ and hence the fourth term $s_2(x)h(x)\geq 0$ for all $x\in\mathcal{C}$. So, this can be utilized as a relaxation term.</li> </ul> <p>So, for all $x\in\mathcal{C}$, since both $s_2(x)h(x)$ and $\sigma(x)$ are nonnegative,</p> <div class="kdmath">$$ L_fh(x)+L_gh(x)\be(x)+ah(x)\geq s_2(x)h(x)+\sigma(x)\geq 0 $$</div> <p>and hence</p> <div class="kdmath">$$ L_fh(x)+L_gh(x)\be(x)\geq -ah(x) $$</div> <p>This implies that $h$ is CBF and $\be(x)\in K_\text{cbf}(x)$.<span style="float: right;">$\square$</span></p> </blockquote> <p>In short,</p> <ul> <li>Theorem 3.3 constructively provides the theoretical existence of CBF.</li> <li>Proposition 3.5 provides the way to compute the CBF constructed in theorem 3.3.</li> </ul> <p>However, there is one more problem left.</p> <p>While SDP solvers can only deal with “Linear” constraints, the SOS constraints in the method proposed in proposition 3.5 are <strong>“Bilinear”</strong>(observe $ah(x)$ and $s_2(x)h(x)$).</p> <p>So, to bypass this issue, an iterative procedure is required to <strong>decouple</strong> the decision variables.</p> <blockquote> <p>[!note] Two-step alternating optimization</p> <ul> <li> <p><strong>Phase 1: Fix $h(x)$ and solve for a and $s_2(x)$</strong>  By treating the polynomial $h(x)$ as a fixed constant from a previous guess or iteration, the constraints $(1)$ and $(2)$ become linear with respect to the remaining decision variables $a$,$s_1​(x)$, and $s_2​(x)$.</p> </li> <li> <p><strong>Phase 2: Fix a and $s_2​(x)$ and solve for $h(x)$</strong>  Once $a$ and $s_2​(x)$ are determined, they are held constant. The solver then searches for a new polynomial $h(x)$ and $s_1​(x)$ that satisfy the SOS conditions. This phase is often used to <strong>maximize the volume</strong> of the safe set $\mathcal{C}$.</p> </li> </ul> </blockquote> <ul> <li>This approach transforms a complex, non-convex problem into a <strong>sequence of convex SDPs</strong> that can be solved efficiently using toolboxes. </li> <li>This iterative “search” eventually <strong>converges to a valid CBF</strong> $h(x)$ that ensures the safe set $\mathcal{C}$ remains within the allowable region $A$ while being compatible with a nominal controller $\be(x)$.</li> </ul> <div style="height: 0.1em;"></div> <hr/> <h2 id="4-exponential-control-barrier-functions">4. Exponential Control Barrier Functions</h2> <div style="height: 0.1em;"></div> <p><strong>Motivation</strong></p> <p>While CBFs offer a powerful methodology, the safety-critical constraints have been so far assumed to be of relative degree one.</p> <p>To overcome this issue, we’ll introduce <strong>Exponential CBFs</strong> that allows for us to ==deal with arbitrarily high relative degree safety constraints.==</p> <h3 id="41-high-relative-degree-safety-constraints">4.1. High Relative-Degree Safety Constraints</h3> <div style="height: 0.1em;"></div> <p>First, recall the definition relative degree.</p> <blockquote> <p>Given a CBF $h(x,u)$, its $k^\th$ derivative be</p> <div class="kdmath">$$ h^{(k)}(x,u)=L_f^k h(x)+L_gL_f^{k-1}h(x)u $$</div> <p>In this context, $h(x,u)$ is said to have relative degree $r$ if</p> <div class="kdmath">$$ \begin{aligned} L_gL_f^{k-1}h(x)&=0,\q\forall k\in\{0,1,\cdots, r-2\}\\ L_gL_f^{r-1}h(x)&\neq0 \end{aligned} $$</div> </blockquote> <p>Using this definition, prepare some critical setup for defining Exponential CBF.</p> <blockquote> <p>[!note] Setup for Exponential CBF</p> <p><strong>Claim:</strong> Here, by defining a barrier state vector corresponding to a CBF $h(x,u)$ with relative degree $r$ by</p> <div class="kdmath">$$ \eta_b(x):= \begin{bmatrix} h(x) \\ \dot h(x) \\ \ddot h(x) \\ \vdots \\ h^{(r-1)}(x) \end{bmatrix}= \begin{bmatrix} h(x) \\ L_f h(x) \\ L_f^2 h(x) \\ \vdots \\ L_f^{(r-1)} h(x) \end{bmatrix}\in\R^r $$</div> <p>and letting $\mu:=h^{(r)}(x,u)=L_f^{r}h(x)+L_gL_f^{r-1}h(x)u$, we can obtain a system of first-order differential equations</p> <div class="kdmath">$$ \begin{aligned} \dot\eta_b(x)&=F\eta_b(x)+G\mu\\[1.2ex] h(x)&=C\eta_b(x) \end{aligned} $$</div> <p>where</p> <div class="kdmath">$$ F=\left[\; \begin{array}{c|c} \mathbf{0}_{r-1} & I_{r-1}\\[1.05ex] \hline 0 & \mathbf{0}^\T_{r-1} \end{array}\; \right]\in\R^{r\times r},\q G= \begin{bmatrix} \mathbf{0}_{r-1} \\ 1 \end{bmatrix}\in\R^r,\q C= \begin{bmatrix} 1 & \mathbf{0}_{r-1}^\T \end{bmatrix}\in\R^{r} $$</div> <p>Also, by assuming a state-feedback controller $\mu=-K_\al\eta_b(x)$, then we</p> <div class="kdmath">$$ h(x(t))=Ce^{(F-GK_\al)}\eta_b(x_0) $$</div> <hr/> <p><strong>Proof)</strong> First, by multiplying two matrices,</p> <div class="kdmath">$$ F\eta_b(x) =\left[ \begin{array}{c|cccc} 0 & 1 & 0 & \cdots & 0 \\ 0 & 0 & 1 & \cdots & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & 0 & \cdots & 1 \\ \hline 0 & 0 & 0 & \cdots & 0 \end{array} \right] \begin{bmatrix} h(x) \\ \dot h(x) \\ \ddot h(x) \\ \vdots \\ h^{(r-1)}(x) \end{bmatrix}= \begin{bmatrix} \dot h(x) \\ \ddot h(x) \\ \vdots \\ h^{(r-1)}(x) \\ 0 \end{bmatrix} $$</div> <p>So,</p> <div class="kdmath">$$ \dot\eta_b(x)= \begin{bmatrix} \dot h(x) \\ \ddot h(x) \\ \vdots \\ h^{(r-1)}(x) \\ h^{(r)}(x) \end{bmatrix}= \underbrace{ \begin{bmatrix} \dot h(x) \\ \ddot h(x) \\ \vdots \\ h^{(r-1)}(x) \\ 0 \end{bmatrix}}_{F\eta_b(x)}+ \underbrace{ \begin{bmatrix} 0 \\ 0 \\ \vdots \\ 0 \\ h^{(r)}(x) \end{bmatrix}}_{G\mu} =F\eta_b(x)+G\mu $$</div> <p>Here, recall that</p> <div class="kdmath">$$ h^{(r)}(x,u)=L_f^rh(x)+L_gL_f^{r-1}h(x)u\overset{\text{let}}{=}:\mu $$</div> <p>Assume that we apply state-feedback controller, i.e. $\mu=-K_\al\eta_b(x)$. By substituting this to the system of first-order differential equations, we obtain</p> <div class="kdmath">$$ \begin{aligned} \dot\eta_b(x)&=F\eta_b(x)+G(-K_\al\eta_b(x))\\[1.2ex] &=(F-GK_\al)\eta_b(x) \end{aligned} $$</div> <p>Here, $\dot\eta_b(x)=(F-GK_\al)\eta_b(x)$ is just a simple linear LTI first-order ODE of the form $\dot x=Ax$ and hence</p> <div class="kdmath">$$ \eta_b(x(t))=\eta_b(x_0)e^{(F-GK_\al)t} $$</div> <p>Therefore, since $h(x(t))=C\eta_b(x)$,</p> <div class="kdmath">$$ h(x(t))=C\eta_b(x_0)e^{(F-GK_\al)t} $$</div> <p>Moreover, by the comparison lemma, if $\mu\geq -K_\al\eta_b(x)$, then $h(x(t))\geq Ce^{(F-GK_\al)}\eta_b(x_0)$. <span style="float: right;">$\square$</span></p> </blockquote> <p>We now can define exponential CBF.</p> <h5 id="def-41-exponential-control-barrier-function">Def 4.1) Exponential Control Barrier Function</h5> <blockquote> <p>Given a set $\mathcal{C}\subset D\subset\R^n$ defined by</p> <div class="kdmath">$$ \mathcal{C}:=\{x\in D:h(x)\geq 0\} $$</div> <p>where $h:D\to\R$ is $C^r$ function, then $h$ is called an <strong>exponential control barrier function</strong> if there exists a row vector $K_\al\in\R^r$ s.t. for control system $\dot x=f(x)+g(x)u$,</p> <div class="kdmath">$$ \sup_{u\in U}\left[L_f^rh(x)+L_gL_f^{r-1}h(x)u\right]\geq-K_\al\eta_b(x)\q\forall x\in \text{Int}\ \mathcal{C} $$</div> <p>results in $h(x(t))\geq Ce^{(F-GK_\al)t}\eta_b(x_0)\geq 0$ whenever $h(x_0)\geq 0$.</p> </blockquote> <p>Intuitively, this implies that the actual input $\mu$ is greater than the assumed state feedback $-K_\al\eta_b(x)$, i.e.</p> <div class="kdmath">$$ \underbrace{L_f^rh(x)+L_gL_f^{r-1}h(x)u}_{\text{actual input}}\geq\underbrace{-K_\al\eta_b(x)}_{\text{reference input}} $$</div> <p>Now, recall the motivation of ECBF: $\to$ Generalize the definition of CBF to the systems with higher relative degree.</p> <p><strong>Q. Is this definition properly generalizes the definition of CBF?</strong></p> <blockquote> <p>[!note] ECBF generalizes CBF</p> <p>By letting $r=1$, then $\eta_b(x)=h(x)$ and hence</p> <div class="kdmath">$$ \mu=-K_\al\eta_b(x)=-K_\al h(x)=-\al(h(x)) $$</div> <p>where $\al(s)=K_\al s\in\text{class }\mathcal{K}_\infty$.</p> </blockquote> <p>Moreover, ECBF can be directly incorporated to the optimization-based control instead of CBF.</p> <blockquote> <p>[!note] CLF-ECBF QP</p> <div class="kdmath">$$ \begin{aligned} u(x)= \operatorname*{argmin}_{(u,\mu,\de)\in\R^{m+2}} & \frac{1}{2}u^\T H(x)u+p\delta^2\\[1.2ex] \text{s.t.}\q & L_fV(x)+L_gV(x)u\leq -\gamma(V(x))+\delta\\[1.1ex] & L_f^rh(x)+L_gL_f^{r-1}h(x)u=\mu\\[1.1ex] & \mu\geq -K_\al\eta_b(x) \end{aligned} $$</div> </blockquote> <div style="height: 0.1em;"></div> <h3 id="42-designing-exponential-control-barrier-functions">4.2. Designing Exponential Control Barrier Functions</h3> <p>Observe that the dynamics</p> <div class="kdmath">$$ \begin{aligned} \dot\eta_b(x)&=F\eta_b(x)+G\mu\\[1.2ex] h(x)&=C\eta_b(x) \end{aligned} $$</div> <p>is the <strong>controllable canonical form</strong>. So, by letting $K_\al=\begin{bmatrix}\al_1 &amp; \al_2 &amp; \cdots &amp; \al_r\end{bmatrix}$, we can obtain</p> <div class="kdmath">$$ F-GK_\al= \begin{bmatrix} 0 & 1 & 0 & \cdots & 0 \\ 0 & 0 & 1 & \cdots & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & 0 & \cdots & 1 \\ -\al_1 & -\al_2 & -\al_3 & \cdots & -\al_r \end{bmatrix} $$</div> <p>and hence the characteristic polynomial of $F-GK_\al$ be</p> <div class="kdmath">$$ \lambda^r+\al_r\lambda^{r-1}+\cdots+\al_2\lambda+\al=0 $$</div> <p>Here, suppose that such a polynomial be factored as</p> <div class="kdmath">$$ (\lambda+p_1)(\lambda+p_2)\cdots(\lambda+p_r)=0, $$</div> <p>i.e. $-p_1,\cdots, -p_r$ are the eigenvalues(poles) of the closed-loop system.</p> <p>Next, define an auxiliary family of function ${\nu_i}_{i\in I}$ where $\nu_i:D\to\R$ for all $i\in I$ and their corresponding superlevel sets $\mathcal{C}_i={x\in D:\nu_i(x)\geq 0}$ as follows.</p> <div class="kdmath">$$ \begin{aligned} \nu_0(x)&=h(x);\qquad\q\q\q\q\;\;\;\q\;\;\mathcal{C}_0=\{x\in D:\nu_0(x)\geq 0\}=\mathcal{C}\\[1.1ex] \nu_1(x)&=\dot\nu_0(x)+p_1\nu_0(x);\qquad\q\;\;\mathcal{C}_1=\{x\in D:\nu_1(x)\geq 0\}\\[1.1ex] &\;\;\vdots\qquad\qquad\qquad\qquad\qquad\qquad\;\;\; \vdots \\[1.1ex] \nu_r(x)&=\dot\nu_{r-1}(x)+p_r\nu_{r-1}(x);\qquad\mathcal{C}_r=\{x\in D:\nu_r(x)\geq 0\} \end{aligned} $$</div> <p>Our goal is to design $K_\al$ to ensure $\mathcal{C}$ is forward invariant.</p> <p>First, begin with the following basic and straightforward result.</p> <h5 id="prop-42-recursive-invariance-of-auxiliary-safe-sets">Prop 4.2) Recursive Invariance of Auxiliary safe sets</h5> <blockquote> <p>For a given $i\in [r]$, if $\mathcal{C}_i$ is forward invariant, then $\mathcal{C}_{i-1}$ is forward invariant whenever $p_i&gt;0$ and $x_0\in\mathcal{C}_i\cap\mathcal{C}_{i-1}$.</p> </blockquote> <p><strong>Proof)</strong> Since $\mathcal{C}_i$ is forward invariant, for a given $x_0\in\mathcal{C}_i\cap\mathcal{C}_{i-1}$, $x(t)\in\mathcal{C}_i$ for all $t\in[0,\infty)$, i.e.</p> <div class="kdmath">$$ \nu_i(x(t))\geq 0,\q\forall t\in[0,\infty) $$</div> <p>By the definition of $\nu_i(x)$,</p> <div class="kdmath">$$ \nu_i(x)=\dot\nu_{i-1}(x)+p_i\nu_{i-1}(x)\geq 0 $$</div> <p>This implies that for $x\to\pp\mathcal{C}_{i-1}$, i.e. $\nu_{i-1}(x)\to 0^+$, then</p> <div class="kdmath">$$ \nu_i(x)=\dot\nu_{i-1}(x)+\underbrace{p_i\nu_{i-1}(x)}_{\to\; 0^+}\approx\dot\nu_{i-1}(x)\geq 0 $$</div> <p>Thus, $\mathcal{C}_{i-1}$ is forward invariant as well. <span style="float: right;">$\square$</span></p> <div style="height: 0.1em;"></div> <p>From such a proposition, ==<strong>inductively</strong>==, we can obtain the following result directly.</p> <h5 id="thm-43-safety-guarantee">Thm 4.3) Safety Guarantee</h5> <blockquote> <p>If $\mathcal{C}_r$ is forward invariant and $x_0\in\bigcap_{i=0}^r\mathcal{C}_i$, then $\mathcal{C}$ is forward invariant.</p> </blockquote> <div style="height: 0.1em;"></div> <p>So far, we’ve observed that two conditions are required for invariance of $\mathcal{C}$.</p> <ol> <li>$p_i&gt;0$ for each $i\in [r]$</li> <li>$x_0\in \mathcal{C}_i$ for each $i\in [r]$</li> </ol> <p>Q. What is the meaning of these conditions?</p> <blockquote> <p>[!note] Meaning of these conditions</p> <p><strong>1. $p_i&gt;0$ for each $i\in[r]$</strong></p> <p>$\to$ As we assumed that $-p_i$ are the poles of a closed-loop system, $F-GK_\al$ be Hurwitz with totally negative, i.e. each eigenvalue of $F-GK_\al$ is negative real. This makes ==a closed-loop system converges without oscillation(overdamped).== (While underdamping system converges to the objective state, it may violate the safety condition because of oscillation.)</p> <p><strong>2. $x_0\in \mathcal{C}_i$ for each $i\in[r]$</strong></p> <p>$\to$ Since $x_0\in\mathcal{C}_i$ implies $\nu_i(x_0)=\dot\nu_{i-1}(x_0)+p_i\nu_{i-1}(x)\geq 0$, we obtain the lower bound for $p_i$.</p> <div class="kdmath">$$ p_i\geq-\frac{\dot\nu_{i-1}(x_0)}{\nu_{i-1}(x_0)} $$</div> <p>This provides the condition for $p_i$ corresponds to $x_0$ that means ==the required response rate depends on $x_0$.==</p> </blockquote> <p>Finally, we can guarantee the existence of ECBF using these conditions.</p> <h5 id="thm-44-conditions-for-choosing-proper-gain-matrix">Thm 4.4) Conditions for choosing Proper gain matrix</h5> <blockquote> <p>Suppose $K_\al$ is chosen s.t. $F-GK_\al$ is Hurwitz and total negative(resulting in negative real poles) and the eigenvalues satisfy</p> <div class="kdmath">$$ \lambda_i(F-GK_\al)\geq -\frac{\dot\nu_{i-1}(x_0)}{\nu_{i-1}(x_0)}, $$</div> <p>then $\mu\geq -K_\al\eta_b(x)$ guarantees $h(x)$ is an exponential CBF.</p> </blockquote> <p>This theorem provides a sufficient conditions for the existence of ECBF, i.e.</p> <div class="kdmath">$$ K_\al\text{ satisfies theorem 4.4 }\Longrightarrow\; h(x)\text{ be ECBF if }\;\mu\geq-K_\al\eta_b(x_0) $$</div>]]></content><author><name></name></author><category term="study"/><category term="CBF"/><category term="Lyapunov"/><summary type="html"><![CDATA[Introduction to Control Barrier Functions and Safety Control]]></summary></entry><entry><title type="html">Jacobi &amp;amp; Gauss-Seidel Method</title><link href="https://adobby77.github.io/study/2025/Jacobi-Gauss-Seidel-method/" rel="alternate" type="text/html" title="Jacobi &amp;amp; Gauss-Seidel Method"/><published>2025-09-13T03:00:00+00:00</published><updated>2025-09-13T03:00:00+00:00</updated><id>https://adobby77.github.io/study/2025/Jacobi-Gauss-Seidel-method</id><content type="html" xml:base="https://adobby77.github.io/study/2025/Jacobi-Gauss-Seidel-method/"><![CDATA[<h2 id="0-introduction">0. Introduction</h2> <p>Jacobi method and Gauss-Seidel method are <strong>classical iterative algorithms to determine the approximate solutions of a large-scale system of linear equations.</strong> They are particularly useful when finding a direct solution by Gaussian elimination is impractical or computationally expensive. They computes the iterative solution from the initial guess until it converges to the exact solution within a desired tolerance.</p> <p>The fundamental difference between them is the way they utilize information during the process. <strong>The Jacobi method computes a new set of values for the solution vector using only the values from the previous iteration.</strong> In contrast, <strong>the Gauss-Seidel method immediately use the most recently computed values from the current iteration in subsequent calculations within that same step.</strong> While the Jacobi method is more convenient to formulate the problem in a parallel manner, the Gauss-Seidel method converges faster than the Jacobi method.</p> <div style="height: 0.1em;"></div> <hr/> <h2 id="1-problem-formulation">1. Problem formulation</h2> <blockquote> <p>[!note] Problem formulation</p> <p><strong>Solve</strong> $Ax=b$ where $A\in\mathbb{R}^{n\times n}$, $x, b\in\mathbb{R}^n$</p> <div class="kdmath">$$ A=\begin{bmatrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{n2}\\ \vdots & \vdots & \ddots & \vdots\\ a_{n1} & a_{n2} & \cdots & a_{nn} \end{bmatrix} ,\quad b=\begin{bmatrix} b_1\\ b_2\\ \vdots\\ b_n \end{bmatrix} \quad\text{and}\quad x=\begin{bmatrix} x_1\\ x_2\\ \vdots\\ x_n \end{bmatrix} $$</div> <p>From a different point-of view, solving $Ax=b$ is equivalent to minimizing $\lVert Ax-b \rVert$. We can generalize this algorithm to the general optimization problem.</p> </blockquote> <hr/> <h2 id="2-algorithms">2. Algorithms</h2> <div style="height: 0.1em;"></div> <h3 id="21-the-jacobi-method">2.1. The Jacobi method</h3> <p>Separate $A$ into 3 parts, i.e. $A=D+L+U$ where $D$ is diagonal, $L$ is strictly lower triangular, $U$ is strictly upper triangular parts of $A$.</p> <p>Then, we have $(D+L+U)x=b$ and hence</p> <blockquote> <p>[!algorithm] Jacobi Method</p> <div class="kdmath">$$ \begin{aligned} Dx + (L+U)x = b& && \text{(given)}\\[2pt] Dx = b - (L+U)x& && \text{(move $(L+U)x$)}\\[2pt] x = D^{-1}\!\bigl(b-(L+U)x\bigr)& && \text{(left-multiply $D^{-1}$)} \end{aligned} $$</div> </blockquote> <p>So, from our initial guess $x^{(0)}$, we can update $x$ using such an iterative algorithm.</p> <div class="kdmath">$$ x^{(k+1)}=D^{-1}(b-(L+U)x^{(k)}) $$</div> <p>The decomposed matrices are</p> <div class="kdmath">$$ D=\begin{bmatrix} a_{11} & 0 & \cdots & 0 \\ 0 & a_{22} & \cdots & 0\\ \vdots & \vdots & \ddots & \vdots\\ 0 & 0& \cdots & a_{nn} \end{bmatrix},\quad U=\begin{bmatrix} 0 & a_{12} & \cdots & a_{1n} \\ 0 & 0 & \cdots & a_{2n}\\ \vdots & \vdots & \ddots & \vdots\\ 0 & 0 & \cdots & 0 \end{bmatrix},\quad L=\begin{bmatrix} 0 & 0 & \cdots & 0 \\ a_{21} & 0 & \cdots & 0\\ \vdots & \vdots & \ddots & \vdots\\ a_{n1} & a_{n2} & \cdots & 0 \end{bmatrix} $$</div> <p>and hence</p> <div class="kdmath">$$ D^{-1}=\begin{bmatrix} \frac{1}{a_{11}} & 0 & \cdots & 0 \\ 0 & \frac{1}{a_{22}} & \cdots & 0\\ \vdots & \vdots & \ddots & \vdots\\ 0 & 0& \cdots & \frac{1}{a_{nn}} \end{bmatrix},\quad L+U=\begin{bmatrix} 0 & a_{12} & \cdots & a_{1n} \\ a_{21} & 0 & \cdots & a_{2n}\\ \vdots & \vdots & \ddots & \vdots\\ a_{n1} & a_{n2} & \cdots & 0 \end{bmatrix},\quad $$</div> <p>Thus, we can rewrite the update equation in terms of elements like:</p> <div class="kdmath">$$ x_i^{(k+1)}=\frac{1}{a_{ii}}\left(b-\sum_{j\neq i}a_{ij}x_j^{(k)}\right), \quad\forall i. $$</div> <div style="height: 0.1em;"></div> <hr/> <h3 id="22-the-gauss-seidel-method">2.2. The Gauss-Seidel method</h3> <p>Same to the Jacobi method, separate $A$ into 3 parts, i.e. $A=D+L+U$ where $D$ is diagonal, $L$ is strictly lower triangular, $U$ is strictly upper triangular parts of $A$.</p> <p>Then, we have $(D+L+U)x=b$ and hence</p> <blockquote> <p>[!algorithm] Gauss-Seidel Method</p> <div class="kdmath">$$ \begin{aligned} (D + L)x+Ux = b& && \text{(given)}\\[2pt] (D+L)x = b - Ux& && \text{(move $Ux$)}\\[2pt] x = (D+L)^{-1}(b-Ux)& && \text{(left-multiply $(D+L)^{-1}$)} \end{aligned} $$</div> </blockquote> <p>So, from our initial guess $x^{(0)}$, we can update $x$ using such an iterative algorithm.</p> <div class="kdmath">$$ x^{(k+1)}=(D+L)^{-1}(b-Ux^{(k)}) $$</div> <p>The decomposed matrices are</p> <div class="kdmath">$$ D+L=\begin{bmatrix} a_{11} & 0 & \cdots & 0 \\ a_{21} & a_{22} & \cdots & 0\\ \vdots & \vdots & \ddots & \vdots\\ a_{n1} & a_{n2} & \cdots & a_{nn} \end{bmatrix},\quad U=\begin{bmatrix} 0 & a_{12} & \cdots & a_{1n} \\ 0 & 0 & \cdots & a_{2n}\\ \vdots & \vdots & \ddots & \vdots\\ 0 & 0 & \cdots & 0 \end{bmatrix} $$</div> <p>and hence the element-based formula is</p> <div class="kdmath">$$ x_i^{(k+1)}=\frac{1}{a_{ii}}\left(b_i-\sum_{j=1}^{i-1}a_{ij}x_j^{(k+1)}-\sum_{j=i+1}^na_{ij}x_j^{(k)}\right) $$</div> <hr/> <p>As we can see, both algorithms require <strong>central factors</strong> and hence not applicable to the fully deectralized optimization problems.</p> <div style="height: 0.1em;"></div> <h2 id="3-convergence">3. Convergence</h2> <h3 id="31-preliminaries">3.1. Preliminaries</h3> <h5 id="def-31-spectral-radius">Def 3.1) Spectral radius</h5> <blockquote> <p>For a square matrix $A\in\mathbb{C}^{n\times n}$, the spectral radius of $A$ is the maximum value of the absolute values of its eigenvalues and denoted by $\rho(A)$.</p> <div class="kdmath">$$ \rho(A)=\max\{|\lambda_1|,\cdots,|\lambda_n|\} $$</div> </blockquote> <div style="height: 0.1em;"></div> <h5 id="lem-32-relationship-between-norm-and-spectral-radius">Lem 3.2) Relationship between Norm and Spectral Radius</h5> <blockquote> <p>For any matrix $T\in\mathbb{C}^{n \times n}$ and any $\epsilon &gt; 0$, there exists a subordinate matrix norm $\lnm\cdot\rnm$ such that:</p> <div class="kdmath">$$ \left\lVert T\right\rVert \le \rho(T) + \epsilon $$</div> </blockquote> <div style="height: 0.1em;"></div> <h5 id="def-33-diagonally-dominant-matrix">Def 3.3) Diagonally Dominant matrix</h5> <blockquote> <p>A square matrix $A\in\mathbb{C}^{n\times n}$ is said to be diagonally dominant if for every row of matrix, the magnitude of the diagonal entry in a row is greater than or equal to the sum of magnitudes of all the off-diagonal entries in that row.</p> <div class="kdmath">$$ |a_{ii}|\geq\sum_{j\neq i}|a_{ij}|, \quad\forall i $$</div> </blockquote> <div style="height: 0.1em;"></div> <h5 id="thm-34-gershgorins-circle-theorem">Thm 3.4) Gershgorin’s Circle Theorem</h5> <blockquote> <p>Let A be a square matrix $A\in\mathbb{C}^{n\times n}$ with entries $a_{ij}$. For $i=1,\cdots,n$, let $R_i$ be the sum of the absolute values of the off-diagoonal entries in the $i^\textrm{th}$ row, i.e. $R_i=\sum_{j\neq i}|a_{ij}|$. Then, <strong>a closed disc centered at $a_{ii}$ with radius $R_i$ in the complex plane is called a Gershgorin disc</strong>, which is denoted by $D(a_{ii},R_i)\subset\mathbb{C}$ .</p> <p>Then, <strong>every eigenvalue of $A$ lies within at least one of the Gershgorin discs $D(a_{ii}, R_i)$.</strong> In other words, <strong>every eigenvalue of $A$ is in the union of the Gershgorin discs, i.e. $\lambda(A)\in\bigcup_iD(a_ii,R_i)$.</strong></p> </blockquote> <div style="height: 0.1em;"></div> <p><strong>Proof.</strong> Let $\lambda$ be the eigenvalue of $A$ and $x$ be the eigenvector corresponds to $\lambda$, i.e. $Ax=\lambda x$.</p> <p>Let $x_{j^*}$ be the element whose magnitude is the largest among the elements of $x$, i.e.</p> <div class="kdmath">$$ |x_{i}|=\max_{j}|x_j| $$</div> <p>Since $x\neq 0,\; \left\vert x_i\right\vert&gt;0$.</p> <p>Now, from the equation $Ax=\lambda x$, observe the $i^{\textrm{th}}$ row only.</p> <div class="kdmath">$$ \lambda x_i=\sum_{j}a_{ij}\frac{x_j}{x_i} $$</div> <p>and hence</p> <div class="kdmath">$$ \lambda-a_{ii}=\sum_{j\neq i}a_{ij}\frac{x_j}{x_i} $$</div> <p>Take absolute value</p> <div class="kdmath">$$ |\lambda-a_{ii}|=\left|\sum_{j\neq i}a_{ij}\frac{x_j}{x_i}\right| $$</div> <p>By triangle inequality,</p> <div class="kdmath">$$ \left|\sum_{j\neq i}a_{ij}\frac{x_j}{x_i}\right|=\sum_{j\neq i}\left|a_{ij}\frac{x_j}{x_i}\right| $$</div> <p>and from the fact that $\left\vert x_i\right\vert\geq\left\vert x_j\right\vert$ ,</p> <div class="kdmath">$$ \sum_{j\neq i}\left|a_{ij}\frac{x_j}{x_i}\right|=\sum_{j\neq i}\left|a_{ij}\right|\left|\frac{x_j}{x_i}\right|\leq\sum_{j\neq i}\left|a_{ij}\right|=R_i $$</div> <p>Thus, we can conclude that $\left\vert\lambda-a_{ii}\right\vert\leq R_i$ and hence, proved.<span style="float: right;">$\square$</span></p> <div style="height: 0.1em;"></div> <h5 id="cor-35-nonsingularity-of-strict-diagonally-dominant-matrix">Cor 3.5) Nonsingularity of Strict Diagonally dominant matrix</h5> <blockquote> <p>A strictly diagonally dominant matrix (or an irreducibly diagonally dominant matrix is nonsingular.</p> </blockquote> <div style="height: 0.1em;"></div> <h3 id="32-convergence-theorems">3.2. Convergence Theorems</h3> <p>Both iterative methods are said to converge when $\lnm x^{(k+1)}-x^{(k)}\rnm&lt;\varepsilon$ for any $\varepsilon&gt;0$. There are some conditions to guarantee the theoretical convergence of Jacobi method.</p> <h5 id="thm-36-convergence-for-strictly-diagonally-dominant-matrix">Thm 3.6) Convergence for strictly diagonally dominant matrix</h5> <blockquote> <p>For a system of linear equations $Ax=b$, both the Jacobi and the Gauss-Seidel method converges to the unique solution if $A$ is strictly diagoally dominant. (Sufficient condition)</p> </blockquote> <div style="height: 0.1em;"></div> <p><strong>Proof for the Jacobi method</strong> Since $A$ is strictly diagonally dominant, $A$ is nonsingular and hence invertible. This implies there exists an exact solution $x^*=A^{-1}b$.</p> <p>From the element-based Jacobi method,</p> <div class="kdmath">$$ x_i^{(k+1)}=\frac{1}{a_{ii}}\left(b_i-\sum_{j\neq i}a_{ij}x_j^{(k)}\right), \quad\forall i, $$</div> <p>we can denote the exact solution by dropping the iteration index $k$.</p> <div class="kdmath">$$ x_i^*=\frac{1}{a_{ii}}\left(b_i-\sum_{j\neq i}a_{ij}x_j^*\right), \quad\forall i, $$</div> <p><strong>Claim: Error Converges to 0</strong></p> <p>In this setting, we can define an error at iteration $k$ by taking an absolute value of the difference between the value at iteration $k$ and the exact solution.</p> <div class="kdmath">$$ e_i^{(k+1)}=x_i^{(k+1)}-x_i^*=\frac{1}{a_{ii}}\sum_{j\neq i}a_{ij}\left(x_j^{(k)}-x_j^*\right)=\frac{1}{a_{ii}}\sum_{j\neq i}a_{ij}e_j^{(k)} $$</div> <p>Taking absolute value and apply the triangle inequality.</p> <div class="kdmath">$$ \left\vert e_i^{(k+1)}\right\vert=\left\vert\frac{1}{a_{ii}}\sum_{j\neq i}a_{ij}e_j^{(k)}\right\vert\leq\left\vert\frac{1}{a_{ii}}\right\vert\sum_{j\neq i}\left\vert a_{ij}e_j^{(k)}\right\vert=\sum_{j\neq i}\left\vert\frac{a_{ij}}{a_{ii}}\right\vert\left\vert e_j^{(k)}\right\vert $$</div> <p>Since $A$ is strictly diagonally dominant, $C_i=\sum_{j\neq i}\left\vert\frac{a_{ij}}{a_{ii}}\right\vert&lt;1$ and hence we have</p> <div class="kdmath">$$ \left|e_i^{(k+1)}\right|\leq C_i\left|e_j^{(k)}\right| $$</div> <p>Then, by the definition of $l_\infty$ norm,</p> <div class="kdmath">$$ \left\lVert e^{(k+1)}\right\rVert_\infty \leq C\left\lVert e^{(k)}\right\rVert_\infty\quad\text{where}\quad C<1 $$</div> <p>Thus, we can conclude that the error converges to zero.<span style="float: right;">$\square$</span></p> <hr/> <p><strong>Proof for the Gauss-Seidel method</strong> The proof for the Gauss-Seidel method utilizes same idea to that of the Jacobi method.</p> <p>Since $A$ is strictly diagonally dominant, $A$ is nonsingular and hence invertible. This implies there exists an exact solution $x^*=A^{-1}b$.</p> <p>From the element-based Gauss-Seidel method,</p> <p><span class="kdmath">$x_i^{(k+1)}=\frac{1}{a_{ii}}\left(b_i-\sum_{j=1}^{i-1}a_{ij}x_j^{(k+1)}-\sum_{j=i+1}^{n}a_{ij}x_j^{(k)}\right), \quad\forall i,$</span> we can denote the exact solution by dropping the iteration index $k$.</p> <div class="kdmath">$$ x_i^*=\frac{1}{a_{ii}}\left(b_i-\sum_{j=1}^{i-1}a_{ij}x_j^*-\sum_{j=i+1}^{n}a_{ij}x_j^*\right), \quad\forall i, $$</div> <p><strong>Claim: Error Converges to 0</strong></p> <p>In this setting, we can define an error at iteration $k$ by taking a difference between the value at iteration $k$ and the exact solution, $e_i^{(k)} = x_i^{(k)}-x_i^*$. Subtracting the second equation from the first yields the error propagation formula:</p> <div class="kdmath">$$ e_i^{(k+1)}=x_i^{(k+1)}-x_i^*=-\frac{1}{a_{ii}}\left(\sum_{j=1}^{i-1}a_{ij}e_j^{(k+1)}+\sum_{j=i+1}^{n}a_{ij}e_j^{(k)}\right) $$</div> <p>Taking the absolute value and applying the triangle inequality, we get:</p> <div class="kdmath">$$ \left|e_i^{(k+1)}\right|\leq\frac{1}{\left|a_{ii}\right|}\left(\sum_{j=1}^{i-1}\left|a_{ij}\right|\left|e_j^{(k+1)}\right|+\sum_{j=i+1}^{n}\left|a_{ij}\right|\left|e_j^{(k)}\right|\right) $$</div> <p>Let $\left\vert e^{(k+1)}\right\vert_\infty = \max_i\left\vert e_i^{(k+1)}\right\vert = \left\vert e_p^{(k+1)}\right\vert$ for some index $p$. For this specific component $p$, the inequality becomes:</p> <div class="kdmath">$$ \|e^{(k+1)}\|_\infty \leq \frac{1}{|a_{pp}|} \left( \left(\sum_{j=1}^{p-1}|a_{pj}|\right) \|e^{(k+1)}\|_\infty + \left(\sum_{j=p+1}^{n}|a_{pj}|\right) \|e^{(k)}\|_\infty \right) $$</div> <p>We can now solve for $|e^{(k+1)}|_\infty$:</p> <div class="kdmath">$$ \|e^{(k+1)}\|_\infty \left( 1 - \frac{\sum_{j=1}^{p-1}|a_{pj}|}{|a_{pp}|} \right) \le \left( \frac{\sum_{j=p+1}^{n}|a_{pj}|}{|a_{pp}|} \right) \|e^{(k)}\|_\infty $$</div> <div class="kdmath">$$ \|e^{(k+1)}\|_\infty \le \left( \frac{\sum_{j=p+1}^{n}|a_{pj}|}{|a_{pp}| - \sum_{j=1}^{p-1}|a_{pj}|} \right) \|e^{(k)}\|_\infty $$</div> <p>Since $A$ is strictly diagonally dominant, we know that $\left\vert a_{pp}\right\vert &gt; \sum_{j \neq p}\left\vert a_{pj}\right\vert = \sum_{j=1}^{p-1}\left\vert a_{pj}\right\vert + \sum_{j=p+1}^{n}\left\vert a_{pj}\right\vert$.</p> <p>This implies $\left\vert a_{pp}\right\vert - \sum_{j=1}^{p-1}\left\vert a_{pj}\right\vert &gt; \sum_{j=p+1}^{n}\left\vert a_{pj}\right\vert$. Let us define the constant as $C_p = \frac{\sum_{j=p+1}^{n}\left\vert a_{pj}\right\vert}{\left\vert a_{pp}\right\vert - \sum_{j=1}^{p-1}\left\vert a_{pj}\right\vert}$, it follows that $C_p &lt; 1$.</p> <p>Then, by the definition of $l_\infty$ norm,</p> <div class="kdmath">$$ \left\lVert e^{(k+1)}\right\rVert_\infty \leq C\left\lVert e^{(k)}\right\rVert_\infty\quad\text{where}\quad C=\max_p C_p < 1 $$</div> <p>Thus, we can conclude that the error converges to zero.<span style="float: right;">$\square$</span></p> <hr/> <h5 id="thm-37-convergence-of-general-itermative-method">Thm 3.7) Convergence of general itermative method</h5> <blockquote> <p>An iterative method of the form $x^{(k+1)} = Tx^{(k)} + c$ converges to the unique solution of $x=Tx+c$ for any initial guess vector $x^{(0)}$ if and only if the spectral radius $\rho(T)$ of the iteration matrix $T$ is less than 1.</p> <div class="kdmath">$$ \rho(T) < 1 $$</div> <p>In this setting, $T_J=D^{-1}(L+U)$ and $T_G=(D+L)^{-1}U$ for the Jacobi and Gauss-Seidel methods, respectively.</p> </blockquote> <div style="height: 0.1em;"></div> <p><strong>Proof.</strong> The error vector $e^{(k)} = x^{(k)} - x^*$ follows the recurrence $e^{(k+1)} = T e^{(k)}$, which implies $e^{(k)} = T^k e^{(0)}$. The method converges if and only if $\lim_{k \to \infty} e^{(k)} = 0$ for any initial error $e^{(0)}$. This is equivalent to the condition that $\lim_{k \to \infty} T^k = 0$ (the zero matrix).</p> <p><strong>(Necessity: $\lim_{k \to \infty} T^k = 0 \implies \rho(T) &lt; 1$)</strong> Let $\lambda$ be any eigenvalue of $T$ with a corresponding eigenvector $v \neq 0$. By definition, $Tv = \lambda v$.</p> <p>Applying $T$ repeatedly, we get $T^k v = \lambda^k v$. Taking the limit as $k \to \infty$, and using our assumption that $T^k \to 0$:</p> <div class="kdmath">$$ \lim_{k \to \infty} \left(T^k v\right) = \left(\lim_{k \to \infty} T^k\right) v = 0 \cdot v = 0 $$</div> <p>This means we must have $\lim_{k \to \infty} (\lambda^k v) = 0$. Since $v$ is a non-zero vector, the scalar sequence $\lambda^k$ must converge to 0. This is only possible if $\left\vert\lambda\right\vert &lt; 1$. Since this must hold for every eigenvalue of $T$, it must hold for the one with the largest magnitude. Thus, $\rho(T) &lt; 1$.</p> <p><strong>(Sufficiency: $\rho(T) &lt; 1 \implies \lim_{k \to \infty} T^k = 0$)</strong> This direction of the proof relies on a lemma of the relationship between norm and spectral radius.</p> <p>By our assumption, $\rho(T) &lt; 1$. We can choose an $\epsilon &gt; 0$ that is small enough such that $\rho(T) + \epsilon &lt; 1$. For instance, we can choose $\epsilon = (1 - \rho(T))/2$.</p> <p>According to the lemma, there exists a matrix norm for which $\left\lVert T\right\rVert \le \rho(T) + \epsilon = C$, where $C$ is a constant less than 1.</p> <p>Using the submultiplicative property of matrix norms $\left\lVert A^k\right\rVert \le \left\lVert A\right\rVert^k$, we have:</p> <div class="kdmath">$$ \left\lVert T^k\right\rVert \le \left\lVert T\right\rVert^k \le C^k $$</div> <p>As $k \to \infty$, since $C &lt; 1$, we have $C^k \to 0$. This implies that $\lim_{k \to \infty} \left\lVert T^k\right\rVert = 0$. If the norm of a matrix converges to zero, the matrix itself must converge to the zero matrix. Therefore, $\lim_{k \to \infty} T^k = 0$.<span style="float: right;">$\square$</span></p> <div style="height: 0.1em;"></div> <hr/> <h5 id="thm-38-convergence-of-the-gauss-seidel-method">Thm 3.8) Convergence of the Gauss-Seidel method</h5> <blockquote> <p>If $A^\mathsf{T}=A\succeq0$, then the Gauss-Seidel iterates converge to $x^*=A^{-1}b$ for any initial guess $x^{(0)}$.</p> </blockquote> <div style="height: 0.1em;"></div> <hr/> <h5 id="thm-39-steinrosenberg-theorem-convergence-rate">Thm 3.9) Stein–Rosenberg theorem (Convergence rate)</h5> <blockquote> <p>Let $A=(a_{ij})\in\mathbb{R}^{n\times n}$ and let $\rho(T)$ be the spectral radius of a matrix $T$. Let $T_J, T_G$ be the matrix splitting for the Jacobi method and the Gauss-Seidel method, respectively. If $a_{ij} \leq 0$, for $i \neq j$ and $a_{ii} &gt; 0$, for $i = 1,2,\ldots,n$, then one and only one of the following statements holds (four statements are mutually exclusive):</p> <p>i) $0 \leq \rho(T_G) &lt; \rho(T_J) &lt; 1$<br/> ii) $1 &lt; \rho(T_J) &lt; \rho(T_G)$<br/> iii) $\rho(T_J) = \rho(T_G) = 0$<br/> iv) $\rho(T_J) = \rho(T_G) = 1$</p> </blockquote> <div style="height: 0.1em;"></div> <hr/> <h2 id="4-variants">4. Variants</h2> <h3 id="41-method-of-successive-over-relaxation-sor">4.1. Method of Successive over-relaxation (SOR)</h3> <p>The method of successive over-relaxation is a variant of the Gauss-Seidel method for solving a system of linear equations for faster convergence by introducing a relaxation factor.</p> <h4 id="411-algorithm">4.1.1. Algorithm</h4> <p>As with the Gauss-Seidal method, separate $A$ into 3 parts, i.e. $A=D+L+U$ where $D$ is diagonal, $L$ is strictly lower triangular, $U$ is strictly upper triangular parts of $A$.</p> <p>Then, we have $(D+L+U)x=b$ and multiply the relaxation factor $\omega&gt;1$ both sides. <span class="kdmath">$\omega\cdot(D+L+U)x=wb$</span> By moving terms properly, we have</p> <blockquote> <p>[!algorithm] SOR</p> <div class="kdmath">$$ \begin{align} & (D+\omega L)x = \omega b-[\omega U+(\omega-1)D]x\\ & x=(D+\omega L)^{-1}\left(\omega b-[\omega U+(\omega -1)D]x\right) \end{align} $$</div> </blockquote> <p>Thus, the iterative update can be expressed by:</p> <div class="kdmath">$$ x^{(k+1)}=(D+\omega L)^{-1}\left(\omega b-[\omega U+(\omega -1)D]x^{(k)}\right) $$</div> <p>and its element-based expression is</p> <div class="kdmath">$$ x_i^{(k+1)} = (1 - \omega)x_i^{(k)} + \frac{\omega}{a_{ii}} \left( b_i - \sum_{j < i} a_{ij} x_j^{(k+1)} - \sum_{j> i} a_{ij} x_j^{(k)} \right), \quad i = 1,2,\ldots,n. $$</div> <p>and it can be also directly expressed by</p> <div class="kdmath">$$ x^{(k+1)} = (1 - \omega)x^{(k)} + \omega D^{-1} \left(b-Lx^{(k+1)}-Ux^{(k)}\right). $$</div> <p>this expression is more convenient because it doesn’t requires the computation of $(D+\omega L)^{-1}$.</p> <p>If $A$ is symmetric, i.e. $L=U^\mathsf{T}$, such a method is called the Symmetric Successive over-relaxation (SSOR).</p> <div style="height: 0.1em;"></div> <h4 id="412-convergence">4.1.2. Convergence</h4> <h5 id="thm-41-kahan">Thm 4.1) Kahan</h5> <blockquote> <p>If $a_{ii} \neq 0$ for $i = 1, \ldots, n$, then the SOR iteration matrix $T_\omega$ satisfies</p> <p><span class="kdmath">$\rho(T_\omega) \geq |\omega - 1|$</span> Consequently, the SOR iterates converge for every $x^{(0)}$ only if $0 &lt; \omega &lt; 2$.</p> </blockquote> <div style="height: 0.1em;"></div> <h5 id="thm-42-ostrowskireich">Thm 4.2) Ostrowski–Reich</h5> <blockquote> <p>If $A^\mathsf{T}=A\succeq0$ and $0 &lt; \omega &lt; 2$, then the SOR iterates converge to $A^{-1}b$ for every $x^{(0)}$.</p> </blockquote> <div style="height: 0.1em;"></div> <h5 id="thm-43-determining-the-relaxation-factor">Thm 4.3) Determining the relaxation factor</h5> <blockquote> <p>If $A$ is symmetric positive-definite and tridiagonal, then</p> <div class="kdmath">$$ \rho(T_{G}) = \rho(T_J)^2 < 1, $$</div> <p>and the $\omega$ that minimizes $\rho(T_\omega)$ is</p> <div class="kdmath">$$ \omega = \frac{2}{1 + \sqrt{1 - \rho(T_J)^2}} $$</div> <p>For this $\omega$, $\rho(T_\omega) = \omega - 1$.</p> </blockquote> <hr/> <h2 id="5-applications">5. Applications</h2> <h3 id="51-2d-laplaces-equation-for-steady-state-analysis">5.1. 2D Laplace’s equation for steady-state analysis</h3> <p>The problem of calculating the steady-state temperature distribution or electrostatic potential on a 2D plane is described by Laplace’s equation:</p> <div class="kdmath">$$ \nabla^2 u = \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} = 0 $$</div> <p>Approximating this with the finite difference method, the second partial derivative term at each grid point $(i,j)$ is expressed as</p> <div class="kdmath">$$ \begin{align} \frac{\partial^2 u}{\partial x^2} \approx \frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2}\\ \frac{\partial^2 u}{\partial y^2} \approx \frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} \end{align} $$</div> <p>and thus the entire equation is transformed into a simple algebraic equation by substituting them into the original PDE.</p> <div class="kdmath">$$ 4u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1} = 0 $$</div> <p>By setting up this equation for every interior grid point, a large, diagonally dominant matrix is formed where the diagonal element of each row is 4 and the off-diagonal elements are -1 or 0. It can be solved using the Gauss-Seidel method.</p> <div class="kdmath">$$ u_{i,j}^{(k+1)} = \frac{1}{4} \Big( u_{i-1,j}^{(k+1)} + u_{i,j-1}^{(k+1)} + u_{i+1,j}^{(k)} + u_{i,j-1}^{(k)} \Big) $$</div> <h3 id="52-time-dependent-1d-heat-equation">5.2. Time-dependent 1D Heat Equation</h3> <p>1D heat equation which describes time-dependent phenomena is</p> <div class="kdmath">$$ \frac{\partial u}{\partial t} = \alpha \frac{\partial^2 u}{\partial x^2} $$</div> <p>Using an implicit method for a stable solution means the time derivative is approximated as</p> <div class="kdmath">$$ \frac{\partial u}{\partial t}\approx\frac{u_i^{n+1} - u_i^n}{\Delta t} $$</div> <p>and the spatial derivative is approximated using the values at the next time step $(n+1)$ as</p> <div class="kdmath">$$ \frac{\partial^2 u}{\partial x^2}\approx\frac{u_{i+1}^{n+1} - 2u_i^{n+1} + u_{i-1}^{n+1}}{h^2} $$</div> <p>By substituting them into the original equation and rearrange it for the unknown $u_i^{n+1}$ at the next time step yields a tridiagonal matrix system, we have</p> <div class="kdmath">$$ -ru_{i-1}^{n+1} + (1+2r)u_i^{n+1} - ru_{i+1}^{n+1} = u_i^n $$</div> <p>where $r = \alpha \Delta t / h^2$. It can also be solved at each time step using the Gauss-Seidel method.</p>]]></content><author><name></name></author><category term="study"/><category term="optimization"/><category term="numerical-analysis"/><category term="linear-algebra"/><summary type="html"><![CDATA[0. Introduction]]></summary></entry><entry><title type="html">Welcome to My Study Notes</title><link href="https://adobby77.github.io/study/2025/welcome/" rel="alternate" type="text/html" title="Welcome to My Study Notes"/><published>2025-08-31T15:00:00+00:00</published><updated>2025-08-31T15:00:00+00:00</updated><id>https://adobby77.github.io/study/2025/welcome</id><content type="html" xml:base="https://adobby77.github.io/study/2025/welcome/"><![CDATA[<h2 id="welcome">Welcome</h2> <p>Here, I document my study process, summarize key papers, and organize mathematical concepts that I encounter during my research.</p> <h3 id="research-interests">Research Interests</h3> <p>My primary interest lies in the theoretical foundations of <strong>Control Theory</strong> and <strong>Optimization</strong>. I am particularly fascinated by how rigorous mathematical structures—such as graph theory and distance geometry—can be applied to solve complex control problems.</p> <p>You will mostly find posts related to:</p> <ul> <li><strong>Control &amp; Optimization</strong>: Optimal control, Distributed optimization…</li> <li><strong>Mathematics</strong>: Distance Geometry…</li> <li><strong>Foundations</strong>: Basic definitions on Linear Algebra, Linear systems,…</li> </ul> <p>Please note that <strong>all notes on this site are continuously updated</strong>.</p> <p>I hope these notes can be of help to others traversing similar paths in mathematics and engineering.</p> <p>[!TIP] <strong>For a cleaner view</strong>, especially for complex mathematical formulas, please refer to the attached PDF. —</p>]]></content><author><name></name></author><category term="introduction"/><category term="intro"/><category term="control-theory"/><category term="mathematics"/><summary type="html"><![CDATA[An archive of my study notes, paper reviews, and mathematical derivations.]]></summary></entry></feed>