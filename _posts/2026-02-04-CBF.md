---
layout: post
title: Control Barrier Functions
date: 2026-02-04 12:00:00 +0900
description: Introduction to Control Barrier Functions and Safety Control
tags: CBF Lyapunov
categories: study
---

Control Barrier Function is one of the most popular methods of 'Safety Control'.

This documents mainly refers to 'Control Barrier Functions: Theory and Applications (2019)' and includes additional explanations from other references.


## 1. Introduction

<div style="height: 0.1em;"></div>

### 1.1. Motivation

- **Intuition of Liveness & Safety**
	- **Liveness:** "Good" things eventually happen. (ex: Asymptotic Stability)
	- **Safety:** "Bad" things do not happen. (ex: Invariance)


- **Motivation (Why CBF?)**
	1. **Societal need for safety control** 
	
		Much of the recent interest lies broadly on autonomous systems, that are expected to operate in ==unknown and unstructured environments.== 
		However, while the modern control theory dominantly focuses on methods analyzing and implementing liveness such as Lyapunov functions, the research about ==ensuring safety was not extensively studied.==


	2. **Usefulness** 
 
		Lots of ==methods based on Lyapunov theory can be suitably transposed== to address the safety considerations,

<div style="height: 0.1em;"></div> 

### 1.2. A Brief History of Barrier Functions

As we mentioned above, our major concern in safety control is **invariance**- ensuring that the system states remain within a predefined safe set.

First, introduce a definition of safe set.

##### Def 1.1) Safe set

> Given a smooth function $h:\R^n\to\R$, a safe set $\mathcal{C}$ is a superlevel set
> 
> $$\mathcal{C}=\{x\in\R^n:h(x)\geq 0\}$$
> 
> satisfying $\del h(x)=\frac{\pp h}{\pp x}(x)\neq0$ for all $x\in\pp \mathcal{C}=\{x\in\R^n:h(x)=0\}$.

Here, he boundary condition is required to guarantee that the boundary $\pp\mathcal{C}$ be smooth $(n-1)$-dimensional manifold.

#### 1.2.1. Bony-Brezis theorem (Nagumo's theorem)

One of the most monumental theorem is a **Bony-Brezis theorem (also called Nagumo's theorem)**, that gives necessary and sufficient conditions for set invariance. 

While Nagumo's theorem is the first, these conditions have been independently re-discovered on multiple occasions; in particular, around the 1970s by Bony and Brezis.

##### Thm 1.2) Bony-Brezis theorem
> 
> Let $F$ be closed subset of a $C^2$ manifold $M$ and let $X$ be a vector field on $M$ which is Lipschitz continuous. Then, TFAE:
> 1. Every integral curve of $X$ starting in $F$ remains in $F$.
> 2. $(X(m),v)\leq 0$ for every exterior normal vector $v$ at a point $m\in F$.

<div style="height: 0.1em;"></div>

In the context of control theory, we can translate such a theorem in more familiar form below.

> Given a dynamical system $\dot x=f(x)$ with $x\in \R^n$, let the safe set $\mathcal{C}$ corresponding to a smooth function $h:\R^n\to\R$.
> 
> Then, TFAE:
> 1. $\mathcal{C}$ is invariant.
> 2. $\dot h(x)\geq 0,\q\forall x\in\partial C=\{x:h(x)=0\}$.

Here, $\dot h(x)=\frac{dh}{dt}=\frac{\pp h}{\pp x}\frac{dx}{dt}=\frac{\pp h}{\pp x} f(x)$.

<div style="height: 0.1em;"></div>

> [!note] Comparison of the Two forms
> 
> | Component | Geometric Form | Functional Form |
> | :--- | :---: | :---: |
> | **Motion** | Vector field $X(m)$ | System dynamics $f(x)$ |
> | **Safe Region** | Closed set $F$ | Superlevel set $\{x : h(x) \ge 0\}$ |
> | **Boundary Vector** | Exterior normal $\nu$ (points **out**) | Gradient $\nabla h$ (points **in**) |
> | **The Requirement** | Velocity must not point **out** ($\le 0$) | $h$ must not **decrease** ($\ge 0$) |
> 
<div style="height: 0.1em;"></div>


#### 1.2.2. Barrier Certificates

Barrier Certificates was introduced to formally prove safety of nonlinear and hybrid systems.

##### Def 1.3) Barrier Certificates
> 
> Let $\mathcal{C_0}$ be the set of initial conditions and $\mathcal{C}_u$ be an unsafe set.  Then, a function $B:\R^n\to \R$ is called a **barrier certificate** if
> 1. $B(x)\leq 0$ for all $x\in \mathcal{C}_0$
> 2. $B(x)> 0$ for all $x\in \mathcal{C}_u$
> 3. $\dot B(x)\leq 0\;\Longrightarrow\;\mathcal{C}$ is invariant (where $\mathcal{C}=\mathcal{C}_u^c$).

Here, by letting $h=-B$, the $h$ in the Bony-Brezis theorem corresponds to the restriction of the barrier certificate to $\partial C$.

<div style="height: 0.1em;"></div>

#### 1.2.3. Barrier Lyapunov Functions

To extend the safety guarantees beyond the boundary of the set, a various "Lyapunov-like" approaches were introduced.

##### Def 1.4) Barrier Lyapunov functions

>Let $\mathcal{C_0}$ be the set of initial conditions and $\mathcal{C}_u$ be an unsafe set.  Then, a function $B:\R^n\to \R$ is called a **barrier Lyapunov function** if
> 1. $B(x)\leq 0$ for all $x\in \mathcal{C}_0$
> 2. $B(x)> 0$ for all $x\in \mathcal{C}_u$
> 3. $\dot B(x)\leq 0\;\Longrightarrow\;\mathcal{C}$ is invariant (where $\mathcal{C}=\mathcal{C}_u^c$).
> 4. $B$ is positive definite.

This is just adding "positive definiteness" to the definition of Barrier certificate $B$.

Then, $\dot B(x)\leq 0$ be satisfied for all $x\in \mathcal{C}$.

- **Advantage:** It ensures **invariance and hence safety**.
- **Limitation:** They enforce every level set invariant and hence they be **overly conservative.**

> [! note] Limitation of BLF
> 
> Let $\Omega_c=\{x(t):B(x(t))\leq c\}\subset \mathcal{C}$ is a sublevel set of $B$. 
> 
> Then, by the definition of sublevel set, 
> 1. $\Omega_{c_1}\subseteq\Omega_{c_2}$ iff $c_1\leq c_2$.
> 2. $\exists c_{\text{max}}$ s.t. $\Omega_c\subset\Omega_{c_\max}=\mathcal{C}$ for all $c\leq c_\max$ and $\Omega_c\not\subset\mathcal{C}$ for all $c>c_\max$.
> 
> Here, let $B(x(0))=c_0$ and hence $x(0)\in\Omega_{c_0}$.
> 
> If $B$ is a barrier Lyapunov function, then $\dot B(x(t))\leq 0$ for all $t$ and hence $x(t)\in \Omega_{c_0}$ for all $t$, i.e. $B(x(t))\leq c_0$ for all $t$. So, while this system is obviously safe, but overly conservative.
> 
> - **The Trap**: If the system starts in a "very safe" state where $c_0​\ll c_\max$​, it is mathematically forbidden from moving toward the boundary of $\mathcal{C}$.
> - **The Lost Space**: The region $\mathcal{C}\setminus \Omega_{c_0}$​​ becomes "dead space." Even though these states are safe, the BLF controller will treat them as "forbidden" because reaching them would require $B(x)$ to increase ($\dot B>0$), which is prohibited.

<div style="height: 0.1em;"></div>

#### 1.2.4. Open Dynamical Systems

Early work, such as Bony-Brezis theorem or Barrier Certificates, focused on **closed systems** $(\dot x=f(x))$, which was more about **analysis and verification(not control)** of existing dynamics.

The discussion then shifted to **open systems** $(\dot x=f(x)+g(x)u)$, moving from passive observation to **active control synthesis**.

In this paradigm, the barrier certificate was extended to the first definition of a control barrier function.

First, introduce the definition.

##### Def 1.5) Forward invariant set, Safe system

> The set $\mathcal{C}$ is called **forward invariant** if for every $x_0\in\mathcal{C}$, $x(t)\in\mathcal{C}$ for $x(0)=x_0$ and all $t\in \left[0,\tau_\max\right)$. The system is called **safe** w.r.t. $\mathcal{C}$ if the safe set $\mathcal{C}=\{x\in D:h(x)\geq 0\}$ of the system is forward invariant.

##### Def 1.6) First version of Control Barrier Function
> Consider a control system $\dot x(t)=f(x)+g(x)u$ and a safe set $\mathcal{C}\subset D\subset\R^n$ defined as the superlevel set of a continuously differentiable function $h:D\to \R$, i.e.
> 
> $$\mathcal{C}=\{x\in D:h(x)\geq 0\}$$
> 
> Then, the function $h$ is a **control barrier function** if for all $x\in\mathcal{C}$, there exists a control input $u\in U$ such that
> 
> $$\dot h(x,u)\geq 0\;\Longrightarrow\;\mathcal{C}\;\text{ is forward invariant}$$

This definition essentially demanded that the safety measure $h(x)$ never decrease, enforcing the system to **"stay away" or "move away" from the boundary at all times.**

<div style="height: 0.1em;"></div>

#### 1.2.5. Unification of Barrier function with Lyapunov

Following this, researchers sought to explicitly combine barrier functions with **Control Lyapunov Functions (CLF)** to achieve safety and stability simultaneously. These early frameworks (e.g., "Control Lyapunov Barrier Functions") successfully unified the concepts but relied on the strict condition of the first definition ($\dot h \geq 0$).

- **The Problem:** This condition was **stronger than necessary**.  
- **Interpretation:** It implied that even when the system is far from danger (i.e., $h(x)$ is very large), the controller is not allowed to let $h(x)$ decrease. This essentially treats safe states as "frozen," severely restricting the controller's flexibility and performance.

<div style="height: 0.1em;"></div>

These limitations motivated the **“most recent formulation”** of safety certificates, simply termed **Control Barrier Functions (CBF)**.

---

## 2. Foundations of Control Barrier Functions

<div style="height: 0.1em;"></div>

We will suppose that we have a nonlinear affine control system:

$$
\dot x=f(x)+g(x)u\q\cdots\q(*)
$$

where both $f$ and $g$ are locally Lipschitz, $x\in D\in\R^n$ and $u\in U\subset \R^m$.

Before starting our argument, introduce a simple lemma first.

##### Lem 2.1) Comparison lemma
> Consider the scalar function $f$ defined as:
> 
> $$f : [t_0,\infty) \times D \to \mathbb{R}$$
> 
> where $t_0\in\R$ and $D \subset \mathbb{R}$ is a connected open set.
> 
> Suppose that $f(t, x)$ is continuous in $t$ and locally Lipschitz in $x$.
> 
> Let $u(t): [t_0,\infty) \to D$ be the solution to the **differential equation**:
> 
> $$\dot{u}(t) = f(t, u(t)), \quad u(t_0) = u_0$$
> 
> Let $v(t): [t_0,\infty) \to D$ be a differentiable function satisfying the **differential inequality**:
> 
> $$\dot{v}(t) \leq f(t, v(t)), \quad \forall t \in [t_0,\infty)$$
> 
> **Statement:**
> 
> If the initial conditions satisfy $v(t_0) \leq u(t_0)$, then:
> 
> $$v(t) \leq u(t), \quad \forall t \in [t_0,\infty)$$

In short, this lemma says that
**"Given two systems with initial condition $u_0, v_0$ s.t. $u_0\leq v_0$, if $\dot u\leq \dot v$, then $u(t)\leq v(t)$ for all $t$."**
<div style="height: 0.1em;"></div>

### 2.1. Motivation: Control Lyapunov Functions

Recall that the objective(goal) of Control Lyapunov function is "Stabilizing" a given system.

Suppose we have the control objective of stabilizing a system $(*)$ to a point $x^*=0$, i.e. driving $x(t)\to 0$.

In a nonlinear context, this can be achieved equivalently ==finding a feedback control law that drives a positive definite function $V:D\to\R_{\ge 0}$ to zero.== 

This can be formally stated as:

> [!note] Asymptotically stabilizable system
>
> If
> 
> $$\exists u=k(x)\q\text{s.t.}\q \dot V(x, k(x))\leq -\gamma(V(x))\q\cdots\q(\dagger)$$
> 
> where
> 
> $$\dot V(x,k(x))=L_fV(x)+L_gV(x)k(x)$$
> 
> and $\gamma:\R_{\ge0}\to\R_{\ge 0}$ is a class $\mathcal{K}$ function,
> 
> then the system $(*)$ is **asymptotically stabilizable** to $V(x^*)=0$, i.e. $x^*=0$.

**Reduction of complexity:** By the statement that we stated above, we only need to treat the one-dimensional (scalar) value $V(x)$ from $(\dagger)$ instead of treating the $n$-dimensional state vector $x(t)$ of $(*)$.

Specifically, by invoking the **comparison lemma**, the differential inequality $(\dagger)$ ensures that the trajectory of $V(x(t))$ is upper-bounded by the solution of the scalar equation $\dot{y} = -\gamma(y)$. 

Since the origin of this scalar system is asymptotically stable (by the definition of the class $\mathcal{K}$ function $\gamma$), $y(t) \to 0$ as $t \to \infty$. Consequently, $V(x(t))$ is forced to zero. 

Finally, due to the **positive definite** property of $V$, ==driving $V(x) \to 0$ necessarily implies driving the state $x(t) \to 0$.==

<div style="height: 0.1em;"></div>

Based on the argument above, we **do not need to explicitly construct** the feedback controller $u=k(x)$ first. Instead, we only need to ensure that a stabilizing controller **exists.**

##### Def 2.2) Control Lyapunov Function, Set of all stabilizing controllers

> A positive definite function $V:D\to \R_{\geq 0}$ is a **Control Lyapunov Function** if it satisfies the following condition
> 
> $$\inf_{u\in U}[L_fV(x)+L_gV(x)u]\leq \gamma(V(x))$$
> 
> where $\gamma:\R_{\ge0}\to\R_{\ge 0}$ is a class $\mathcal{K}$ function.
> 
> This definition allows us to define the **set of all valid control inputs** that stabilize the system for every point $x\in D$:
> 
> $$K_{\text{clf}}(x):=\{u\in U: L_fV(x)+L_gV(x)u\leq -\gamma(V(x))\}\q\cdots\q(**)$$

> [!note] Key insight: Affine constraint
> 
> The inequality in (**) is **affine in $u$**.
> 
> - This is crucial because it allows us to **formulate the controller synthesis problem as an Optimization Problem** (e.g., Quadratic Program).

<div style="height: 0.1em;"></div>

**Proposition 2.3) Verification of CLF**

> Suppose that $V$ is a CLF and $U=\R^m$.
> If $L_gV(x)=0$, i.e. uncontrollable, then $K_\text{clf}(x)\neq \varnothing$.

**Proof)** Since $V$ is a CLF, this satisfies that

$$\inf_{u\in U}[L_fV(x)+L_gV(x)u]\leq -\gamma(V(x))$$

Here, if $L_gV(x)=0$, then the argument of infimum, $L_fV(x)$, is no longer $u$-dependent and hence 

$$\inf_{u\in U}[L_fV(x)]=L_fV(x)\leq -\gamma(V(x))$$

Recall that $K_\text{clf}=\{u\in U: L_fV(x)+0\cdot u\leq-\gamma(V(x)) \}$. 
Since this inequality is independent of $u$, **any $u$ in the admissible set $U$** satisfies the condition.

**Here, because we assumed $U = \mathbb{R}^m$ (unconstrained input),** the set $U$ is not empty. Therefore, there exists at least one $u$ (in fact, infinitely many) that satisfies the condition.<span style="float: right;">$\square$</span>


These arguments can be generalized by the following theorem.

##### Thm 2.3) Stabilization Theorem
> For the nonlinear control system
> 
> $$\dot x=f(x)+g(x)u$$
>
> , if there exists a control Lyapunov function $V:D\to\R_{\geq 0}$, then any Lipschitz continuous feedback controller $u(x)\in K_{\text{clf}}(x)$ asymptotically stabilizes the system to $x^*=0$.

<div style="height: 0.1em;"></div>


### 2.2. Control Barrier Functions

Using control Lyapunov functions as motivation, we wish to generalize to the concept of safety.

**Q. Can we use Control Lyapunov functions directly for safety?** $\to$ NO.

The **"overly restrictive"** issue for BLF again occurs in CLF.

> [! note] Limitation of CLF
>
> **- The following argument is almost same to that of BLF.**
> 
> Let $\Omega_c=\{x(t):V(x(t))\leq c\}\subset \mathcal{C}$ is a sublevel set of $V$. 
> 
> Then, by the definition of sublevel set, 
> 1. $\Omega_{c_1}\subseteq\Omega_{c_2}$ iff $c_1\leq c_2$.
> 2. $\exists c_{\text{max}}$ s.t. $\Omega_c\subset\Omega_{c_\max}=\mathcal{C}$ for all $c\leq c_\max$ and $\Omega_c\not\subset\mathcal{C}$ for all $c>c_\max$.
> 
> Here, let $V(x(0))=c_0$ and hence $x(0)\in\Omega_{c_0}$.
> 
> If $V$ is a control Lyapunov function, then $\dot V(x(t))\leq -\gamma\left(V(x(t))\right)$ for all $t$ and hence $x(t)\in \Omega_{c_0}$ for all $t$, i.e. $V(x(t))\leq c_0$ for all $t$. 
> So, while this system is obviously safe, but overly conservative.
> 
> - **The Trap**: If the system starts in a "very safe" state where $c_0​\ll c_\max$​, it is mathematically forbidden from moving toward the boundary of $\mathcal{C}$.
> - **The Lost Space**: The region $\mathcal{C}\setminus \Omega_{c_0}$​​ becomes "dead space." Even though these states are safe, the CLF controller will treat them as "forbidden" because reaching them would require $V(x)$ to increase ($\dot V>0$), which is prohibited.

This motivates the formulation of Control Barrier Functions. Let's begin with a historical remark that motivates the modern definition of CBF.

##### Historical remark: Viability Theory

- The condition for set invariance, $\dot{h}(x) \ge -h(x)$, was proposed in **Viability Theory**.
- The modern definition of CBF generalizes this by allowing **any extended class $\mathcal{K}_\infty$ function** $\alpha$, offering greater flexibility in designing the convergence rate to the boundary.

##### Def 2.4) Modern definition of Control Barrier Functions, Set of all safe controllers

> Let $\mathcal{C}\subset D\subset\R^n$ be the superlevel set of a continuously differentiable function $h:D\to \R$, i.e.
> 
> $$\mathcal{C}=\{x\in D:h(x)\geq 0\}$$
> 
> Then, $h$ is called a **control barrier function** if there exists an extended class $\mathcal{K}_\infty$ function $\al$ such that, for the control system $(*)$,
> 
> $$\sup_{u\in U}\left[L_fh(x)+L_gh(x)u\right]\geq-\al(h(x))$$
> 
> for all $x\in D$.
> 
> This definition allows us to define the **set of all safe controllers** that render $\mathcal{C}$ safe:
> 
> $$K_\text{cbf}(x)=\{u\in U:L_fh(x)+L_gh(x)u+\al h(x)\geq 0\}$$

Here, 

$$\dot h(x,u)=\frac{\pp h}{\pp x}\frac{dx}{dt}=\frac{\pp h}{\pp x}\left(f(x)+g(x)u\right)=\underbrace{\frac{\pp h}{\pp x}f(x)}_{L_f h(x)}+\underbrace{\frac{\pp h}{\pp x}g(x)}_{L_g h(x)}u=L_fh(x)+L_gh(x)u$$

and hence CBF can be rewritten as $\sup_{u\in U}\dot h(x,u)\geq -\al((h(x)))$.

> [!note] Why $\al$ is extended $\mathcal{K}_\infty$ function?
> 
> 1. $\al(0)=0$: Ensures safety at the boundary
> 	- Since we have $\dot h(x)\geq-\al(h(x))$ and we need to keep $h(x)\ge0$, we need to force $f$ not to decrease anymore if $h(x)=0$.
> 2. $\al$ is strictly increasing: Modulate the allowable decay rate in proportion to the safe margin. 
> 	- $h(x)\gg 0$(very safe): A large decay is permitted, allowing aggressive maneuvers.
> 	- $h(x) \to 0$ (approaching danger): The lower bound $-\alpha(h(x))$ approaches zero, forcing the system to "brake" and slow its approach to the boundary.
> 3. $\al(r)\to\infty$ as $r\to \infty$: Guarantees global behavior and robustness
> 	- Unboundedness: Ensures that for any arbitrarily large safety margin, the control law remains valid and allows for proportionally fast dynamics.
> 
> 4. $\al:\R\to\R$: Escaping unsafety (Asymptotic stability)
> 	- Since $\alpha$ is defined not only on $\R_{\geq 0}$ but also on $\R_{\leq 0}$ (odd-function-like), if the system is perturbed outside the safe set ($h(x)<0$), then $-\alpha(h(x))$ becomes **positive**. This forces $\dot h(x) > 0$, driving the system **back into the safe set** and hence $\mathcal{C}$ is not only invariant but also asymptotically stable.
> 


<div style="height: 0.1em;"></div>


> [! note] First Vs modern definitions of CBF
> 
> **1. First definition: $\dot h(x,u)\geq 0$**
> 
> $\to$ **Requires $h$ to be non-decreasing**, and hence invariance of every level set is forced (overly restrictive).
>
> **2. Modern definition: $\dot h(x,u)\geq -\al(h(x))$**
> 
> $\to$ **Allows $h$ to decrease** within a bound. This only forces invariance of the zero superlevel set, i.e. safe set $\mathcal{C}$ and hence allows moving freely within the interior (minimally restrictive).

As we can see, this definition is quite analogous to that of CLF and set of all stabilizing controllers. So, similar results follows as well.

##### Thm 2.5) Safety guarantee via CBFs (sufficiency for safety)
> Let $\mathcal{C}\subset\R^n$ be a set defined as the superlevel set of a continuously differentiable function $h:D\to\R$. 
> If $h$ is a control barrier function on $D$ and $\frac{\pp h}{\pp x}(x)\neq 0$ for all $x\in\pp C$, then any Lipschitz continuous controller $u(x)\in K_\text{cbf}$ for the system $(*)$ renders the set $\mathcal{C}$ safe. Additionally, the set $\mathcal{C}$ is asymptotically stable in $D$.

##### Thm 2.6) Necessity for safety

> Let $\mathcal{C}$ be a compact set that is the superlevel set of a continuously differentiable function $h:D\to\R$ where $\frac{\pp h}{\pp x}(x)\neq0$ for all $x\in\pp \mathcal{C}$. 
> If there exists a control law $u=k(x)$ that renders $\mathcal{C}$ safe, i.e. $\mathcal{C}$ is forward invariant with respect to $\dot x=f(x)+g(x)k(x)$, then $h|_\mathcal{C}:\mathcal{C}\to\R$ is a control barrier function on $\mathcal{C}$.


<div style="height: 0.1em;"></div>

In short, 

$$\begin{aligned}
\text{Theorem 2.4)}& \q h\; \text{ is CBF } \Longrightarrow  u\in K_\text{cbf}\; \text{ makes }\; \mathcal{C}\; \text{safe}. \q\q(\text{Sufficiency})\\
\text{Theorem 2.5)}& \q \exists u\; \text{ makes }\; \mathcal{C}\; \text{ safe } \Longrightarrow h|_\mathcal{C}\; \text{ is CBF} \q\q\q\q(\text{Necessity}).
\end{aligned}$$

the theorem 2.4 states the sufficient condition for $\mathcal{C}$ to be safe and the theorem 2.5 states the necessary condition for $\mathcal{C}$ to be safe.

<div style="height: 0.1em;"></div>


### 2.3. Optimization Based Control

In the previous section, we've observed that CBF provides necessary and sufficient conditions for safety.

Then, a natural question arises:

**Q. How can we incorporate these safety conditions into an existing controller with minimal modification?** $\to$ Optimization based controller

#### 2.3.1. Safety-Critical Control

Suppose that we have a nominal feedback controller $u=k(x)$. 

- **Problem:** While this controller has good performance, **it may not guarantee safety** (i.e. $k(x)\notin K_\text{cbf}$).
- **Objective:** Construct a safe controller $u^*(x)\in K_\text{cbf}$ with performance similar to $k(x)$.

To acheive such a goal, we can construct a QP problem.
> [!note] Safe-Critical QP (CBF-QP)
>
> $$\begin{aligned}
> u^*(x) &=\underset{u\in\R^m}{\arg\min} \frac{1}{2}\lnm u-k(x) \rnm^2\\[1.4ex]
> &\text{s.t.}\q L_fh(x)+L_gh(x)u\geq -\al(h(x))
> \end{aligned}$$

There are two advantages of this method:
1. **Minimally Invasive:** Since an objective function measures the deivation between nominal controller and new controller that satisfies the safety condition, 
	- **Case 1)** If $k(x)\in K_\text{cbf}$, then $u^*(x)=k(x)$ and hence the objective function is zero.
	- **Case 2)** If $k(x)\notin K_\text{cbf}$, then $u^*(x)$ is a safe controller that is the closest to $k(x)$.
2. **Closed-form Solution:** Since the constraint is affine in $u$, such QP has a closed form solution and hence applicable to the real-time control.

#### 2.3.2. Unifying with Lyapunov

Analogous to the safety-critical control, we can incorporate a control Lyapunov constraint into the QP to guarantee stability.

**Q. Is the following construction (just add Lyapunov control directly) valid?**

$$\begin{aligned}
u^*(x) &=\underset{u\in\R^m}{\arg\min} \frac{1}{2}\lnm u-k(x) \rnm^2\\[1.4ex]
&\text{s.t.}\q L_fh(x)+L_gh(x)u\geq -\al(h(x))\\
&\text{s.t.}\q L_fV(x)+L_gV(x)u\geq -\gm(V(x))
\end{aligned}$$

**A. NO. A conflict may arise between safety(CBF) and stability(CLF) constraints**, i.e. such a QP may be infeasible.

To resolve this, we need to introduce a relaxation variable $\delta$.

> [!note] Safety-Stability QP (CBF-CLF QP)
>
> $$\begin{aligned}
> u^*&(x) =\underset{u\in\R^m}{\arg\min}\left[\frac{1}{2}u^\T H(x) u + p\delta^2\right]\\[1.5ex]
> &\text{s.t.}\q L_fh(x)+L_gh(x)u\geq -\al(h(x))\\
> &\text{s.t.}\q L_fV(x)+L_gV(x)u\geq -\gm(V(x))+\delta
> \end{aligned}$$
> 
> where $H(x)$ is any positive definite matrix,
> $\delta$ is a relaxation variable and
> $p$ is a penalty coefficient for relaxation.

Observe the difference between Safety-critical QP.
1. **Constraint**
	- As we mentioned above, two constraints may conflict and result in infeasibility. 
	- So, by introducing the relaxation variable $\delta$, we can treat the CLF constraint as a **soft** constraint (allow violation).
2. **Objective function**
	- Unlike the Safety-Critical QP (CBF-QP), the **CLF-CBF QP** explicitly enforces stability through the CLF constraint.
	- Since this constraint directly restricts the feasible set to stabilizing control inputs, **tracking a nominal controller is not required to achieve stability.**
	- Therefore, the objective function does not need to include a deviation term $\|u - k(x)\|^2$ and can instead **focus on minimizing control effort** ($\frac{1}{2}u^T H u$).
	- Also, by introducing the penalizing term $p\delta^2$, we can penalize the over-relaxation and hence **prevents the stability constraint from being excessively violated.**

<div style="height: 0.1em;"></div>

---

## 3. CBF for systems with Actuation Constraints

### 3.1. Motivation

In the previous section, we've established the conditions for the existence of CBFs. However, **is the theoretical CBF always be applicable to the real world?**

Specifically, most of the actuators have their own **physical limitations** we need to consider when we apply the control inputs to the system.

##### Def 3.1) Performance function, Allowable set

> A function $\rho:D\to\R$ is called a **performance function** if it is a continuously differentiable function that defines the **allowable set of states $A$** as its superlevel set, i.e. $A=\{x\in D:\rho(x)\geq 0\}$.

Recall the definition of <u>safe set</u>:

$$\mathcal{C}=\{x\in D:h(x)\geq 0\}$$

In some ideal cases, it may possible to take $h(x)=\rho(x)$, i.e. 

$$\forall x\in A,\;\exists u\in U\q\text{s.t.}\q\dot\rho(x,u)\geq -\al(\rho(x))$$

Then, $\mathcal{C}=A$ and hence $A$ is forward invariant itself as well.

However, forward invariance of $A$ cannot be achieved in general because:
> [!example] Example) Invariance violation of $A$
>
> - **Case 1) Insufficient actuation limit**
> 	- In many cases, $U$ is defined by
>  $$U=\{u\in\R^m:\lnm u\rnm\leq u_\max\}$$
>
> 	- $\rho=h$ implies that $\rho$ is CBF and hence $A$ is forward invariant. So, by the definition of the set of all safe controllers, the set of control inputs that render $A$ invariant is
> 	  
> 	$$K_{\rho}(x)=\{u\in \R^m: L_f\rho(x)+L_g\rho(x)u\geq-\al(\rho(x))\}$$
>
> 	- However, $K_\rho(x)\cap U=\varnothing$ for some $x\in A$.
> 		- Specifically, for $x$ near the boundary of $A$ (i.e. $x$ s.t. $\rho(x)\to 0^+$), for $u$ to make $A$ invariant, $u$ must satisfy
> 	   
> 			$$L_f\rho(x)+L_g\rho(x)u \geq \underbrace{-\al(\rho(x))\approx0}_{\al \in\\ \text{ extended class}\ \mathcal{K}_\infty}$$
>
> 		- In this case, if $L_f\rho(x)\ll 0$, then, there may not exist $u\in U$ s.t. $L_f\rho(x)<L_g\rho(x)u$.
> 	
> - **Case 2) Dynamics with higher relative degree**
> 	- Let $\rho(x)$ has a relative degree $r$. If $r\geq 2$, then by the definition of relative degree,
>  
> 		$$\dot\rho(x)=\frac{\pp \rho}{\pp x}(f(x)+g(x)u)=L_f\rho(x)+\underbrace{L_g\rho(x)}_{=\;0}u=L_f\rho(x)$$
>
> 	- So, the invariance conditions become state-dependent that is independent of $u$, i.e.
> 	  
> 		$$L_f\rho(x)\geq -\al(\rho(x))$$
>
> 	- In this case, we cannot choose proper $u\in U$. If the system enters a state $x_0\in A$ where $L_f\rho(x_0)<-\al(\rho(x_0))$, then  the condition is violated regardless of the control input.
> 
> - **Case 3) Dynamics with disturbances**
> 	- Consider the perturbed system dynamics:
>    
> 		$$\dot x=f(x)+g(x)u+d(t)$$
>
> 	where $d(t)\in\R^n$ is an unknown disturbance.
> 	- Then,
>  
> 		$$\dot \rho(x,u,d)=L_f\rho(x)+L_g\rho(x)u+\frac{\pp\rho}{\pp x}d(t)$$
>
> 	- So, even if we choose $u$ satisfying $L_f\rho(x)+L_g\rho(x)u\geq-\al(\rho(x))$, a large negative disturbance can cause the violation, i.e.
>  
> 		$$L_f\rho(x)+L_g\rho(x)u+\frac{\pp\rho}{\pp x}d(t)<-\al(\rho(x))$$
> 		
> 		and this forces $A$ is not invariant. 

So, our objective is to construct a CBF $h:D\to\R$ s.t. $\mathcal{C}\subseteq A$.

<div style="height: 0.1em;"></div>


### 3.2. Constructing CBF considering Actuation limits

First, introduce a definition.
##### Def 3.1) Nominal Controller, Nominal Trajectory

> Let $D\subset\R^n$ be the set of states and $U\in\R^m$ be the set of admissible control inputs.
> 
> Here, a **nominal controller** $\be:D\to U$ is a locally Lipschitz function that encapsulates a control strategy intended to keep the system within the allowable set $A$, even if it provides no a priori guarantees of safety.
> 
> For any $t\geq 0$ and $x\in D$, the **nominal trajectory** $\phi_\be(t,x):\R_{\ge0}\times D\to D$ is defined by  the state of the control system $(*)$ at time $t$ when the nominal controller $\be$ is used as input and the system is initialized to $x$.
> 
> So, $\phi_\be(t,x)$ satisfies
> 
> $$\dot\phi_\be(t,x)=f(\phi_\be(t,x))+g(\phi_\be(t,x))\be(\phi_\be(t,x))$$
> 
> with initial condition $\phi_\be(0,x)=x$.

> [!warning] Warning
>
> **These are NOT general definitions in control theory**. They are just adopted to construct CBF in this context.

<div style="height: 0.1em;"></div>

Now, the following theorem provides the way to construct a CBF satisfying $\mathcal{C}\subseteq A$.
##### Thm 3.3) CBF using nominal controller

> Let $\rho(x)$ be a continuously differentiable performance function with and $A$ is an allowable set corresponds to $\rho$. 
> Also, let $\be(x)$ be a nominal controller s.t. $f(x)+g(x)\be(x)$ is continuously differentiable.
> 
> Define $h:D\to\R$ as
> 
> $$h(x):=\inf_{\tau\in[0,\infty)}\rho(\phi_\be(\tau,x))$$
> 
> and define $\mathcal{C}:=\{x\in D:h(x)\geq 0\}$.
> 
> Suppose that for each $x$ there exists a unique $x^*$ s.t. $h(x)=\rho(x^*)$ and $\phi_\be(\tau,x)=x^*$ for some $\tau\geq 0$. Then,
> 1. $h$ is a CBF.
> 2. $\mathcal{C}\subseteq A$.
> 3. $\be(x)\in K_\text{cbf}(x)$ for all $x\in\mathcal{C}$.

<div style="height: 0.1em;"></div>


### 3.3. Numerical Implementation

Note that we're discussing about the **'real-world' application** and hence we need to consider the way to **compute in practice**.

> [!abstract] Q. How to compute $h$ in theorem 3.3 in practice?
> 
> - In some cases, it is possible to compute $h$ in **closed form**.
> - If it is not possible, we need to approximate $h$ by **simulating the system trajectory for a finite horizon and compute the infimum numerically.**
> 	- However, as we observed in CBF-QP, we need to compute the gradient of $h$ to utilize $h$ in QP problem that requires **huge computational burden as the dimension of the system grows.**

To overcome this issue, another approach is introduced.

##### Def 3.4) SOS polynomial

> A polynomial $s(x)$ is called a sums of squares (SOS) polynomial if there exists a family  of polynomials $\{g_i(x)\}_{i\in [r]}$ s.t.
> 
> $$s(x)\sum_{i= 1}^r(g_i(x))^2$$
> 
> Also, $\Sigma[x]$ denotes the set of all SOS polynomials.

Using this definition, we can compute $h$ by parametrizing $h$ as fixed degree polynomial and use SOS programming to enforce the required conditions on $h$.

##### Prop 3.5) Polynomial CBF Synthesis via SOS

> Given the control system $(*)$, assume both $f(x)$ and $g(x)$ are polynomials. Let $\rho(x)$ be a polynomial performance function and let $\be(x)$ be a polynomial nominal controller. 
> 
> A polynomial $h(x)$ is a CBF if there exists positive constants $a>0$, $\varepsilon>0$ and SOS polynomials $s_1(x),s_2(x)$ s.t.
> 
> $$\begin{aligned}
> -h(x)-\varepsilon+s_1(x)\rho(x)\in\Sigma[x]\q&\cdots\q (1)\\[1.3ex]
> L_fh(x)+L_gh(x)\be(x)+ah(x)-s_2(x)h(x)\in\Sigma[x]\q&\cdots\q (2)
> \end{aligned}$$
> 
> Moreover, $\mathcal{C}\subseteq A$ and $\be(x)\in K_\text{cbf}$ for all $x\in\mathcal{C}$.

> [!note] Q. What are the equations $(1)$ and $(2)$ mean?
> 
> **Claim 1:** If $(1)$, then $\mathcal{C}\subset A$.
> 
> **Proof)** Suppose that $-h(x)-\varepsilon+s_1(x)\rho(x)\in\Sigma[x]$. Then, $\exists\sigma(x)\in\Sigma[x]$ s.t.
> 
> $$-h(x)-\varepsilon+s_1(x)\rho(x)=\sigma(x)$$
> 
> Since $\sigma(x)$ is SOS, $\sigma(x)\geq 0$ for all $x\in D$ and hence we have
>
> $$-h(x)-\varepsilon+s_1(x)\rho(x)=\sigma(x)\geq 0\\[1.2ex]$$
> 
> By arranging terms properly,
>
> $$h(x)\leq s_1(x)\rho(x)-\varepsilon-\sigma(x)$$
> 
> and since $s_1(x)$ is SOS, $s_1(x)\geq 0$ for all $x\in D$ and hence $h(x)<0$ if $\rho(x)<0$.
> 
> Here, $\rho(x)<0$ and $h(x)<0$ implies that $x\notin A$ and $x\notin \mathcal{C}$, respectively and hence we can conclude that if $(1)$ is true, then $D\setminus A\subseteq D\setminus\mathcal{C}$. 
> 
> By taking complement, $\mathcal{C}\subseteq A$.<span style="float: right;">$\square$</span>
> 
> ---
> **Claim 2:** If $(2)$, then $\be(x)\in K_\text{cbf}(x)$.
> 
> **Proof)** Suppose that $L_fh(x)+L_gh(x)\be(x)+ah(x)-s_2(x)h(x)\in\Sigma[x]$, i.e. $\exists\sigma(x)\in\Sigma[x]$ s.t.
> 
> $$\underbrace{L_fh(x)+L_gh(x)\be(x)}_{\dot h(x,\be(x))}+\underbrace{ah(x)}_{\al(h(x))}-\underbrace{s_2(x)h(x)}_{\text{relaxation}}=\sigma(x)\geq 0$$
> 
> Here, as we can see above, 
> - The first two terms $L_fh(x)+L_gh(x)\be(x)$ is the time derivative of $h$ when the nominal controller $\be(x)$ is applied, i.e. $\dot h(x,\be(x))$.
> - The third term $ah(x)$ is $\al(h(x))$ where $\al(\cdot)\in\mathcal{K}_\infty$ is linear, i.e. $\al(s)=as$.
> - Since $s_2(x)$ is SOS, $s_2(x)\geq 0$ for all $x\in D$ and hence the fourth term $s_2(x)h(x)\geq 0$ for all $x\in\mathcal{C}$. So, this can be utilized as a relaxation term.
> 
> So, for all $x\in\mathcal{C}$, since both $s_2(x)h(x)$ and $\sigma(x)$ are nonnegative,
> 
> $$L_fh(x)+L_gh(x)\be(x)+ah(x)\geq s_2(x)h(x)+\sigma(x)\geq 0$$
> 
> and hence
> 
> $$L_fh(x)+L_gh(x)\be(x)\geq -ah(x)$$
> 
> This implies that $h$ is CBF and $\be(x)\in K_\text{cbf}(x)$.<span style="float: right;">$\square$</span>

In short,
- Theorem 3.3 constructively provides the theoretical existence of CBF.
- Proposition 3.5 provides the way to compute the CBF constructed in theorem 3.3.

However, there is one more problem left.

While SDP solvers can only deal with "Linear" constraints, the SOS constraints in the method proposed in proposition 3.5 are **"Bilinear"**(observe $ah(x)$ and $s_2(x)h(x)$).

So, to bypass this issue, an iterative procedure is required to **decouple** the decision variables.

> [!note] Two-step alternating optimization
> 
> - **Phase 1: Fix $h(x)$ and solve for a and $s_2(x)$** 
> 	By treating the polynomial $h(x)$ as a fixed constant from a previous guess or iteration, the constraints $(1)$ and $(2)$ become linear with respect to the remaining decision variables $a$,$s_1​(x)$, and $s_2​(x)$.
>     
> - **Phase 2: Fix a and $s_2​(x)$ and solve for $h(x)$** 
> 	Once $a$ and $s_2​(x)$ are determined, they are held constant. The solver then searches for a new polynomial $h(x)$ and $s_1​(x)$ that satisfy the SOS conditions. This phase is often used to **maximize the volume** of the safe set $\mathcal{C}$.


- This approach transforms a complex, non-convex problem into a **sequence of convex SDPs** that can be solved efficiently using toolboxes. 
- This iterative "search" eventually **converges to a valid CBF** $h(x)$ that ensures the safe set $\mathcal{C}$ remains within the allowable region $A$ while being compatible with a nominal controller $\be(x)$.

<div style="height: 0.1em;"></div>

---

## 4. Exponential Control Barrier Functions
<div style="height: 0.1em;"></div>


**Motivation**

While CBFs offer a powerful methodology, the safety-critical constraints have been so far assumed to be of relative degree one.

To overcome this issue, we'll introduce **Exponential CBFs** that allows for us to ==deal with arbitrarily high relative degree safety constraints.==

### 4.1. High Relative-Degree Safety Constraints

<div style="height: 0.1em;"></div>

First, recall the definition relative degree.

> Given a CBF $h(x,u)$, its $k^\th$ derivative be
> 
> $$h^{(k)}(x,u)=L_f^k h(x)+L_gL_f^{k-1}h(x)u$$
> 
> In this context, $h(x,u)$ is said to have relative degree $r$ if
>
> $$\begin{aligned}
> L_gL_f^{k-1}h(x)&=0,\q\forall k\in\{0,1,\cdots, r-2\}\\
> L_gL_f^{r-1}h(x)&\neq0
> \end{aligned}$$

Using this definition, prepare some critical setup for defining Exponential CBF.

> [!note] Setup for Exponential CBF
>
> 
> **Claim:** Here, by defining a barrier state vector corresponding to a CBF $h(x,u)$ with relative degree $r$ by
> 
> $$\eta_b(x):=
> \begin{bmatrix}
> h(x) \\
> \dot h(x) \\
> \ddot h(x) \\
> \vdots \\
> h^{(r-1)}(x)
> \end{bmatrix}=
> \begin{bmatrix}
> h(x) \\
> L_f h(x) \\
> L_f^2 h(x) \\
> \vdots \\
> L_f^{(r-1)} h(x)
> \end{bmatrix}\in\R^r$$
> 
> and letting $\mu:=h^{(r)}(x,u)=L_f^{r}h(x)+L_gL_f^{r-1}h(x)u$, we can obtain a system of first-order differential equations
>
> $$\begin{aligned}
> \dot\eta_b(x)&=F\eta_b(x)+G\mu\\[1.2ex]
> h(x)&=C\eta_b(x)
> \end{aligned}$$
> 
> where 
>
> $$F=\left[\;
> \begin{array}{c|c}
> \mathbf{0}_{r-1} & I_{r-1}\\[1.05ex] \hline
> 0 & \mathbf{0}^\T_{r-1}
> \end{array}\;
> \right]\in\R^{r\times r},\q
> G=
> \begin{bmatrix}
> \mathbf{0}_{r-1} \\
> 1
> \end{bmatrix}\in\R^r,\q
> C=
> \begin{bmatrix}
> 1 & \mathbf{0}_{r-1}^\T
> \end{bmatrix}\in\R^{r}$$
> 
> Also, by assuming a state-feedback controller $\mu=-K_\al\eta_b(x)$, then we 
>
> $$h(x(t))=Ce^{(F-GK_\al)}\eta_b(x_0)$$
> 
> ---
> **Proof)** First, by multiplying two matrices,
>
> $$F\eta_b(x)
> =\left[ \begin{array}{c|cccc} 0 & 1 & 0 & \cdots & 0 \\ 0 & 0 & 1 & \cdots & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & 0 & \cdots & 1 \\ \hline 0 & 0 & 0 & \cdots & 0 \end{array} \right]
> \begin{bmatrix}
> h(x) \\
> \dot h(x) \\
> \ddot h(x) \\
> \vdots \\
> h^{(r-1)}(x)
> \end{bmatrix}=
> \begin{bmatrix}
> \dot h(x) \\
> \ddot h(x) \\
> \vdots \\
> h^{(r-1)}(x) \\
> 0
> \end{bmatrix}$$
> 
> So,
>
> $$\dot\eta_b(x)=
> \begin{bmatrix}
> \dot h(x) \\
> \ddot h(x) \\
> \vdots \\
> h^{(r-1)}(x) \\
> h^{(r)}(x)
> \end{bmatrix}=
> \underbrace{
> \begin{bmatrix}
> \dot h(x) \\
> \ddot h(x) \\
> \vdots \\
> h^{(r-1)}(x) \\
> 0
> \end{bmatrix}}_{F\eta_b(x)}+
> \underbrace{
> \begin{bmatrix}
> 0 \\
> 0 \\
> \vdots \\
> 0 \\
> h^{(r)}(x)
> \end{bmatrix}}_{G\mu}
> =F\eta_b(x)+G\mu$$
> 
> Here, recall that
> 
> $$h^{(r)}(x,u)=L_f^rh(x)+L_gL_f^{r-1}h(x)u\overset{\text{let}}{=}:\mu$$
> 
> Assume that we apply state-feedback controller, i.e. $\mu=-K_\al\eta_b(x)$.
> By substituting this to the system of first-order differential equations, we obtain
> 
> $$\begin{aligned}
> \dot\eta_b(x)&=F\eta_b(x)+G(-K_\al\eta_b(x))\\[1.2ex]
> &=(F-GK_\al)\eta_b(x)
> \end{aligned}$$
> 
> Here, $\dot\eta_b(x)=(F-GK_\al)\eta_b(x)$ is just a simple linear LTI first-order ODE of the form $\dot x=Ax$ and hence
>
> $$\eta_b(x(t))=\eta_b(x_0)e^{(F-GK_\al)t}$$
>
> Therefore, since $h(x(t))=C\eta_b(x)$, 
>
> $$h(x(t))=C\eta_b(x_0)e^{(F-GK_\al)t}$$
> 
> Moreover, by the comparison lemma, if $\mu\geq -K_\al\eta_b(x)$, then $h(x(t))\geq Ce^{(F-GK_\al)}\eta_b(x_0)$. <span style="float: right;">$\square$</span>

We now can define exponential CBF.

##### Def 4.1) Exponential Control Barrier Function

> Given a set $\mathcal{C}\subset D\subset\R^n$ defined by
> 
> $$\mathcal{C}:=\{x\in D:h(x)\geq 0\}$$
> 
> where $h:D\to\R$ is $C^r$ function, then $h$ is called an **exponential control barrier function** if there exists a row vector $K_\al\in\R^r$ s.t. for control system $\dot x=f(x)+g(x)u$,
>
> $$\sup_{u\in U}\left[L_f^rh(x)+L_gL_f^{r-1}h(x)u\right]\geq-K_\al\eta_b(x)\q\forall x\in \text{Int}\ \mathcal{C}$$
> 
> results in $h(x(t))\geq Ce^{(F-GK_\al)t}\eta_b(x_0)\geq 0$ whenever $h(x_0)\geq 0$.

Intuitively, this implies that the actual input $\mu$ is greater than the assumed state feedback $-K_\al\eta_b(x)$, i.e.

$$\underbrace{L_f^rh(x)+L_gL_f^{r-1}h(x)u}_{\text{actual input}}\geq\underbrace{-K_\al\eta_b(x)}_{\text{reference input}}$$

Now, recall the motivation of ECBF:
$\to$ Generalize the definition of CBF to the systems with higher relative degree.

**Q. Is this definition properly generalizes the definition of CBF?**

> [!note] ECBF generalizes CBF
> 
> By letting $r=1$, then $\eta_b(x)=h(x)$ and hence $$\mu=-K_\al\eta_b(x)=-K_\al h(x)=-\al(h(x))$$ where $\al(s)=K_\al s\in\text{class }\mathcal{K}_\infty$.

Moreover, ECBF can be directly incorporated to the optimization-based control instead of CBF.


> [!note] CLF-ECBF QP
> 
> $$\begin{aligned}
> u(x)= \operatorname*{argmin}_{(u,\mu,\de)\in\R^{m+2}} & \frac{1}{2}u^\T H(x)u+p\delta^2\\[1.2ex]
> \text{s.t.}\q & L_fV(x)+L_gV(x)u\leq -\gamma(V(x))+\delta\\[1.1ex]
> & L_f^rh(x)+L_gL_f^{r-1}h(x)u=\mu\\[1.1ex]
> & \mu\geq -K_\al\eta_b(x)
> \end{aligned}$$

<div style="height: 0.1em;"></div>

### 4.2. Designing Exponential Control Barrier Functions



Observe that the dynamics 

$$\begin{aligned}
\dot\eta_b(x)&=F\eta_b(x)+G\mu\\[1.2ex]
h(x)&=C\eta_b(x)
\end{aligned}$$

is the **controllable canonical form**.
So, by letting $K_\al=\begin{bmatrix}\al_1 & \al_2 & \cdots & \al_r\end{bmatrix}$, we can obtain

$$F-GK_\al=
\begin{bmatrix}
0 & 1 & 0 & \cdots & 0 \\
0 & 0 & 1 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & 1 \\
-\al_1 & -\al_2 & -\al_3 & \cdots & -\al_r
\end{bmatrix}$$

and hence the characteristic polynomial of $F-GK_\al$ be

$$\lambda^r+\al_r\lambda^{r-1}+\cdots+\al_2\lambda+\al=0$$

Here, suppose that such a polynomial be factored as 

$$(\lambda+p_1)(\lambda+p_2)\cdots(\lambda+p_r)=0,$$

i.e. $-p_1,\cdots, -p_r$ are the eigenvalues(poles) of the closed-loop system.

Next, define an auxiliary family of function $\{\nu_i\}_{i\in I}$ where $\nu_i:D\to\R$ for all $i\in I$ and their corresponding superlevel sets $\mathcal{C}_i=\{x\in D:\nu_i(x)\geq 0\}$ as follows.

$$\begin{aligned}
\nu_0(x)&=h(x);\qquad\q\q\q\q\;\;\;\q\;\;\mathcal{C}_0=\{x\in D:\nu_0(x)\geq 0\}=\mathcal{C}\\[1.1ex]
\nu_1(x)&=\dot\nu_0(x)+p_1\nu_0(x);\qquad\q\;\;\mathcal{C}_1=\{x\in D:\nu_1(x)\geq 0\}\\[1.1ex]
&\;\;\vdots\qquad\qquad\qquad\qquad\qquad\qquad\;\;\; \vdots \\[1.1ex]
\nu_r(x)&=\dot\nu_{r-1}(x)+p_r\nu_{r-1}(x);\qquad\mathcal{C}_r=\{x\in D:\nu_r(x)\geq 0\}
\end{aligned}$$

Our goal is to design $K_\al$ to ensure $\mathcal{C}$ is forward invariant. 

First, begin with the following basic and straightforward result.

##### Prop 4.2) Recursive Invariance of Auxiliary safe sets

> For a given $i\in \[r\]$, if $\mathcal{C}_i$ is forward invariant, then $\mathcal{C}_{i-1}$ is forward invariant whenever $p_i>0$ and $x_0\in\mathcal{C}_i\cap\mathcal{C}_{i-1}$.

**Proof)** Since $\mathcal{C}_i$ is forward invariant, for a given $x_0\in\mathcal{C}_i\cap\mathcal{C}_{i-1}$, $x(t)\in\mathcal{C}_i$ for all $t\in[0,\infty)$, i.e. 

$$\nu_i(x(t))\geq 0,\q\forall t\in[0,\infty)$$

By the definition of $\nu_i(x)$, 

$$\nu_i(x)=\dot\nu_{i-1}(x)+p_i\nu_{i-1}(x)\geq 0$$

This implies that for $x\to\pp\mathcal{C}_{i-1}$, i.e. $\nu_{i-1}(x)\to 0^+$, then 

$$\nu_i(x)=\dot\nu_{i-1}(x)+\underbrace{p_i\nu_{i-1}(x)}_{\to\; 0^+}\approx\dot\nu_{i-1}(x)\geq 0$$

Thus, $\mathcal{C}_{i-1}$ is forward invariant as well. <span style="float: right;">$\square$</span>

<div style="height: 0.1em;"></div>


From such a proposition, ==**inductively**==, we can obtain the following result directly.
##### Thm 4.3) Safety Guarantee

> If $\mathcal{C}\_r$ is forward invariant and $x_0\in\bigcap_{i=0}^r\mathcal{C}_i$, then $\mathcal{C}$ is forward invariant.

<div style="height: 0.1em;"></div>

So far, we've observed that two conditions are required for invariance of $\mathcal{C}$.
1. $p_i>0$ for each $i\in [r]$
2. $x_0\in \mathcal{C}_i$ for each $i\in [r]$

Q. What is the meaning of these conditions?

> [!note] Meaning of these conditions
> 
> **1. $p_i>0$ for each $i\in[r]$**
> 
> $\to$ As we assumed that $-p_i$ are the poles of a closed-loop system, $F-GK_\al$ be Hurwitz with totally negative, i.e. each eigenvalue of $F-GK_\al$ is negative real.
> This makes ==a closed-loop system converges without oscillation(overdamped).==
> (While underdamping system converges to the objective state, it may violate the safety condition because of oscillation.)
> 	
> **2. $x_0\in \mathcal{C}_i$ for each $i\in\[r\]$**
> 
> $\to$ Since $x_0\in\mathcal{C}\_i$ implies $\nu_i(x_0)=\dot\nu_{i-1}(x_0)+p_i\nu_{i-1}(x)\geq 0$, we obtain the lower bound for $p_i$.
> 
>	$$p_i\geq-\frac{\dot\nu_{i-1}(x_0)}{\nu_{i-1}(x_0)}$$
> 
>This provides the condition for $p_i$ corresponds to $x_0$ that means ==the required response rate depends on $x_0$.==

Finally, we can guarantee the existence of ECBF using these conditions.

##### Thm 4.4) Conditions for choosing Proper gain matrix

> Suppose $K_\al$ is chosen s.t. $F-GK_\al$ is Hurwitz and total negative(resulting in negative real poles) and the eigenvalues satisfy
>
> $$\lambda_i(F-GK_\al)\geq -\frac{\dot\nu_{i-1}(x_0)}{\nu_{i-1}(x_0)},$$
>
> then $\mu\geq -K_\al\eta_b(x)$ guarantees $h(x)$ is an exponential CBF.

This theorem provides a sufficient conditions for the existence of ECBF, i.e. 

$$K_\al\text{ satisfies theorem 4.4 }\Longrightarrow\; h(x)\text{ be ECBF if }\;\mu\geq-K_\al\eta_b(x_0)$$
