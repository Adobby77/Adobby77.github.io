<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Control Barrier Functions | Woojin Shin </title> <meta name="author" content="Woojin Shin"> <meta name="description" content="Introduction to Control Barrier Functions and Safety Control"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adobby77.github.io/study/2026/CBF/"> <script src="/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <link rel="stylesheet" href="/assets/css/obsidian-compat.css?v=05ae35f9ce652dbe8f02ec6f984e0a75"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Woojin Shin </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/study/index.html">Study </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Control Barrier Functions</h1> <p class="post-meta"> Created on February 03, 2026 </p> <p class="post-tags"> <i class="fa-solid fa-calendar fa-sm"></i> 2026   ·   <i class="fa-solid fa-hashtag fa-sm"></i> CBF   <i class="fa-solid fa-hashtag fa-sm"></i> Lyapunov   ·   <i class="fa-solid fa-tag fa-sm"></i> study </p> </header> <article class="post-content"> <div id="markdown-content"> <blockquote> <p>[!TIP] Download PDF</p> <p>For a cleaner view, please refer to the attached PDF.</p> <div style="margin-top: 10px; display: flex; align-items: center; gap: 15px;"> <a href="/assets/pdf/Control%20Barrier%20Function.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank"> <i class="fas fa-file-pdf"></i> Download PDF </a> <span style="font-size: 0.85rem; color: #888;"> <i class="fas fa-history"></i> Last updated: Feb. 15. 2026. </span> </div> </blockquote> <p>Control Barrier Function is one of the most popular methods of ‘Safety Control’.</p> <p>This documents mainly refers to ‘Control Barrier Functions: Theory and Applications (2019)’ and includes additional explanations from other references.</p> <h2 id="1-introduction">1. Introduction</h2> <div style="height: 0.1em;"></div> <h3 id="11-motivation">1.1. Motivation</h3> <ul> <li> <strong>Intuition of Liveness &amp; Safety</strong> <ul> <li> <strong>Liveness:</strong> “Good” things eventually happen. (ex: Asymptotic Stability)</li> <li> <strong>Safety:</strong> “Bad” things do not happen. (ex: Invariance)</li> </ul> </li> <li> <strong>Motivation (Why CBF?)</strong> <ol> <li> <p><strong>Societal need for safety control</strong></p> <p>Much of the recent interest lies broadly on autonomous systems, that are expected to operate in ==unknown and unstructured environments.== However, while the modern control theory dominantly focuses on methods analyzing and implementing liveness such as Lyapunov functions, the research about ==ensuring safety was not extensively studied.==</p> </li> <li> <p><strong>Usefulness</strong></p> <p>Lots of ==methods based on Lyapunov theory can be suitably transposed== to address the safety considerations,</p> </li> </ol> </li> </ul> <div style="height: 0.1em;"></div> <h3 id="12-a-brief-history-of-barrier-functions">1.2. A Brief History of Barrier Functions</h3> <p>As we mentioned above, our major concern in safety control is <strong>invariance</strong>- ensuring that the system states remain within a predefined safe set.</p> <p>First, introduce a definition of safe set.</p> <h5 id="def-11-safe-set">Def 1.1) Safe set</h5> <blockquote> <p>Given a smooth function $h:\R^n\to\R$, a safe set $\mathcal{C}$ is a superlevel set</p> <div class="kdmath">$$ \mathcal{C}=\{x\in\R^n:h(x)\geq 0\} $$</div> <p>satisfying $\del h(x)=\frac{\pp h}{\pp x}(x)\neq0$ for all $x\in\pp \mathcal{C}={x\in\R^n:h(x)=0}$.</p> </blockquote> <p>Here, he boundary condition is required to guarantee that the boundary $\pp\mathcal{C}$ be smooth $(n-1)$-dimensional manifold.</p> <h4 id="121-bony-brezis-theorem-nagumos-theorem">1.2.1. Bony-Brezis theorem (Nagumo’s theorem)</h4> <p>One of the most monumental theorem is a <strong>Bony-Brezis theorem (also called Nagumo’s theorem)</strong>, that gives necessary and sufficient conditions for set invariance.</p> <p>While Nagumo’s theorem is the first, these conditions have been independently re-discovered on multiple occasions; in particular, around the 1970s by Bony and Brezis.</p> <h5 id="thm-12-bony-brezis-theorem">Thm 1.2) Bony-Brezis theorem</h5> <blockquote> <p>Let $F$ be closed subset of a $C^2$ manifold $M$ and let $X$ be a vector field on $M$ which is Lipschitz continuous. Then, TFAE:</p> <ol> <li>Every integral curve of $X$ starting in $F$ remains in $F$.</li> <li>$(X(m),v)\leq 0$ for every exterior normal vector $v$ at a point $m\in F$.</li> </ol> </blockquote> <div style="height: 0.1em;"></div> <p>In the context of control theory, we can translate such a theorem in more familiar form below.</p> <blockquote> <p>Given a dynamical system $\dot x=f(x)$ with $x\in \R^n$, let the safe set $\mathcal{C}$ corresponding to a smooth function $h:\R^n\to\R$.</p> <p>Then, TFAE:</p> <ol> <li>$\mathcal{C}$ is invariant.</li> <li>$\dot h(x)\geq 0,\q\forall x\in\partial C={x:h(x)=0}$.</li> </ol> </blockquote> <p>Here, $\dot h(x)=\frac{dh}{dt}=\frac{\pp h}{\pp x}\frac{dx}{dt}=\frac{\pp h}{\pp x} f(x)$.</p> <div style="height: 0.1em;"></div> <blockquote> <p>[!note] Comparison of the Two forms</p> <table> <thead> <tr> <th style="text-align: left">Component</th> <th style="text-align: center">Geometric Form</th> <th style="text-align: center">Functional Form</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><strong>Motion</strong></td> <td style="text-align: center">Vector field $X(m)$</td> <td style="text-align: center">System dynamics $f(x)$</td> </tr> <tr> <td style="text-align: left"><strong>Safe Region</strong></td> <td style="text-align: center">Closed set $F$</td> <td style="text-align: center">Superlevel set ${x : h(x) \ge 0}$</td> </tr> <tr> <td style="text-align: left"><strong>Boundary Vector</strong></td> <td style="text-align: center">Exterior normal $\nu$ (points <strong>out</strong>)</td> <td style="text-align: center">Gradient $\nabla h$ (points <strong>in</strong>)</td> </tr> <tr> <td style="text-align: left"><strong>The Requirement</strong></td> <td style="text-align: center">Velocity must not point <strong>out</strong> ($\le 0$)</td> <td style="text-align: center">$h$ must not <strong>decrease</strong> ($\ge 0$)</td> </tr> </tbody> </table> </blockquote> <div style="height: 0.1em;"></div> <h4 id="122-barrier-certificates">1.2.2. Barrier Certificates</h4> <p>Barrier Certificates was introduced to formally prove safety of nonlinear and hybrid systems.</p> <h5 id="def-13-barrier-certificates">Def 1.3) Barrier Certificates</h5> <blockquote> <p>Let $\mathcal{C_0}$ be the set of initial conditions and $\mathcal{C}_u$ be an unsafe set. Then, a function $B:\R^n\to \R$ is called a <strong>barrier certificate</strong> if</p> <ol> <li>$B(x)\leq 0$ for all $x\in \mathcal{C}_0$</li> <li>$B(x)&gt; 0$ for all $x\in \mathcal{C}_u$</li> <li>$\dot B(x)\leq 0\;\Longrightarrow\;\mathcal{C}$ is invariant (where $\mathcal{C}=\mathcal{C}_u^c$).</li> </ol> </blockquote> <p>Here, by letting $h=-B$, the $h$ in the Bony-Brezis theorem corresponds to the restriction of the barrier certificate to $\partial C$.</p> <div style="height: 0.1em;"></div> <h4 id="123-barrier-lyapunov-functions">1.2.3. Barrier Lyapunov Functions</h4> <p>To extend the safety guarantees beyond the boundary of the set, a various “Lyapunov-like” approaches were introduced.</p> <h5 id="def-14-barrier-lyapunov-functions">Def 1.4) Barrier Lyapunov functions</h5> <blockquote> <p>Let $\mathcal{C_0}$ be the set of initial conditions and $\mathcal{C}_u$ be an unsafe set. Then, a function $B:\R^n\to \R$ is called a <strong>barrier Lyapunov function</strong> if</p> <ol> <li>$B(x)\leq 0$ for all $x\in \mathcal{C}_0$</li> <li>$B(x)&gt; 0$ for all $x\in \mathcal{C}_u$</li> <li>$\dot B(x)\leq 0\;\Longrightarrow\;\mathcal{C}$ is invariant (where $\mathcal{C}=\mathcal{C}_u^c$).</li> <li>$B$ is positive definite.</li> </ol> </blockquote> <p>This is just adding “positive definiteness” to the definition of Barrier certificate $B$.</p> <p>Then, $\dot B(x)\leq 0$ be satisfied for all $x\in \mathcal{C}$.</p> <ul> <li> <strong>Advantage:</strong> It ensures <strong>invariance and hence safety</strong>.</li> <li> <strong>Limitation:</strong> They enforce every level set invariant and hence they be <strong>overly conservative.</strong> </li> </ul> <blockquote> <p>[! note] Limitation of BLF</p> <p>Let $\Omega_c={x(t):B(x(t))\leq c}\subset \mathcal{C}$ is a sublevel set of $B$.</p> <p>Then, by the definition of sublevel set,</p> <ol> <li>$\Omega_{c_1}\subseteq\Omega_{c_2}$ iff $c_1\leq c_2$.</li> <li>$\exists c_{\text{max}}$ s.t. $\Omega_c\subset\Omega_{c_\max}=\mathcal{C}$ for all $c\leq c_\max$ and $\Omega_c\not\subset\mathcal{C}$ for all $c&gt;c_\max$.</li> </ol> <p>Here, let $B(x(0))=c_0$ and hence $x(0)\in\Omega_{c_0}$.</p> <p>If $B$ is a barrier Lyapunov function, then $\dot B(x(t))\leq 0$ for all $t$ and hence $x(t)\in \Omega_{c_0}$ for all $t$, i.e. $B(x(t))\leq c_0$ for all $t$. So, while this system is obviously safe, but overly conservative.</p> <ul> <li> <strong>The Trap</strong>: If the system starts in a “very safe” state where $c_0​\ll c_\max$​, it is mathematically forbidden from moving toward the boundary of $\mathcal{C}$.</li> <li> <strong>The Lost Space</strong>: The region $\mathcal{C}\setminus \Omega_{c_0}$​​ becomes “dead space.” Even though these states are safe, the BLF controller will treat them as “forbidden” because reaching them would require $B(x)$ to increase ($\dot B&gt;0$), which is prohibited.</li> </ul> </blockquote> <div style="height: 0.1em;"></div> <h4 id="124-open-dynamical-systems">1.2.4. Open Dynamical Systems</h4> <p>Early work, such as Bony-Brezis theorem or Barrier Certificates, focused on <strong>closed systems</strong> $(\dot x=f(x))$, which was more about <strong>analysis and verification(not control)</strong> of existing dynamics.</p> <p>The discussion then shifted to <strong>open systems</strong> $(\dot x=f(x)+g(x)u)$, moving from passive observation to <strong>active control synthesis</strong>.</p> <p>In this paradigm, the barrier certificate was extended to the first definition of a control barrier function.</p> <p>First, introduce the definition.</p> <h5 id="def-15-forward-invariant-set-safe-system">Def 1.5) Forward invariant set, Safe system</h5> <blockquote> <p>The set $\mathcal{C}$ is called <strong>forward invariant</strong> if for every $x_0\in\mathcal{C}$, $x(t)\in\mathcal{C}$ for $x(0)=x_0$ and all $t\in \left[0,\tau_\max\right)$. The system is called <strong>safe</strong> w.r.t. $\mathcal{C}$ if the safe set $\mathcal{C}={x\in D:h(x)\geq 0}$ of the system is forward invariant.</p> </blockquote> <h5 id="def-16-first-version-of-control-barrier-function">Def 1.6) First version of Control Barrier Function</h5> <blockquote> <p>Consider a control system $\dot x(t)=f(x)+g(x)u$ and a safe set $\mathcal{C}\subset D\subset\R^n$ defined as the superlevel set of a continuously differentiable function $h:D\to \R$, i.e.</p> <div class="kdmath">$$ \mathcal{C}=\{x\in D:h(x)\geq 0\} $$</div> <p>Then, the function $h$ is a <strong>control barrier function</strong> if for all $x\in\mathcal{C}$, there exists a control input $u\in U$ such that</p> <div class="kdmath">$$ \dot h(x,u)\geq 0\;\Longrightarrow\;\mathcal{C}\;\text{ is forward invariant} $$</div> </blockquote> <p>This definition essentially demanded that the safety measure $h(x)$ never decrease, enforcing the system to <strong>“stay away” or “move away” from the boundary at all times.</strong></p> <div style="height: 0.1em;"></div> <h4 id="125-unification-of-barrier-function-with-lyapunov">1.2.5. Unification of Barrier function with Lyapunov</h4> <p>Following this, researchers sought to explicitly combine barrier functions with <strong>Control Lyapunov Functions (CLF)</strong> to achieve safety and stability simultaneously. These early frameworks (e.g., “Control Lyapunov Barrier Functions”) successfully unified the concepts but relied on the strict condition of the first definition ($\dot h \geq 0$).</p> <ul> <li> <strong>The Problem:</strong> This condition was <strong>stronger than necessary</strong>.</li> <li> <strong>Interpretation:</strong> It implied that even when the system is far from danger (i.e., $h(x)$ is very large), the controller is not allowed to let $h(x)$ decrease. This essentially treats safe states as “frozen,” severely restricting the controller’s flexibility and performance.</li> </ul> <div style="height: 0.1em;"></div> <p>These limitations motivated the <strong>“most recent formulation”</strong> of safety certificates, simply termed <strong>Control Barrier Functions (CBF)</strong>.</p> <hr> <h2 id="2-foundations-of-control-barrier-functions">2. Foundations of Control Barrier Functions</h2> <div style="height: 0.1em;"></div> <p>We will suppose that we have a nonlinear affine control system:</p> <div class="kdmath">$$ \dot x=f(x)+g(x)u\q\cdots\q(*) $$</div> <p>where both $f$ and $g$ are locally Lipschitz, $x\in D\in\R^n$ and $u\in U\subset \R^m$.</p> <p>Before starting our argument, introduce a simple lemma first.</p> <h5 id="lem-21-comparison-lemma">Lem 2.1) Comparison lemma</h5> <blockquote> <p>Consider the scalar function $f$ defined as:</p> <div class="kdmath">$$ f : [t_0,\infty) \times D \to \mathbb{R} $$</div> <p>where $t_0\in\R$ and $D \subset \mathbb{R}$ is a connected open set.</p> <p>Suppose that $f(t, x)$ is continuous in $t$ and locally Lipschitz in $x$.</p> <p>Let $u(t): [t_0,\infty) \to D$ be the solution to the <strong>differential equation</strong>:</p> <div class="kdmath">$$ \dot{u}(t) = f(t, u(t)), \quad u(t_0) = u_0 $$</div> <p>Let $v(t): [t_0,\infty) \to D$ be a differentiable function satisfying the <strong>differential inequality</strong>:</p> <div class="kdmath">$$ \dot{v}(t) \leq f(t, v(t)), \quad \forall t \in [t_0,\infty) $$</div> <p><strong>Statement:</strong></p> <p>If the initial conditions satisfy $v(t_0) \leq u(t_0)$, then:</p> <div class="kdmath">$$ v(t) \leq u(t), \quad \forall t \in [t_0,\infty) $$</div> </blockquote> <p>In short, this lemma says that <strong>“Given two systems with initial condition $u_0, v_0$ s.t. $u_0\leq v_0$, if $\dot u\leq \dot v$, then $u(t)\leq v(t)$ for all $t$.”</strong></p> <div style="height: 0.1em;"></div> <h3 id="21-motivation-control-lyapunov-functions">2.1. Motivation: Control Lyapunov Functions</h3> <p>Recall that the objective(goal) of Control Lyapunov function is “Stabilizing” a given system.</p> <p>Suppose we have the control objective of stabilizing a system $(*)$ to a point $x^*=0$, i.e. driving $x(t)\to 0$.</p> <p>In a nonlinear context, this can be achieved equivalently ==finding a feedback control law that drives a positive definite function $V:D\to\R_{\ge 0}$ to zero.==</p> <p>This can be formally stated as:</p> <blockquote> <p>[!note] Asymptotically stabilizable system</p> <p>If</p> <div class="kdmath">$$ \exists u=k(x)\q\text{s.t.}\q \dot V(x, k(x))\leq -\gamma(V(x))\q\cdots\q(\dagger) $$</div> <p>where</p> <div class="kdmath">$$ \dot V(x,k(x))=L_fV(x)+L_gV(x)k(x) $$</div> <p>and $\gamma:\R_{\ge0}\to\R_{\ge 0}$ is a class $\mathcal{K}$ function,</p> <p>then the system $(*)$ is <strong>asymptotically stabilizable</strong> to $V(x^*)=0$, i.e. $x^*=0$.</p> </blockquote> <p><strong>Reduction of complexity:</strong> By the statement that we stated above, we only need to treat the one-dimensional (scalar) value $V(x)$ from $(\dagger)$ instead of treating the $n$-dimensional state vector $x(t)$ of $(*)$.</p> <p>Specifically, by invoking the <strong>comparison lemma</strong>, the differential inequality $(\dagger)$ ensures that the trajectory of $V(x(t))$ is upper-bounded by the solution of the scalar equation $\dot{y} = -\gamma(y)$.</p> <p>Since the origin of this scalar system is asymptotically stable (by the definition of the class $\mathcal{K}$ function $\gamma$), $y(t) \to 0$ as $t \to \infty$. Consequently, $V(x(t))$ is forced to zero.</p> <p>Finally, due to the <strong>positive definite</strong> property of $V$, ==driving $V(x) \to 0$ necessarily implies driving the state $x(t) \to 0$.==</p> <div style="height: 0.1em;"></div> <p>Based on the argument above, we <strong>do not need to explicitly construct</strong> the feedback controller $u=k(x)$ first. Instead, we only need to ensure that a stabilizing controller <strong>exists.</strong></p> <h5 id="def-22-control-lyapunov-function-set-of-all-stabilizing-controllers">Def 2.2) Control Lyapunov Function, Set of all stabilizing controllers</h5> <blockquote> <p>A positive definite function $V:D\to \R_{\geq 0}$ is a <strong>Control Lyapunov Function</strong> if it satisfies the following condition</p> <div class="kdmath">$$ \inf_{u\in U}[L_fV(x)+L_gV(x)u]\leq \gamma(V(x)) $$</div> <p>where $\gamma:\R_{\ge0}\to\R_{\ge 0}$ is a class $\mathcal{K}$ function.</p> <p>This definition allows us to define the <strong>set of all valid control inputs</strong> that stabilize the system for every point $x\in D$:</p> <div class="kdmath">$$ K_{\text{clf}}(x):=\{u\in U: L_fV(x)+L_gV(x)u\leq -\gamma(V(x))\}\q\cdots\q(**) $$</div> </blockquote> <blockquote> <p>[!note] Key insight: Affine constraint</p> <p>The inequality in (**) is <strong>affine in $u$</strong>.</p> <ul> <li>This is crucial because it allows us to <strong>formulate the controller synthesis problem as an Optimization Problem</strong> (e.g., Quadratic Program).</li> </ul> </blockquote> <div style="height: 0.1em;"></div> <p><strong>Proposition 2.3) Verification of CLF</strong></p> <blockquote> <p>Suppose that $V$ is a CLF and $U=\R^m$. If $L_gV(x)=0$, i.e. uncontrollable, then $K_\text{clf}(x)\neq \varnothing$.</p> </blockquote> <p><strong>Proof)</strong> Since $V$ is a CLF, this satisfies that</p> <div class="kdmath">$$ \inf_{u\in U}[L_fV(x)+L_gV(x)u]\leq -\gamma(V(x)) $$</div> <p>Here, if $L_gV(x)=0$, then the argument of infimum, $L_fV(x)$, is no longer $u$-dependent and hence</p> <div class="kdmath">$$ \inf_{u\in U}[L_fV(x)]=L_fV(x)\leq -\gamma(V(x)) $$</div> <p>Recall that $K_\text{clf}={u\in U: L_fV(x)+0\cdot u\leq-\gamma(V(x)) }$. Since this inequality is independent of $u$, <strong>any $u$ in the admissible set $U$</strong> satisfies the condition.</p> <p><strong>Here, because we assumed $U = \mathbb{R}^m$ (unconstrained input),</strong> the set $U$ is not empty. Therefore, there exists at least one $u$ (in fact, infinitely many) that satisfies the condition.<span style="float: right;">$\square$</span></p> <p>These arguments can be generalized by the following theorem.</p> <h5 id="thm-23-stabilization-theorem">Thm 2.3) Stabilization Theorem</h5> <blockquote> <p>For the nonlinear control system</p> <div class="kdmath">$$ \dot x=f(x)+g(x)u $$</div> <p>, if there exists a control Lyapunov function $V:D\to\R_{\geq 0}$, then any Lipschitz continuous feedback controller $u(x)\in K_{\text{clf}}(x)$ asymptotically stabilizes the system to $x^*=0$.</p> </blockquote> <div style="height: 0.1em;"></div> <h3 id="22-control-barrier-functions">2.2. Control Barrier Functions</h3> <p>Using control Lyapunov functions as motivation, we wish to generalize to the concept of safety.</p> <p><strong>Q. Can we use Control Lyapunov functions directly for safety?</strong> $\to$ NO.</p> <p>The <strong>“overly restrictive”</strong> issue for BLF again occurs in CLF.</p> <blockquote> <p>[! note] Limitation of CLF</p> <p><strong>- The following argument is almost same to that of BLF.</strong></p> <p>Let $\Omega_c={x(t):V(x(t))\leq c}\subset \mathcal{C}$ is a sublevel set of $V$.</p> <p>Then, by the definition of sublevel set,</p> <ol> <li>$\Omega_{c_1}\subseteq\Omega_{c_2}$ iff $c_1\leq c_2$.</li> <li>$\exists c_{\text{max}}$ s.t. $\Omega_c\subset\Omega_{c_\max}=\mathcal{C}$ for all $c\leq c_\max$ and $\Omega_c\not\subset\mathcal{C}$ for all $c&gt;c_\max$.</li> </ol> <p>Here, let $V(x(0))=c_0$ and hence $x(0)\in\Omega_{c_0}$.</p> <p>If $V$ is a control Lyapunov function, then $\dot V(x(t))\leq -\gamma\left(V(x(t))\right)$ for all $t$ and hence $x(t)\in \Omega_{c_0}$ for all $t$, i.e. $V(x(t))\leq c_0$ for all $t$. So, while this system is obviously safe, but overly conservative.</p> <ul> <li> <strong>The Trap</strong>: If the system starts in a “very safe” state where $c_0​\ll c_\max$​, it is mathematically forbidden from moving toward the boundary of $\mathcal{C}$.</li> <li> <strong>The Lost Space</strong>: The region $\mathcal{C}\setminus \Omega_{c_0}$​​ becomes “dead space.” Even though these states are safe, the CLF controller will treat them as “forbidden” because reaching them would require $V(x)$ to increase ($\dot V&gt;0$), which is prohibited.</li> </ul> </blockquote> <p>This motivates the formulation of Control Barrier Functions. Let’s begin with a historical remark that motivates the modern definition of CBF.</p> <h5 id="historical-remark-viability-theory">Historical remark: Viability Theory</h5> <ul> <li>The condition for set invariance, $\dot{h}(x) \ge -h(x)$, was proposed in <strong>Viability Theory</strong>.</li> <li>The modern definition of CBF generalizes this by allowing <strong>any extended class $\mathcal{K}_\infty$ function</strong> $\alpha$, offering greater flexibility in designing the convergence rate to the boundary.</li> </ul> <h5 id="def-24-modern-definition-of-control-barrier-functions-set-of-all-safe-controllers">Def 2.4) Modern definition of Control Barrier Functions, Set of all safe controllers</h5> <blockquote> <p>Let $\mathcal{C}\subset D\subset\R^n$ be the superlevel set of a continuously differentiable function $h:D\to \R$, i.e.</p> <div class="kdmath">$$ \mathcal{C}=\{x\in D:h(x)\geq 0\} $$</div> <p>Then, $h$ is called a <strong>control barrier function</strong> if there exists an extended class $\mathcal{K}_\infty$ function $\al$ such that, for the control system $(*)$,</p> <div class="kdmath">$$ \sup_{u\in U}\left[L_fh(x)+L_gh(x)u\right]\geq-\al(h(x)) $$</div> <p>for all $x\in D$.</p> <p>This definition allows us to define the <strong>set of all safe controllers</strong> that render $\mathcal{C}$ safe:</p> <div class="kdmath">$$ K_\text{cbf}(x)=\{u\in U:L_fh(x)+L_gh(x)u+\al h(x)\geq 0\} $$</div> </blockquote> <p>Here,</p> <div class="kdmath">$$ \dot h(x,u)=\frac{\pp h}{\pp x}\frac{dx}{dt}=\frac{\pp h}{\pp x}\left(f(x)+g(x)u\right)=\underbrace{\frac{\pp h}{\pp x}f(x)}_{L_f h(x)}+\underbrace{\frac{\pp h}{\pp x}g(x)}_{L_g h(x)}u=L_fh(x)+L_gh(x)u $$</div> <p>and hence CBF can be rewritten as $\sup_{u\in U}\dot h(x,u)\geq -\al((h(x)))$.</p> <blockquote> <p>[!note] Why $\al$ is extended $\mathcal{K}_\infty$ function?</p> <ol> <li>$\al(0)=0$: Ensures safety at the boundary <ul> <li>Since we have $\dot h(x)\geq-\al(h(x))$ and we need to keep $h(x)\ge0$, we need to force $f$ not to decrease anymore if $h(x)=0$.</li> </ul> </li> <li>$\al$ is strictly increasing: Modulate the allowable decay rate in proportion to the safe margin. <ul> <li>$h(x)\gg 0$(very safe): A large decay is permitted, allowing aggressive maneuvers.</li> <li>$h(x) \to 0$ (approaching danger): The lower bound $-\alpha(h(x))$ approaches zero, forcing the system to “brake” and slow its approach to the boundary.</li> </ul> </li> <li>$\al(r)\to\infty$ as $r\to \infty$: Guarantees global behavior and robustness <ul> <li>Unboundedness: Ensures that for any arbitrarily large safety margin, the control law remains valid and allows for proportionally fast dynamics.</li> </ul> </li> <li>$\al:\R\to\R$: Escaping unsafety (Asymptotic stability) <ul> <li>Since $\alpha$ is defined not only on $\R_{\geq 0}$ but also on $\R_{\leq 0}$ (odd-function-like), if the system is perturbed outside the safe set ($h(x)&lt;0$), then $-\alpha(h(x))$ becomes <strong>positive</strong>. This forces $\dot h(x) &gt; 0$, driving the system <strong>back into the safe set</strong> and hence $\mathcal{C}$ is not only invariant but also asymptotically stable.</li> </ul> </li> </ol> </blockquote> <div style="height: 0.1em;"></div> <blockquote> <p>[! note] First Vs modern definitions of CBF</p> <p><strong>1. First definition: $\dot h(x,u)\geq 0$</strong></p> <p>$\to$ <strong>Requires $h$ to be non-decreasing</strong>, and hence invariance of every level set is forced (overly restrictive).</p> <p><strong>2. Modern definition: $\dot h(x,u)\geq -\al(h(x))$</strong></p> <p>$\to$ <strong>Allows $h$ to decrease</strong> within a bound. This only forces invariance of the zero superlevel set, i.e. safe set $\mathcal{C}$ and hence allows moving freely within the interior (minimally restrictive).</p> </blockquote> <p>As we can see, this definition is quite analogous to that of CLF and set of all stabilizing controllers. So, similar results follows as well.</p> <h5 id="thm-25-safety-guarantee-via-cbfs-sufficiency-for-safety">Thm 2.5) Safety guarantee via CBFs (sufficiency for safety)</h5> <blockquote> <p>Let $\mathcal{C}\subset\R^n$ be a set defined as the superlevel set of a continuously differentiable function $h:D\to\R$. If $h$ is a control barrier function on $D$ and $\frac{\pp h}{\pp x}(x)\neq 0$ for all $x\in\pp C$, then any Lipschitz continuous controller $u(x)\in K_\text{cbf}$ for the system $(*)$ renders the set $\mathcal{C}$ safe. Additionally, the set $\mathcal{C}$ is asymptotically stable in $D$.</p> </blockquote> <h5 id="thm-26-necessity-for-safety">Thm 2.6) Necessity for safety</h5> <blockquote> <p>Let $\mathcal{C}$ be a compact set that is the superlevel set of a continuously differentiable function $h:D\to\R$ where $\frac{\pp h}{\pp x}(x)\neq0$ for all $x\in\pp \mathcal{C}$. If there exists a control law $u=k(x)$ that renders $\mathcal{C}$ safe, i.e. $\mathcal{C}$ is forward invariant with respect to $\dot x=f(x)+g(x)k(x)$, then $h|_\mathcal{C}:\mathcal{C}\to\R$ is a control barrier function on $\mathcal{C}$.</p> </blockquote> <div style="height: 0.1em;"></div> <p>In short,</p> <div class="kdmath">$$ \begin{aligned} \text{Theorem 2.4)}&amp; \q h\; \text{ is CBF } \Longrightarrow u\in K_\text{cbf}\; \text{ makes }\; \mathcal{C}\; \text{safe}. \q\q(\text{Sufficiency})\\ \text{Theorem 2.5)}&amp; \q \exists u\; \text{ makes }\; \mathcal{C}\; \text{ safe } \Longrightarrow h|_\mathcal{C}\; \text{ is CBF} \q\q\q\q(\text{Necessity}). \end{aligned} $$</div> <p>the theorem 2.4 states the sufficient condition for $\mathcal{C}$ to be safe and the theorem 2.5 states the necessary condition for $\mathcal{C}$ to be safe.</p> <div style="height: 0.1em;"></div> <h3 id="23-optimization-based-control">2.3. Optimization Based Control</h3> <p>In the previous section, we’ve observed that CBF provides necessary and sufficient conditions for safety.</p> <p>Then, a natural question arises:</p> <p><strong>Q. How can we incorporate these safety conditions into an existing controller with minimal modification?</strong> $\to$ Optimization based controller</p> <h4 id="231-safety-critical-control">2.3.1. Safety-Critical Control</h4> <p>Suppose that we have a nominal feedback controller $u=k(x)$.</p> <ul> <li> <strong>Problem:</strong> While this controller has good performance, <strong>it may not guarantee safety</strong> (i.e. $k(x)\notin K_\text{cbf}$).</li> <li> <strong>Objective:</strong> Construct a safe controller $u^*(x)\in K_\text{cbf}$ with performance similar to $k(x)$.</li> </ul> <p>To acheive such a goal, we can construct a QP problem.</p> <blockquote> <p>[!note] Safe-Critical QP (CBF-QP)</p> <div class="kdmath">$$ \begin{aligned} u^*(x) &amp;=\underset{u\in\R^m}{\arg\min} \frac{1}{2}\lnm u-k(x) \rnm^2\\[1.4ex] &amp;\text{s.t.}\q L_fh(x)+L_gh(x)u\geq -\al(h(x)) \end{aligned} $$</div> </blockquote> <p>There are two advantages of this method:</p> <ol> <li> <strong>Minimally Invasive:</strong> Since an objective function measures the deivation between nominal controller and new controller that satisfies the safety condition, <ul> <li> <strong>Case 1)</strong> If $k(x)\in K_\text{cbf}$, then $u^*(x)=k(x)$ and hence the objective function is zero.</li> <li> <strong>Case 2)</strong> If $k(x)\notin K_\text{cbf}$, then $u^*(x)$ is a safe controller that is the closest to $k(x)$.</li> </ul> </li> <li> <strong>Closed-form Solution:</strong> Since the constraint is affine in $u$, such QP has a closed form solution and hence applicable to the real-time control.</li> </ol> <h4 id="232-unifying-with-lyapunov">2.3.2. Unifying with Lyapunov</h4> <p>Analogous to the safety-critical control, we can incorporate a control Lyapunov constraint into the QP to guarantee stability.</p> <p><strong>Q. Is the following construction (just add Lyapunov control directly) valid?</strong></p> <div class="kdmath">$$ \begin{aligned} u^*(x) &amp;=\underset{u\in\R^m}{\arg\min} \frac{1}{2}\lnm u-k(x) \rnm^2\\[1.4ex] &amp;\text{s.t.}\q L_fh(x)+L_gh(x)u\geq -\al(h(x))\\ &amp;\text{s.t.}\q L_fV(x)+L_gV(x)u\geq -\gm(V(x)) \end{aligned} $$</div> <p><strong>A. NO. A conflict may arise between safety(CBF) and stability(CLF) constraints</strong>, i.e. such a QP may be infeasible.</p> <p>To resolve this, we need to introduce a relaxation variable $\delta$.</p> <blockquote> <p>[!note] Safety-Stability QP (CBF-CLF QP)</p> <div class="kdmath">$$ \begin{aligned} u^*&amp;(x) =\underset{u\in\R^m}{\arg\min}\left[\frac{1}{2}u^\T H(x) u + p\delta^2\right]\\[1.5ex] &amp;\text{s.t.}\q L_fh(x)+L_gh(x)u\geq -\al(h(x))\\ &amp;\text{s.t.}\q L_fV(x)+L_gV(x)u\geq -\gm(V(x))+\delta \end{aligned} $$</div> <p>where $H(x)$ is any positive definite matrix, $\delta$ is a relaxation variable and $p$ is a penalty coefficient for relaxation.</p> </blockquote> <p>Observe the difference between Safety-critical QP.</p> <ol> <li> <strong>Constraint</strong> <ul> <li>As we mentioned above, two constraints may conflict and result in infeasibility.</li> <li>So, by introducing the relaxation variable $\delta$, we can treat the CLF constraint as a <strong>soft</strong> constraint (allow violation).</li> </ul> </li> <li> <strong>Objective function</strong> <ul> <li>Unlike the Safety-Critical QP (CBF-QP), the <strong>CLF-CBF QP</strong> explicitly enforces stability through the CLF constraint.</li> <li>Since this constraint directly restricts the feasible set to stabilizing control inputs, <strong>tracking a nominal controller is not required to achieve stability.</strong> </li> <li>Therefore, the objective function does not need to include a deviation term $|u - k(x)|^2$ and can instead <strong>focus on minimizing control effort</strong> ($\frac{1}{2}u^T H u$).</li> <li>Also, by introducing the penalizing term $p\delta^2$, we can penalize the over-relaxation and hence <strong>prevents the stability constraint from being excessively violated.</strong> </li> </ul> </li> </ol> <div style="height: 0.1em;"></div> <hr> <h2 id="3-cbf-for-systems-with-actuation-constraints">3. CBF for systems with Actuation Constraints</h2> <h3 id="31-motivation">3.1. Motivation</h3> <p>In the previous section, we’ve established the conditions for the existence of CBFs. However, <strong>is the theoretical CBF always be applicable to the real world?</strong></p> <p>Specifically, most of the actuators have their own <strong>physical limitations</strong> we need to consider when we apply the control inputs to the system.</p> <h5 id="def-31-performance-function-allowable-set">Def 3.1) Performance function, Allowable set</h5> <blockquote> <p>A function $\rho:D\to\R$ is called a <strong>performance function</strong> if it is a continuously differentiable function that defines the <strong>allowable set of states $A$</strong> as its superlevel set, i.e. $A={x\in D:\rho(x)\geq 0}$.</p> </blockquote> <p>Recall the definition of <u>safe set</u>:</p> <div class="kdmath">$$ \mathcal{C}=\{x\in D:h(x)\geq 0\} $$</div> <p>In some ideal cases, it may possible to take $h(x)=\rho(x)$, i.e.</p> <div class="kdmath">$$ \forall x\in A,\;\exists u\in U\q\text{s.t.}\q\dot\rho(x,u)\geq -\al(\rho(x)) $$</div> <p>Then, $\mathcal{C}=A$ and hence $A$ is forward invariant itself as well.</p> <p>However, forward invariance of $A$ cannot be achieved in general because:</p> <blockquote> <p>[!example] Example) Invariance violation of $A$</p> <ul> <li> <strong>Case 1) Insufficient actuation limit</strong> <ul> <li> <p>In many cases, $U$ is defined by <span class="kdmath">$U=\{u\in\R^m:\lnm u\rnm\leq u_\max\}$</span></p> </li> <li> <p>$\rho=h$ implies that $\rho$ is CBF and hence $A$ is forward invariant. So, by the definition of the set of all safe controllers, the set of control inputs that render $A$ invariant is</p> </li> </ul> <div class="kdmath">$$ K_{\rho}(x)=\{u\in \R^m: L_f\rho(x)+L_g\rho(x)u\geq-\al(\rho(x))\} $$</div> <ul> <li>However, $K_\rho(x)\cap U=\varnothing$ for some $x\in A$. <ul> <li> <p>Specifically, for $x$ near the boundary of $A$ (i.e. $x$ s.t. $\rho(x)\to 0^+$), for $u$ to make $A$ invariant, $u$ must satisfy</p> <div class="kdmath">$$ L_f\rho(x)+L_g\rho(x)u \geq \underbrace{-\al(\rho(x))\approx0}_{\al \in\\ \text{ extended class}\ \mathcal{K}_\infty} $$</div> </li> <li> <p>In this case, if $L_f\rho(x)\ll 0$, then, there may not exist $u\in U$ s.t. $L_f\rho(x)&lt;L_g\rho(x)u$.</p> </li> </ul> </li> </ul> </li> <li> <strong>Case 2) Dynamics with higher relative degree</strong> <ul> <li> <p>Let $\rho(x)$ has a relative degree $r$. If $r\geq 2$, then by the definition of relative degree,</p> <div class="kdmath">$$ \dot\rho(x)=\frac{\pp \rho}{\pp x}(f(x)+g(x)u)=L_f\rho(x)+\underbrace{L_g\rho(x)}_{=\;0}u=L_f\rho(x) $$</div> </li> <li> <p>So, the invariance conditions become state-dependent that is independent of $u$, i.e.</p> <div class="kdmath">$$ L_f\rho(x)\geq -\al(\rho(x)) $$</div> </li> <li> <p>In this case, we cannot choose proper $u\in U$. If the system enters a state $x_0\in A$ where $L_f\rho(x_0)&lt;-\al(\rho(x_0))$, then the condition is violated regardless of the control input.</p> </li> </ul> </li> <li> <strong>Case 3) Dynamics with disturbances</strong> <ul> <li> <p>Consider the perturbed system dynamics:</p> <div class="kdmath">$$ \dot x=f(x)+g(x)u+d(t) $$</div> </li> </ul> <p>where $d(t)\in\R^n$ is an unknown disturbance.</p> <ul> <li> <p>Then,</p> <div class="kdmath">$$ \dot \rho(x,u,d)=L_f\rho(x)+L_g\rho(x)u+\frac{\pp\rho}{\pp x}d(t) $$</div> </li> <li> <p>So, even if we choose $u$ satisfying $L_f\rho(x)+L_g\rho(x)u\geq-\al(\rho(x))$, a large negative disturbance can cause the violation, i.e.</p> <div class="kdmath">$$ L_f\rho(x)+L_g\rho(x)u+\frac{\pp\rho}{\pp x}d(t)&lt;-\al(\rho(x)) $$</div> <p>and this forces $A$ is not invariant.</p> </li> </ul> </li> </ul> </blockquote> <p>So, our objective is to construct a CBF $h:D\to\R$ s.t. $\mathcal{C}\subseteq A$.</p> <div style="height: 0.1em;"></div> <h3 id="32-constructing-cbf-considering-actuation-limits">3.2. Constructing CBF considering Actuation limits</h3> <p>First, introduce a definition.</p> <h5 id="def-31-nominal-controller-nominal-trajectory">Def 3.1) Nominal Controller, Nominal Trajectory</h5> <blockquote> <p>Let $D\subset\R^n$ be the set of states and $U\in\R^m$ be the set of admissible control inputs.</p> <p>Here, a <strong>nominal controller</strong> $\be:D\to U$ is a locally Lipschitz function that encapsulates a control strategy intended to keep the system within the allowable set $A$, even if it provides no a priori guarantees of safety.</p> <p>For any $t\geq 0$ and $x\in D$, the <strong>nominal trajectory</strong> $\phi_\be(t,x):\R_{\ge0}\times D\to D$ is defined by the state of the control system $(*)$ at time $t$ when the nominal controller $\be$ is used as input and the system is initialized to $x$.</p> <p>So, $\phi_\be(t,x)$ satisfies</p> <div class="kdmath">$$ \dot\phi_\be(t,x)=f(\phi_\be(t,x))+g(\phi_\be(t,x))\be(\phi_\be(t,x)) $$</div> <p>with initial condition $\phi_\be(0,x)=x$.</p> </blockquote> <blockquote> <p>[!warning] Warning</p> <p><strong>These are NOT general definitions in control theory</strong>. They are just adopted to construct CBF in this context.</p> </blockquote> <div style="height: 0.1em;"></div> <p>Now, the following theorem provides the way to construct a CBF satisfying $\mathcal{C}\subseteq A$.</p> <h5 id="thm-33-cbf-using-nominal-controller">Thm 3.3) CBF using nominal controller</h5> <blockquote> <p>Let $\rho(x)$ be a continuously differentiable performance function with and $A$ is an allowable set corresponds to $\rho$. Also, let $\be(x)$ be a nominal controller s.t. $f(x)+g(x)\be(x)$ is continuously differentiable.</p> <p>Define $h:D\to\R$ as</p> <div class="kdmath">$$ h(x):=\inf_{\tau\in[0,\infty)}\rho(\phi_\be(\tau,x)) $$</div> <p>and define $\mathcal{C}:={x\in D:h(x)\geq 0}$.</p> <p>Suppose that for each $x$ there exists a unique $x^*$ s.t. $h(x)=\rho(x^*)$ and $\phi_\be(\tau,x)=x^*$ for some $\tau\geq 0$. Then,</p> <ol> <li>$h$ is a CBF.</li> <li>$\mathcal{C}\subseteq A$.</li> <li>$\be(x)\in K_\text{cbf}(x)$ for all $x\in\mathcal{C}$.</li> </ol> </blockquote> <div style="height: 0.1em;"></div> <h3 id="33-numerical-implementation">3.3. Numerical Implementation</h3> <p>Note that we’re discussing about the <strong>‘real-world’ application</strong> and hence we need to consider the way to <strong>compute in practice</strong>.</p> <blockquote> <p>[!abstract] Q. How to compute $h$ in theorem 3.3 in practice?</p> <ul> <li>In some cases, it is possible to compute $h$ in <strong>closed form</strong>.</li> <li>If it is not possible, we need to approximate $h$ by <strong>simulating the system trajectory for a finite horizon and compute the infimum numerically.</strong> <ul> <li>However, as we observed in CBF-QP, we need to compute the gradient of $h$ to utilize $h$ in QP problem that requires <strong>huge computational burden as the dimension of the system grows.</strong> </li> </ul> </li> </ul> </blockquote> <p>To overcome this issue, another approach is introduced.</p> <h5 id="def-34-sos-polynomial">Def 3.4) SOS polynomial</h5> <blockquote> <p>A polynomial $s(x)$ is called a sums of squares (SOS) polynomial if there exists a family of polynomials ${g_i(x)}_{i\in [r]}$ s.t.</p> <div class="kdmath">$$ s(x)\sum_{i= 1}^r(g_i(x))^2 $$</div> <p>Also, $\Sigma[x]$ denotes the set of all SOS polynomials.</p> </blockquote> <p>Using this definition, we can compute $h$ by parametrizing $h$ as fixed degree polynomial and use SOS programming to enforce the required conditions on $h$.</p> <h5 id="prop-35-polynomial-cbf-synthesis-via-sos">Prop 3.5) Polynomial CBF Synthesis via SOS</h5> <blockquote> <p>Given the control system $(*)$, assume both $f(x)$ and $g(x)$ are polynomials. Let $\rho(x)$ be a polynomial performance function and let $\be(x)$ be a polynomial nominal controller.</p> <p>A polynomial $h(x)$ is a CBF if there exists positive constants $a&gt;0$, $\varepsilon&gt;0$ and SOS polynomials $s_1(x),s_2(x)$ s.t.</p> <div class="kdmath">$$ \begin{aligned} -h(x)-\varepsilon+s_1(x)\rho(x)\in\Sigma[x]\q&amp;\cdots\q (1)\\[1.3ex] L_fh(x)+L_gh(x)\be(x)+ah(x)-s_2(x)h(x)\in\Sigma[x]\q&amp;\cdots\q (2) \end{aligned} $$</div> <p>Moreover, $\mathcal{C}\subseteq A$ and $\be(x)\in K_\text{cbf}$ for all $x\in\mathcal{C}$.</p> </blockquote> <blockquote> <p>[!note] Q. What are the equations $(1)$ and $(2)$ mean?</p> <p><strong>Claim 1:</strong> If $(1)$, then $\mathcal{C}\subset A$.</p> <p><strong>Proof)</strong> Suppose that $-h(x)-\varepsilon+s_1(x)\rho(x)\in\Sigma[x]$. Then, $\exists\sigma(x)\in\Sigma[x]$ s.t.</p> <div class="kdmath">$$ -h(x)-\varepsilon+s_1(x)\rho(x)=\sigma(x) $$</div> <p>Since $\sigma(x)$ is SOS, $\sigma(x)\geq 0$ for all $x\in D$ and hence we have</p> <div class="kdmath">$$ -h(x)-\varepsilon+s_1(x)\rho(x)=\sigma(x)\geq 0\\[1.2ex] $$</div> <p>By arranging terms properly,</p> <div class="kdmath">$$ h(x)\leq s_1(x)\rho(x)-\varepsilon-\sigma(x) $$</div> <p>and since $s_1(x)$ is SOS, $s_1(x)\geq 0$ for all $x\in D$ and hence $h(x)&lt;0$ if $\rho(x)&lt;0$.</p> <p>Here, $\rho(x)&lt;0$ and $h(x)&lt;0$ implies that $x\notin A$ and $x\notin \mathcal{C}$, respectively and hence we can conclude that if $(1)$ is true, then $D\setminus A\subseteq D\setminus\mathcal{C}$.</p> <p>By taking complement, $\mathcal{C}\subseteq A$.<span style="float: right;">$\square$</span></p> <hr> <p><strong>Claim 2:</strong> If $(2)$, then $\be(x)\in K_\text{cbf}(x)$.</p> <p><strong>Proof)</strong> Suppose that $L_fh(x)+L_gh(x)\be(x)+ah(x)-s_2(x)h(x)\in\Sigma[x]$, i.e. $\exists\sigma(x)\in\Sigma[x]$ s.t.</p> <div class="kdmath">$$ \underbrace{L_fh(x)+L_gh(x)\be(x)}_{\dot h(x,\be(x))}+\underbrace{ah(x)}_{\al(h(x))}-\underbrace{s_2(x)h(x)}_{\text{relaxation}}=\sigma(x)\geq 0 $$</div> <p>Here, as we can see above,</p> <ul> <li>The first two terms $L_fh(x)+L_gh(x)\be(x)$ is the time derivative of $h$ when the nominal controller $\be(x)$ is applied, i.e. $\dot h(x,\be(x))$.</li> <li>The third term $ah(x)$ is $\al(h(x))$ where $\al(\cdot)\in\mathcal{K}_\infty$ is linear, i.e. $\al(s)=as$.</li> <li>Since $s_2(x)$ is SOS, $s_2(x)\geq 0$ for all $x\in D$ and hence the fourth term $s_2(x)h(x)\geq 0$ for all $x\in\mathcal{C}$. So, this can be utilized as a relaxation term.</li> </ul> <p>So, for all $x\in\mathcal{C}$, since both $s_2(x)h(x)$ and $\sigma(x)$ are nonnegative,</p> <div class="kdmath">$$ L_fh(x)+L_gh(x)\be(x)+ah(x)\geq s_2(x)h(x)+\sigma(x)\geq 0 $$</div> <p>and hence</p> <div class="kdmath">$$ L_fh(x)+L_gh(x)\be(x)\geq -ah(x) $$</div> <p>This implies that $h$ is CBF and $\be(x)\in K_\text{cbf}(x)$.<span style="float: right;">$\square$</span></p> </blockquote> <p>In short,</p> <ul> <li>Theorem 3.3 constructively provides the theoretical existence of CBF.</li> <li>Proposition 3.5 provides the way to compute the CBF constructed in theorem 3.3.</li> </ul> <p>However, there is one more problem left.</p> <p>While SDP solvers can only deal with “Linear” constraints, the SOS constraints in the method proposed in proposition 3.5 are <strong>“Bilinear”</strong>(observe $ah(x)$ and $s_2(x)h(x)$).</p> <p>So, to bypass this issue, an iterative procedure is required to <strong>decouple</strong> the decision variables.</p> <blockquote> <p>[!note] Two-step alternating optimization</p> <ul> <li> <p><strong>Phase 1: Fix $h(x)$ and solve for a and $s_2(x)$</strong>  By treating the polynomial $h(x)$ as a fixed constant from a previous guess or iteration, the constraints $(1)$ and $(2)$ become linear with respect to the remaining decision variables $a$,$s_1​(x)$, and $s_2​(x)$.</p> </li> <li> <p><strong>Phase 2: Fix a and $s_2​(x)$ and solve for $h(x)$</strong>  Once $a$ and $s_2​(x)$ are determined, they are held constant. The solver then searches for a new polynomial $h(x)$ and $s_1​(x)$ that satisfy the SOS conditions. This phase is often used to <strong>maximize the volume</strong> of the safe set $\mathcal{C}$.</p> </li> </ul> </blockquote> <ul> <li>This approach transforms a complex, non-convex problem into a <strong>sequence of convex SDPs</strong> that can be solved efficiently using toolboxes. </li> <li>This iterative “search” eventually <strong>converges to a valid CBF</strong> $h(x)$ that ensures the safe set $\mathcal{C}$ remains within the allowable region $A$ while being compatible with a nominal controller $\be(x)$.</li> </ul> <div style="height: 0.1em;"></div> <hr> <h2 id="4-exponential-control-barrier-functions">4. Exponential Control Barrier Functions</h2> <div style="height: 0.1em;"></div> <p><strong>Motivation</strong></p> <p>While CBFs offer a powerful methodology, the safety-critical constraints have been so far assumed to be of relative degree one.</p> <p>To overcome this issue, we’ll introduce <strong>Exponential CBFs</strong> that allows for us to ==deal with arbitrarily high relative degree safety constraints.==</p> <h3 id="41-high-relative-degree-safety-constraints">4.1. High Relative-Degree Safety Constraints</h3> <div style="height: 0.1em;"></div> <p>First, recall the definition relative degree.</p> <blockquote> <p>Given a CBF $h(x,u)$, its $k^\th$ derivative be</p> <div class="kdmath">$$ h^{(k)}(x,u)=L_f^k h(x)+L_gL_f^{k-1}h(x)u $$</div> <p>In this context, $h(x,u)$ is said to have relative degree $r$ if</p> <div class="kdmath">$$ \begin{aligned} L_gL_f^{k-1}h(x)&amp;=0,\q\forall k\in\{0,1,\cdots, r-2\}\\ L_gL_f^{r-1}h(x)&amp;\neq0 \end{aligned} $$</div> </blockquote> <p>Using this definition, prepare some critical setup for defining Exponential CBF.</p> <blockquote> <p>[!note] Setup for Exponential CBF</p> <p><strong>Claim:</strong> Here, by defining a barrier state vector corresponding to a CBF $h(x,u)$ with relative degree $r$ by</p> <div class="kdmath">$$ \eta_b(x):= \begin{bmatrix} h(x) \\ \dot h(x) \\ \ddot h(x) \\ \vdots \\ h^{(r-1)}(x) \end{bmatrix}= \begin{bmatrix} h(x) \\ L_f h(x) \\ L_f^2 h(x) \\ \vdots \\ L_f^{(r-1)} h(x) \end{bmatrix}\in\R^r $$</div> <p>and letting $\mu:=h^{(r)}(x,u)=L_f^{r}h(x)+L_gL_f^{r-1}h(x)u$, we can obtain a system of first-order differential equations</p> <div class="kdmath">$$ \begin{aligned} \dot\eta_b(x)&amp;=F\eta_b(x)+G\mu\\[1.2ex] h(x)&amp;=C\eta_b(x) \end{aligned} $$</div> <p>where</p> <div class="kdmath">$$ F=\left[\; \begin{array}{c|c} \mathbf{0}_{r-1} &amp; I_{r-1}\\[1.05ex] \hline 0 &amp; \mathbf{0}^\T_{r-1} \end{array}\; \right]\in\R^{r\times r},\q G= \begin{bmatrix} \mathbf{0}_{r-1} \\ 1 \end{bmatrix}\in\R^r,\q C= \begin{bmatrix} 1 &amp; \mathbf{0}_{r-1}^\T \end{bmatrix}\in\R^{r} $$</div> <p>Also, by assuming a state-feedback controller $\mu=-K_\al\eta_b(x)$, then we</p> <div class="kdmath">$$ h(x(t))=Ce^{(F-GK_\al)}\eta_b(x_0) $$</div> <hr> <p><strong>Proof)</strong> First, by multiplying two matrices,</p> <div class="kdmath">$$ F\eta_b(x) =\left[ \begin{array}{c|cccc} 0 &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 1 \\ \hline 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \end{array} \right] \begin{bmatrix} h(x) \\ \dot h(x) \\ \ddot h(x) \\ \vdots \\ h^{(r-1)}(x) \end{bmatrix}= \begin{bmatrix} \dot h(x) \\ \ddot h(x) \\ \vdots \\ h^{(r-1)}(x) \\ 0 \end{bmatrix} $$</div> <p>So,</p> <div class="kdmath">$$ \dot\eta_b(x)= \begin{bmatrix} \dot h(x) \\ \ddot h(x) \\ \vdots \\ h^{(r-1)}(x) \\ h^{(r)}(x) \end{bmatrix}= \underbrace{ \begin{bmatrix} \dot h(x) \\ \ddot h(x) \\ \vdots \\ h^{(r-1)}(x) \\ 0 \end{bmatrix}}_{F\eta_b(x)}+ \underbrace{ \begin{bmatrix} 0 \\ 0 \\ \vdots \\ 0 \\ h^{(r)}(x) \end{bmatrix}}_{G\mu} =F\eta_b(x)+G\mu $$</div> <p>Here, recall that</p> <div class="kdmath">$$ h^{(r)}(x,u)=L_f^rh(x)+L_gL_f^{r-1}h(x)u\overset{\text{let}}{=}:\mu $$</div> <p>Assume that we apply state-feedback controller, i.e. $\mu=-K_\al\eta_b(x)$. By substituting this to the system of first-order differential equations, we obtain</p> <div class="kdmath">$$ \begin{aligned} \dot\eta_b(x)&amp;=F\eta_b(x)+G(-K_\al\eta_b(x))\\[1.2ex] &amp;=(F-GK_\al)\eta_b(x) \end{aligned} $$</div> <p>Here, $\dot\eta_b(x)=(F-GK_\al)\eta_b(x)$ is just a simple linear LTI first-order ODE of the form $\dot x=Ax$ and hence</p> <div class="kdmath">$$ \eta_b(x(t))=\eta_b(x_0)e^{(F-GK_\al)t} $$</div> <p>Therefore, since $h(x(t))=C\eta_b(x)$,</p> <div class="kdmath">$$ h(x(t))=C\eta_b(x_0)e^{(F-GK_\al)t} $$</div> <p>Moreover, by the comparison lemma, if $\mu\geq -K_\al\eta_b(x)$, then $h(x(t))\geq Ce^{(F-GK_\al)}\eta_b(x_0)$. <span style="float: right;">$\square$</span></p> </blockquote> <p>We now can define exponential CBF.</p> <h5 id="def-41-exponential-control-barrier-function">Def 4.1) Exponential Control Barrier Function</h5> <blockquote> <p>Given a set $\mathcal{C}\subset D\subset\R^n$ defined by</p> <div class="kdmath">$$ \mathcal{C}:=\{x\in D:h(x)\geq 0\} $$</div> <p>where $h:D\to\R$ is $C^r$ function, then $h$ is called an <strong>exponential control barrier function</strong> if there exists a row vector $K_\al\in\R^r$ s.t. for control system $\dot x=f(x)+g(x)u$,</p> <div class="kdmath">$$ \sup_{u\in U}\left[L_f^rh(x)+L_gL_f^{r-1}h(x)u\right]\geq-K_\al\eta_b(x)\q\forall x\in \text{Int}\ \mathcal{C} $$</div> <p>results in $h(x(t))\geq Ce^{(F-GK_\al)t}\eta_b(x_0)\geq 0$ whenever $h(x_0)\geq 0$.</p> </blockquote> <p>Intuitively, this implies that the actual input $\mu$ is greater than the assumed state feedback $-K_\al\eta_b(x)$, i.e.</p> <div class="kdmath">$$ \underbrace{L_f^rh(x)+L_gL_f^{r-1}h(x)u}_{\text{actual input}}\geq\underbrace{-K_\al\eta_b(x)}_{\text{reference input}} $$</div> <p>Now, recall the motivation of ECBF: $\to$ Generalize the definition of CBF to the systems with higher relative degree.</p> <p><strong>Q. Is this definition properly generalizes the definition of CBF?</strong></p> <blockquote> <p>[!note] ECBF generalizes CBF</p> <p>By letting $r=1$, then $\eta_b(x)=h(x)$ and hence</p> <div class="kdmath">$$ \mu=-K_\al\eta_b(x)=-K_\al h(x)=-\al(h(x)) $$</div> <p>where $\al(s)=K_\al s\in\text{class }\mathcal{K}_\infty$.</p> </blockquote> <p>Moreover, ECBF can be directly incorporated to the optimization-based control instead of CBF.</p> <blockquote> <p>[!note] CLF-ECBF QP</p> <div class="kdmath">$$ \begin{aligned} u(x)= \operatorname*{argmin}_{(u,\mu,\de)\in\R^{m+2}} &amp; \frac{1}{2}u^\T H(x)u+p\delta^2\\[1.2ex] \text{s.t.}\q &amp; L_fV(x)+L_gV(x)u\leq -\gamma(V(x))+\delta\\[1.1ex] &amp; L_f^rh(x)+L_gL_f^{r-1}h(x)u=\mu\\[1.1ex] &amp; \mu\geq -K_\al\eta_b(x) \end{aligned} $$</div> </blockquote> <div style="height: 0.1em;"></div> <h3 id="42-designing-exponential-control-barrier-functions">4.2. Designing Exponential Control Barrier Functions</h3> <p>Observe that the dynamics</p> <div class="kdmath">$$ \begin{aligned} \dot\eta_b(x)&amp;=F\eta_b(x)+G\mu\\[1.2ex] h(x)&amp;=C\eta_b(x) \end{aligned} $$</div> <p>is the <strong>controllable canonical form</strong>. So, by letting $K_\al=\begin{bmatrix}\al_1 &amp; \al_2 &amp; \cdots &amp; \al_r\end{bmatrix}$, we can obtain</p> <div class="kdmath">$$ F-GK_\al= \begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; 0 &amp; \cdots &amp; 1 \\ -\al_1 &amp; -\al_2 &amp; -\al_3 &amp; \cdots &amp; -\al_r \end{bmatrix} $$</div> <p>and hence the characteristic polynomial of $F-GK_\al$ be</p> <div class="kdmath">$$ \lambda^r+\al_r\lambda^{r-1}+\cdots+\al_2\lambda+\al=0 $$</div> <p>Here, suppose that such a polynomial be factored as</p> <div class="kdmath">$$ (\lambda+p_1)(\lambda+p_2)\cdots(\lambda+p_r)=0, $$</div> <p>i.e. $-p_1,\cdots, -p_r$ are the eigenvalues(poles) of the closed-loop system.</p> <p>Next, define an auxiliary family of function ${\nu_i}_{i\in I}$ where $\nu_i:D\to\R$ for all $i\in I$ and their corresponding superlevel sets $\mathcal{C}_i={x\in D:\nu_i(x)\geq 0}$ as follows.</p> <div class="kdmath">$$ \begin{aligned} \nu_0(x)&amp;=h(x);\qquad\q\q\q\q\;\;\;\q\;\;\mathcal{C}_0=\{x\in D:\nu_0(x)\geq 0\}=\mathcal{C}\\[1.1ex] \nu_1(x)&amp;=\dot\nu_0(x)+p_1\nu_0(x);\qquad\q\;\;\mathcal{C}_1=\{x\in D:\nu_1(x)\geq 0\}\\[1.1ex] &amp;\;\;\vdots\qquad\qquad\qquad\qquad\qquad\qquad\;\;\; \vdots \\[1.1ex] \nu_r(x)&amp;=\dot\nu_{r-1}(x)+p_r\nu_{r-1}(x);\qquad\mathcal{C}_r=\{x\in D:\nu_r(x)\geq 0\} \end{aligned} $$</div> <p>Our goal is to design $K_\al$ to ensure $\mathcal{C}$ is forward invariant.</p> <p>First, begin with the following basic and straightforward result.</p> <h5 id="prop-42-recursive-invariance-of-auxiliary-safe-sets">Prop 4.2) Recursive Invariance of Auxiliary safe sets</h5> <blockquote> <p>For a given $i\in [r]$, if $\mathcal{C}_i$ is forward invariant, then $\mathcal{C}_{i-1}$ is forward invariant whenever $p_i&gt;0$ and $x_0\in\mathcal{C}_i\cap\mathcal{C}_{i-1}$.</p> </blockquote> <p><strong>Proof)</strong> Since $\mathcal{C}_i$ is forward invariant, for a given $x_0\in\mathcal{C}_i\cap\mathcal{C}_{i-1}$, $x(t)\in\mathcal{C}_i$ for all $t\in[0,\infty)$, i.e.</p> <div class="kdmath">$$ \nu_i(x(t))\geq 0,\q\forall t\in[0,\infty) $$</div> <p>By the definition of $\nu_i(x)$,</p> <div class="kdmath">$$ \nu_i(x)=\dot\nu_{i-1}(x)+p_i\nu_{i-1}(x)\geq 0 $$</div> <p>This implies that for $x\to\pp\mathcal{C}_{i-1}$, i.e. $\nu_{i-1}(x)\to 0^+$, then</p> <div class="kdmath">$$ \nu_i(x)=\dot\nu_{i-1}(x)+\underbrace{p_i\nu_{i-1}(x)}_{\to\; 0^+}\approx\dot\nu_{i-1}(x)\geq 0 $$</div> <p>Thus, $\mathcal{C}_{i-1}$ is forward invariant as well. <span style="float: right;">$\square$</span></p> <div style="height: 0.1em;"></div> <p>From such a proposition, ==<strong>inductively</strong>==, we can obtain the following result directly.</p> <h5 id="thm-43-safety-guarantee">Thm 4.3) Safety Guarantee</h5> <blockquote> <p>If $\mathcal{C}_r$ is forward invariant and $x_0\in\bigcap_{i=0}^r\mathcal{C}_i$, then $\mathcal{C}$ is forward invariant.</p> </blockquote> <div style="height: 0.1em;"></div> <p>So far, we’ve observed that two conditions are required for invariance of $\mathcal{C}$.</p> <ol> <li>$p_i&gt;0$ for each $i\in [r]$</li> <li>$x_0\in \mathcal{C}_i$ for each $i\in [r]$</li> </ol> <p>Q. What is the meaning of these conditions?</p> <blockquote> <p>[!note] Meaning of these conditions</p> <p><strong>1. $p_i&gt;0$ for each $i\in[r]$</strong></p> <p>$\to$ As we assumed that $-p_i$ are the poles of a closed-loop system, $F-GK_\al$ be Hurwitz with totally negative, i.e. each eigenvalue of $F-GK_\al$ is negative real. This makes ==a closed-loop system converges without oscillation(overdamped).== (While underdamping system converges to the objective state, it may violate the safety condition because of oscillation.)</p> <p><strong>2. $x_0\in \mathcal{C}_i$ for each $i\in[r]$</strong></p> <p>$\to$ Since $x_0\in\mathcal{C}_i$ implies $\nu_i(x_0)=\dot\nu_{i-1}(x_0)+p_i\nu_{i-1}(x)\geq 0$, we obtain the lower bound for $p_i$.</p> <div class="kdmath">$$ p_i\geq-\frac{\dot\nu_{i-1}(x_0)}{\nu_{i-1}(x_0)} $$</div> <p>This provides the condition for $p_i$ corresponds to $x_0$ that means ==the required response rate depends on $x_0$.==</p> </blockquote> <p>Finally, we can guarantee the existence of ECBF using these conditions.</p> <h5 id="thm-44-conditions-for-choosing-proper-gain-matrix">Thm 4.4) Conditions for choosing Proper gain matrix</h5> <blockquote> <p>Suppose $K_\al$ is chosen s.t. $F-GK_\al$ is Hurwitz and total negative(resulting in negative real poles) and the eigenvalues satisfy</p> <div class="kdmath">$$ \lambda_i(F-GK_\al)\geq -\frac{\dot\nu_{i-1}(x_0)}{\nu_{i-1}(x_0)}, $$</div> <p>then $\mu\geq -K_\al\eta_b(x)$ guarantees $h(x)$ is an exponential CBF.</p> </blockquote> <p>This theorem provides a sufficient conditions for the existence of ECBF, i.e.</p> <div class="kdmath">$$ K_\al\text{ satisfies theorem 4.4 }\Longrightarrow\; h(x)\text{ be ECBF if }\;\mu\geq-K_\al\eta_b(x_0) $$</div> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/study/2025/Jacobi-Gauss-Seidel-method/">Jacobi &amp; Gauss-Seidel Method</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/study/2025/welcome/">Welcome to My Study Notes</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Woojin Shin. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=4c7ba839817bcbd792b494605a85f4db"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> <script src="/assets/js/obsidian-compat.js?v=d8cb3b9cd436ff9007912f2f758b4d85"></script> </body> </html>